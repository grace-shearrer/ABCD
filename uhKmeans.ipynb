{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "import sklearn.metrics as sm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data as csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_table('important_txt/4Kmeans.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperate by sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dudes = data[data['sex'] >= 0]\n",
    "lady_dudes = data[data['sex'] >= 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a List of variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names=list(lady_dudes.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine variables of interest into a single matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_true=lady_dudes['PDS'].values\n",
    "f2=lady_dudes['pds_ht2_y'].values\n",
    "f3=lady_dudes['pds_skin2_y'].values\n",
    "f4=lady_dudes['pds_bdyhair_y'].values\n",
    "f5=lady_dudes['pds_f4_2_y'].values\n",
    "f6=lady_dudes['pds_f5_y'].values\n",
    "f7=lady_dudes['interview_age'].values\n",
    "f8=lady_dudes['anthroheightcalc'].values \n",
    "f9=lady_dudes['anthroweightcalc'].values\n",
    "f10=lady_dudes['anthro_waist_cm'].values\n",
    "f11=lady_dudes['hormone_scr_dhea_mean'].values\n",
    "f12=lady_dudes['hormone_scr_hse_mean'].values\n",
    "f13=lady_dudes['hormone_scr_ert_mean'].values\n",
    "X=np.matrix(zip(f2,f3,f4,f5,f6,f7,f8,f9,f10,f11,f12,f13))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of the variable names included in this analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names=['pds_ht2_y',\n",
    "'pds_skin2_y'\n",
    "'pds_bdyhair_y',\n",
    "'pds_f4_2_y',\n",
    "'pds_f5_y',\n",
    "'interview_age',\n",
    "'anthroheightcalc',\n",
    "'anthroweightcalc',\n",
    "'anthro_waist_cm',\n",
    "'hormone_scr_dhea_mean',\n",
    "'hormone_scr_hse_mean',\n",
    "'hormone_scr_ert_mean']\n",
    "len(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 610), (2, 271), (3, 20), (4, 2)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB2fwaW4dUtJmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111fba310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.hist(labels_true)\n",
    "y = np.bincount(labels_true.astype(int))\n",
    "ii = np.nonzero(y)[0]\n",
    "zip(ii,y[ii])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An issue is a low number of people in groups 3 and 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible solution, randomly sample equal numbers\n",
    "Using the rule of thumb 2^m I need 8 people per cluster \n",
    "Possible combinations below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393849377343759797528386895216640000\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "x=math.factorial(70)\n",
    "y=math.factorial(70-20)\n",
    "fact=x/y\n",
    "print(fact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create target variable (or the one you are comparing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_var=pd.DataFrame(lady_dudes['PDS'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute missing values\n",
    "This will not allow missing data, so have to impute nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "imputer = Imputer()\n",
    "transformed_values = imputer.fit_transform(X)\n",
    "# count the number of NaN values in each column\n",
    "print(np.isnan(transformed_values).sum()) \n",
    "transformed_values_scale = scale(transformed_values)\n",
    "trans = np.hstack((transformed_values_scale,target_var.round(decimals=0)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lev3\n",
      "(70, 13)\n",
      "lev2\n",
      "(529, 13)\n",
      "lev1\n",
      "(302, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20, 13)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#def random_selct(data):\n",
    "dictr = {}\n",
    "levels = ['lev1','lev2','lev3']\n",
    "i=1\n",
    "for lev in levels:\n",
    "    if i < len(levels)+1:\n",
    "        dictr[lev] = trans[np.where(trans[:,-1] == i)]\n",
    "        i=i+1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "rand_dict={}\n",
    "target_dict={}\n",
    "for key, value in dictr.iteritems():\n",
    "    print(key)\n",
    "    print(value.shape)\n",
    "    ind = np.random.permutation(value.shape[0])#random index\n",
    "    training_idx = ind[:20]#get 20 subjects indexes\n",
    "    training = value[training_idx,:]#select 20 subjects from the value in the dictionary\n",
    "    labels_true = value[:,-1] #get the labels from the value in the dictiornary last column\n",
    "    target_dict[key] = labels_true[training_idx]#add targets to dictionary\n",
    "    rand_dict[key] = training\n",
    "    \n",
    "\n",
    "\n",
    "    # for\n",
    "# ind = np.random.permutation(transformed_values_scale.shape[0])\n",
    "#dictr['lev3'].shape\n",
    "rand_dict['lev2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly select data to train on and to test on\n",
    "It is important that you keep your indices else you won't be able to validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 486 is out of bounds for axis 1 with size 302",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-0a9d83580815>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtraining_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m721\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m721\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m#80 20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformed_values_scale\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_values_scale\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtraining_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 486 is out of bounds for axis 1 with size 302"
     ]
    }
   ],
   "source": [
    "indices = np.random.permutation(transformed_values_scale.shape[0])\n",
    "\n",
    "training_idx, test_idx = indices[:721], indices[721:]#80 20\n",
    "training, test = transformed_values_scale[training_idx,:], transformed_values_scale[test_idx,:]\n",
    "training_target, test_target = labels_true[training_idx], labels_true[test_idx]\n",
    "\n",
    "plt.hist(training_target)\n",
    "y = np.bincount(training_target.astype(int))\n",
    "ii = np.nonzero(y)[0]\n",
    "zip(ii,y[ii])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the normality of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABBUAAAOVCAYAAAA2lthRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAG+V9EQgyWMBn8LwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cf453d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=6, ncols=2, sharex=True, figsize=(18, 16))\n",
    "\n",
    "titles = names\n",
    "# axes.flat returns the set of axes as a flat (1D) array instead\n",
    "# of the two-dimensional version we used earlier\n",
    "for ax, title, y in zip(axes.flat, titles, training):\n",
    "    ax.hist(y)\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the rest of the mods you will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define how many sample are present (rows), how many features (columns), and unique labels (get the unique integers of the labels from above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-6ae808ac8d53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mn_digits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_target' is not defined"
     ]
    }
   ],
   "source": [
    "n_samples, n_features = training.shape\n",
    "labels = np.round(training_target,decimals=0)\n",
    "n_digits = len(np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size=903"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we are testing which K means works the best\n",
    "### this is done with a couple of functions to test the different strategies based on the inputs above\n",
    "This will do each for 10000 times, it takes about 80 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"n_digits: %d, \\t n_samples %d, \\t n_features %d\"\n",
    "      % (n_digits, n_samples, n_features))\n",
    "print(82 * '_')\n",
    "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette')\n",
    "\n",
    "def bench_k_means(estimator, name, data):\n",
    "    t0 = time()\n",
    "    estimator.fit(data)\n",
    "    print('%-9s\\t%.2fs\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f'\n",
    "          % (name, (time() - t0), estimator.inertia_,\n",
    "             metrics.homogeneity_score(labels, estimator.labels_),\n",
    "             metrics.completeness_score(labels, estimator.labels_),\n",
    "             metrics.v_measure_score(labels, estimator.labels_),\n",
    "             metrics.adjusted_rand_score(labels, estimator.labels_),\n",
    "             metrics.adjusted_mutual_info_score(labels,  estimator.labels_),\n",
    "             metrics.silhouette_score(data, estimator.labels_,\n",
    "                                      metric='euclidean',\n",
    "                                      sample_size=sample_size)))\n",
    "\n",
    "bench_k_means(KMeans(init='k-means++', n_clusters=n_digits, n_init=10000),\n",
    "              name=\"k-means++\", data=training)\n",
    "\n",
    "bench_k_means(KMeans(init='random', n_clusters=n_digits, n_init=10000),\n",
    "              name=\"random\", data=training)\n",
    "\n",
    "# in this case the seeding of the centers is deterministic, hence we run the\n",
    "# kmeans algorithm only once with n_init=1\n",
    "pca = PCA(n_components=n_digits).fit(training)\n",
    "bench_k_means(KMeans(init=pca.components_, n_clusters=n_digits, n_init=1),\n",
    "              name=\"PCA-based\",\n",
    "              data=training)\n",
    "print(82 * '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* silhouette =>The score is bounded between -1 for incorrect clustering and +1 for highly dense clustering. \n",
    "* Scores around zero indicate overlapping clusters.\n",
    "* homogeneity: each cluster contains only members of a single class.\n",
    "* completeness: all members of a given class are assigned to the same cluster.\n",
    "* Bounded scores: 0.0 is as bad as it can be, 1.0 is a perfect score.\n",
    "* Intuitive interpretation: clustering with bad V-measure can be qualitatively analyzed in terms of homogeneity and completeness to better feel what kind of mistakes is done by the assignment.\n",
    "* No assumption is made on the cluster structure: can be used to compare clustering algorithms such as k-means which assumes isotropic blob shapes with results of spectral clustering algorithms which can find cluster with folded shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reduction and visulaization using PCA\n",
    "### This is further compressing the data to two components for graphical ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Visualize the results on PCA-reduced data\n",
    "\n",
    "reduced_data = PCA(n_components=2).fit_transform(training)\n",
    "kmeans = KMeans(init='k-means++', n_clusters=n_digits, n_init=10000)\n",
    "kmeans.fit(reduced_data)\n",
    "\n",
    "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "h = .02     # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.imshow(Z, interpolation='nearest',\n",
    "           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "           cmap=plt.cm.Paired,\n",
    "           aspect='auto', origin='lower')\n",
    "\n",
    "plt.plot(reduced_data[:, 0], reduced_data[:, 1], 'k.', markersize=2)\n",
    "# Plot the centroids as a white X\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "            marker='x', s=169, linewidths=3,\n",
    "            color='w', zorder=10)\n",
    "plt.title('K-means clustering on the digits dataset (PCA-reduced data)\\n'\n",
    "          'Centroids are marked with white cross')\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is getting the fit and predictions from the kmeans object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,1000):\n",
    "    kmeans = KMeans(init='k-means++', n_clusters=n_digits, n_init=300)\n",
    "    kmeans.fit(training)\n",
    "    y_kmeans = kmeans.predict(training)\n",
    "    clusters = kmeans.fit_predict(training)\n",
    "    kmeans.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is a graphical representation of the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(8, 3))\n",
    "centers = kmeans.cluster_centers_.reshape(4, 2, 6)\n",
    "for axi, center in zip(ax.flat, centers):\n",
    "    axi.set(xticks=[], yticks=[])\n",
    "    axi.imshow(center, interpolation='nearest', cmap=plt.cm.binary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is creating a matrix of all the scatter plots possible\n",
    "Currently not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import itertools\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def main(data, names, colors):\n",
    "#     fig = scatterplot_matrix(data, names,\n",
    "#             linestyle='none', marker='o', color=colors, mfc='none')\n",
    "#     fig.suptitle('Simple Scatterplot Matrix')\n",
    "#     plt.show()\n",
    "\n",
    "# def scatterplot_matrix(data, names, **kwargs):\n",
    "#     \"\"\"Plots a scatterplot matrix of subplots.  Each row of \"data\" is plotted\n",
    "#     against other rows, resulting in a nrows by nrows grid of subplots with the\n",
    "#     diagonal subplots labeled with \"names\".  Additional keyword arguments are\n",
    "#     passed on to matplotlib's \"plot\" command. Returns the matplotlib figure\n",
    "#     object containg the subplot grid.\"\"\"\n",
    "#     numvars, numdata = data.shape\n",
    "#     fig, axes = plt.subplots(nrows=numvars, ncols=numvars, figsize=(8,8))\n",
    "#     fig.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "\n",
    "#     for ax in axes.flat:\n",
    "#         # Hide all ticks and labels\n",
    "#         ax.xaxis.set_visible(False)\n",
    "#         ax.yaxis.set_visible(False)\n",
    "\n",
    "#         # Set up ticks only on one side for the \"edge\" subplots...\n",
    "#         if ax.is_first_col():\n",
    "#             ax.yaxis.set_ticks_position('left')\n",
    "#         if ax.is_last_col():\n",
    "#             ax.yaxis.set_ticks_position('right')\n",
    "#         if ax.is_first_row():\n",
    "#             ax.xaxis.set_ticks_position('top')\n",
    "#         if ax.is_last_row():\n",
    "#             ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "#     # Plot the data.\n",
    "#     for i, j in zip(*np.triu_indices_from(axes, k=1)):\n",
    "#         for x, y in [(i,j), (j,i)]:\n",
    "#             axes[x,y].plot(data[x], data[y], **kwargs)\n",
    "\n",
    "#     # Label the diagonal subplots...\n",
    "#     for i, label in enumerate(names):\n",
    "#         axes[i,i].annotate(label, (0.5, 0.5), xycoords='axes fraction',\n",
    "#                 ha='center', va='center')\n",
    "\n",
    "#     # Turn on the proper x or y axes ticks.\n",
    "#     for i, j in zip(range(numvars), itertools.cycle((-1, 0))):\n",
    "#         axes[j,i].xaxis.set_visible(True)\n",
    "#         axes[i,j].yaxis.set_visible(True)\n",
    "\n",
    "#     return fig\n",
    "\n",
    "# main(training, names, y_kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is an accuracy score to compare the training target variables to the labels we generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "labels = np.zeros_like(clusters)\n",
    "for i in range(4):\n",
    "    mask = (clusters == i)\n",
    "    labels[mask] = mode(training_target[mask])[0]\n",
    "#np.dtype(labels)\n",
    "# for x in range(0,len(training_target)):\n",
    "#      print(np.dtype(labels[x,]))\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(training_target.astype('int'), labels.astype('int'),normalize=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is a confusion matrix to see where errors may occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "acks=['1','2','3','4']\n",
    "mat = confusion_matrix(training_target.astype('int'), labels.astype('int'))\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=acks,\n",
    "            yticklabels=acks)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');\n",
    "#looks like it is really good at getting 1, or messing up 1 and 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is a Gaussian Mixture model to assess the probability of being in a given cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "#X = iris['data']\n",
    "#y = iris['target']\n",
    "#kmeans = KMeans(n_clusters=6).fit(X)\n",
    "distances = np.column_stack([np.sum((training - center)**2, axis=1)**0.5 for center in kmeans.cluster_centers_])\n",
    "svm = SVC().fit(distances.astype('int'), training_target.astype('int'))\n",
    "print(svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to randomly sample the data and perform the kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_digits: 3, \t n_samples 60, \t n_features 12\n",
      "__________________________________________________________________________________\n",
      "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "k-means++\t0.33s\t532\t0.455\t0.510\t0.481\t0.360\t0.437\t0.284\n",
      "random   \t0.28s\t532\t0.455\t0.510\t0.481\t0.360\t0.437\t0.284\n",
      "PCA-based\t0.00s\t532\t0.455\t0.510\t0.481\t0.360\t0.437\t0.284\n",
      "__________________________________________________________________________________\n",
      "(60, 3)\n",
      "(60,)\n",
      "(60,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cf2ded0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'cluster_space' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-30c86840a74f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mrandom_selct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mCS_dct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arr%i'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcluster_space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0mCluster_dct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arr%i'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclusters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cluster_space' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def random_selct(DATA):\n",
    "    dictr = {}\n",
    "    levels = ['lev1','lev2','lev3']\n",
    "    i=1\n",
    "    for lev in levels:\n",
    "        if i < len(levels)+1:\n",
    "            dictr[lev] = DATA[np.where(DATA[:,-1] == i)]\n",
    "            i=i+1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    rand_dict={}\n",
    "    target_dict={}\n",
    "    for key, value in dictr.iteritems():\n",
    "        #print(key)\n",
    "        #print(value.shape)\n",
    "        ind = np.random.permutation(value.shape[0])#random index\n",
    "        training_idx = ind[:20]#get 20 subjects indexes\n",
    "        training = value[training_idx,:]#select 20 subjects from the value in the dictionary\n",
    "        labels_true = value[:,-1] #get the labels from the value in the dictiornary last column\n",
    "        target_dict[key] = labels_true[training_idx]#add targets to dictionary\n",
    "        rand_dict[key] = training\n",
    "\n",
    "        #combine\n",
    "    data=np.vstack((rand_dict['lev1'],rand_dict['lev2'],rand_dict['lev3']))\n",
    "    data=np.delete(data,12,1)\n",
    "    targets=np.hstack((target_dict['lev1'],target_dict['lev2'],target_dict['lev3']))\n",
    "\n",
    "    n_samples, n_features = data.shape\n",
    "    labels = np.round(targets)\n",
    "    n_digits = len(np.unique(targets))\n",
    "    sample_size=n_samples\n",
    "\n",
    "    ############################\n",
    "    ####start the k meaning#####\n",
    "    ############################\n",
    "\n",
    "    ### making a cute table################### making a cute table###################\n",
    "    print(\"n_digits: %d, \\t n_samples %d, \\t n_features %d\"##########################\n",
    "          % (n_digits, n_samples, n_features))### making a cute table################\n",
    "    print(82 * '_')##################################################################\n",
    "    print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette')########\n",
    "    #################################################################################\n",
    "\n",
    "    def bench_k_means(estimator, name, data):\n",
    "        t0 = time() #time\n",
    "        estimator.fit(data) #estimating the fit \n",
    "        print('%-9s\\t%.2fs\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f'\n",
    "              % (name, (time() - t0), estimator.inertia_,\n",
    "                 metrics.homogeneity_score(labels, estimator.labels_),\n",
    "                 metrics.completeness_score(labels, estimator.labels_),\n",
    "                 metrics.v_measure_score(labels, estimator.labels_),\n",
    "                 metrics.adjusted_rand_score(labels, estimator.labels_),\n",
    "                 metrics.adjusted_mutual_info_score(labels,  estimator.labels_),\n",
    "                 metrics.silhouette_score(data, estimator.labels_,\n",
    "                                          metric='euclidean',\n",
    "                                          sample_size=sample_size)))\n",
    "\n",
    "    bench_k_means(KMeans(init='k-means++', n_clusters=n_digits, n_init=300),\n",
    "                  name=\"k-means++\", data=data)\n",
    "\n",
    "    bench_k_means(KMeans(init='random', n_clusters=n_digits, n_init=300),\n",
    "                  name=\"random\", data=data)\n",
    "\n",
    "    # in this case the seeding of the centers is deterministic, hence we run the\n",
    "    # kmeans algorithm only once with n_init=1\n",
    "    pca = PCA(n_components=n_digits).fit(data)\n",
    "    bench_k_means(KMeans(init=pca.components_, n_clusters=n_digits, n_init=1),\n",
    "                  name=\"PCA-based\",\n",
    "                  data=data)\n",
    "    print(82 * '_')\n",
    "    \n",
    "    kmeans = KMeans(init='k-means++', n_clusters=n_digits, n_init=300)\n",
    "    ####THINGS TO SAVE#########\n",
    "    kmeans.fit(data)\n",
    "    y_kmeans = kmeans.predict(data)\n",
    "    clusters = kmeans.fit_predict(data)\n",
    "    cluster_space = kmeans.fit_transform(data)\n",
    "    print(cluster_space.shape)\n",
    "    print(clusters.shape)\n",
    "    print(y_kmeans.shape)\n",
    "    \n",
    "        # #############################################################################\n",
    "    # Visualize the results on PCA-reduced data\n",
    "\n",
    "    reduced_data = PCA(n_components=2).fit_transform(data)\n",
    "    kmeans = KMeans(init='k-means++', n_clusters=n_digits, n_init=10000)\n",
    "    kmeans.fit(reduced_data)\n",
    "\n",
    "    # Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "    h = .02     # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "    y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    # Obtain labels for each point in mesh. Use last trained model.\n",
    "    Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure(1)\n",
    "    plt.clf()\n",
    "    plt.imshow(Z, interpolation='nearest',\n",
    "               extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "               cmap=plt.cm.Paired,\n",
    "               aspect='auto', origin='lower')\n",
    "\n",
    "    plt.plot(reduced_data[:, 0], reduced_data[:, 1], 'k.', markersize=2)\n",
    "    # Plot the centroids as a white X\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "                marker='x', s=169, linewidths=3,\n",
    "                color='w', zorder=10)\n",
    "    plt.title('K-means clustering on the digits dataset (PCA-reduced data)\\n'\n",
    "              'Centroids are marked with white cross')\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_digits: 3, \t n_samples 60, \t n_features 12\n",
      "__________________________________________________________________________________\n",
      "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "k-means++\t0.34s\t458\t0.475\t0.538\t0.504\t0.359\t0.457\t0.310\n",
      "random   \t0.29s\t458\t0.475\t0.538\t0.504\t0.359\t0.457\t0.310\n",
      "PCA-based\t0.00s\t613\t0.457\t0.470\t0.463\t0.404\t0.439\t0.102\n",
      "__________________________________________________________________________________\n",
      "(60, 3)\n",
      "(60,)\n",
      "(60,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112591510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_digits: 3, \t n_samples 60, \t n_features 12\n",
      "__________________________________________________________________________________\n",
      "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "k-means++\t0.34s\t512\t0.467\t0.538\t0.500\t0.359\t0.449\t0.307\n",
      "random   \t0.29s\t512\t0.467\t0.538\t0.500\t0.359\t0.449\t0.307\n",
      "PCA-based\t0.00s\t638\t0.538\t0.554\t0.546\t0.500\t0.523\t0.122\n",
      "__________________________________________________________________________________\n",
      "(60, 3)\n",
      "(60,)\n",
      "(60,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1125913d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_digits: 3, \t n_samples 60, \t n_features 12\n",
      "__________________________________________________________________________________\n",
      "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "k-means++\t0.36s\t627\t0.481\t0.562\t0.518\t0.368\t0.463\t0.316\n",
      "random   \t0.30s\t627\t0.481\t0.562\t0.518\t0.368\t0.463\t0.316\n",
      "PCA-based\t0.00s\t648\t0.487\t0.562\t0.522\t0.368\t0.469\t0.287\n",
      "__________________________________________________________________________________\n",
      "(60, 3)\n",
      "(60,)\n",
      "(60,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11257b6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_digits: 3, \t n_samples 60, \t n_features 12\n",
      "__________________________________________________________________________________\n",
      "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "k-means++\t0.30s\t434\t0.538\t0.667\t0.595\t0.415\t0.522\t0.322\n",
      "random   \t0.25s\t434\t0.538\t0.667\t0.595\t0.415\t0.522\t0.322\n",
      "PCA-based\t0.00s\t436\t0.487\t0.562\t0.522\t0.368\t0.469\t0.299\n",
      "__________________________________________________________________________________\n",
      "(60, 3)\n",
      "(60,)\n",
      "(60,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5P8DzEhpyZD5nsAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111feb110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_digits: 3, \t n_samples 60, \t n_features 12\n",
      "__________________________________________________________________________________\n",
      "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "k-means++\t0.33s\t577\t0.477\t0.550\t0.511\t0.362\t0.459\t0.304\n",
      "random   \t0.26s\t577\t0.477\t0.550\t0.511\t0.362\t0.459\t0.304\n",
      "PCA-based\t0.00s\t578\t0.481\t0.562\t0.518\t0.368\t0.463\t0.308\n",
      "__________________________________________________________________________________\n",
      "(60, 3)\n",
      "(60,)\n",
      "(60,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a16cf3450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_digits: 3, \t n_samples 60, \t n_features 12\n",
      "__________________________________________________________________________________\n",
      "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "k-means++\t0.36s\t499\t0.471\t0.552\t0.508\t0.364\t0.452\t0.291\n",
      "random   \t0.30s\t499\t0.471\t0.552\t0.508\t0.364\t0.452\t0.291\n",
      "PCA-based\t0.00s\t603\t0.478\t0.493\t0.485\t0.424\t0.460\t0.140\n",
      "__________________________________________________________________________________\n",
      "(60, 3)\n",
      "(60,)\n",
      "(60,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xu4HVWd5vHvD4ghhJOEQJBLuExI\ni4BGJjggCgYFEeSiIC2gQlDQ1oFBERWFRhgbRAZE7JYGFFtABA1IGKChB2hNMKCiIGBDQAIGE0hC\nQg45IYQouOaP36qkTqVqX87Z93o/z5MnZ++qXbdd9daqVavWthACIiJSDhu0ewFERKR1FPoiIiWi\n0BcRKRGFvohIiSj0RURKRKEvIlIiCv0KzGyOmZ3QAcuxn5k91u7lqJeZHWBm85s07clmFlKv7zKz\nj9X42ZrHHc4ydRMzO8TMbmr3cgxVM/e1CvOs6/s2s+vM7NwmLcsXzOy8WsatGvpmNt/MDki9PsbM\n+s1s2nAWsizM7CQzmzWcaYQQZoUQdmvQIjWFmW1kZsHMdmzH/EMIB4YQflzvuI34foaiVSFVx3zO\nB74ZP5N8l6vM7GUzW2hmF5nZ2rwws+PM7ME4ziIz+3cze2dm3ifF6RzZ0JUqgSEUOK8APmFmm1cb\nsa6SvplNBy4DDgkhzK7nszI0ZrZRu5dBepuZ7Q2MDCH8LjNotxDCpsCBwHTgk3H8LwMXA/8ETAB2\nAL4HfDDz+enA8vh/Pcujfb5OIYRXgLuA42oZueI/YD5wAPBpYBnw9irjzwG+DvwaWAXcAmwO3AAM\nAL8Btk+NvytwD75zPAF8ODXscOBhYCXwZ+Ds1LDJQACOBxYCS4GvpIa/A3goznMJcFGFZT4yzmcA\nmAccmFqXE+Lf5wFXZ+efen1i3FYrgWeAY4C3Aq8CrwMvA8viuBsDlwAL4rL9K7BxHHZAnM6ZwGLg\nh8l7qXktBL4A/AFYEbftyNTwr8bPPgd8Km6nHQvWfSJwe9z+TwGfTA07L077urhe/wVMLZjO/XE+\nq+K6fji1Ll+O38/zwPGpzxRuh5zpbwh8G3gReBo4JbP909/VhsClcdxngP+VN26F7+dQYG5c54XA\naUNcppNS03kaOCm+PxZYDfwtzvdlYEtgb/y4eQlYBPwzMCJ+ZoP4+oX4nT8K7FppOxbNJ2c9vg5c\nkXq9UXafAWbGbboZ8ApwRJUcmBTnexTwF2BClfEXAl/C9+m/pPbNmXHf+RNwcmr8TYAfAf3AY8AZ\nxGOkYPmvA86t4Zgfhx9zi+IyfR3YoJbvO2ed9mBdft0A3JgsA56Jd8R16wduA7aNwy7E98lX43d2\naXz/u3GZBoDfAu/MzG86cHfVTK86gh+0P4s709tqGH8O8Mf4pW+GB/mTwHvil3E98P04bh8eTMfH\nYXvEDbpzHP5e4C34Dv82/KRzaDp08cuajYGpwBrg7+Lw3wLHpuazV8HyvhM/yPaP89kuNf+aQh8Y\ngx+Iyby3Zt0BeRIwKzPP7+I782bxs3cA/xTWhf5rwDeANwCjyA/9XwNbxZ3nj6wLlEPxcN0FGB13\ntkqhfx/wL6ltuAyYllrn1cD78R3+ImBOwXTyDrRkXc4BRuAn8VXAmGrbIWf6p+AH98S4zvdSHPqn\n4CeobYHxwC8qjJv3/SwlHlDx80UnumrLdBh+HBi+L68GpqS2zfzM9P4HsFfclpPi93pKHHYI8AAe\n5BvghaWtatyf5uctf2q+M0md2LLfJbAbfrKZHvevvwAbVpnm/wbuj3/PBU6tMv5C4MG4LUfF/e1h\nvPDzBvx4mw/sH8e/GJgV13kH4HFqDH0qH/O34yfNTfDj60HgxFq+78z6jIzrdCq+7x8D/DW1DBOA\nI+K6jgFuBm7K20dT7x2H748b4Se55xhc2NsTeKFqRlcdwTf0APB/iWe8KuPPAc5Ivf4OcFvq9RHA\n7+LfHwN+kfn8D4CzCqb9XWKJnXWhv1Vq+EPAUfHv+4GvAZtXWd4fUHAVQH2h/1Jct40z0xgUKnEn\nexXYIfXevsBTqYP0VeANqeF5oX9M6vUlwHfj39eSCk7gzRSEPvDf4o44OvXeRcBVqXX+j9SwKcDL\nBduqKPRfJhUQ+BXF26tth5zp30s8scXXH6A4yO8lHqjx9UEVxs0L/efj+31V9p2Ky5Qz/u3E0mr2\nOy0Y/4vAjfHvA/EC1F6kjsMa96dq8/lFZj2S73Ig7tfz8BA3PPgXVpme4VdYyQnrbODBKp9ZyOCr\nwHcBz2TGOZt1BcY/Awekhv1Pag/93GMeLySsZnCQHkcsPdfzfeMn+QWApd57gNTVRmb8twNL8/bR\nCtt4JV4Fl7y3C/EqqdK/Wuv0PwO8CbjKzCx508yuijd6Xo71fIklqb9X57zeNP69A/AuM3sp+Qcc\njZeUMbO9zWyWmS01sxX4gbhFesFCCItTL19JTfsTeGnoSTN7wMw+ULBu2+GXakMWQhgAjgVOBhab\n2e1m9qaC0bfCSwGPpNb5dvzyPrEkhPCXKrMtWu9t8J0tkf47axu8SmNV6r1n8Z2/aD6jqyxX1rIQ\nwus5y1rLdsgua3pdnq0wz3q2QZ4j8KuSP8f9b6+hLJOZHWpmvzGz5XH9DiSz/2bGf3O8IbrYzAbw\nqoUtAEIId+FXtZcDS8zsCjPro/7tmKcfvxrOmhJCGBdCmBxCOCd4srwIbJm+qZvj3fhxNSO+vh6Y\namZviet5Vyo3jk59Lr0tdwC2z2TDl+P6gmdErftDVtExvwO+LZek5nkZ8MY4vN59cGHcZuuNb2aj\nY37+OX7XP6fCvhE/82UzeyJmYT9+LKY/04efpCuqNfRfwC+F9sUvfQAIIZwUQtg0/vs/NU4rbQHw\nn3HHSv5tGkI4JQ7/CV61tF0IYSxwFX6GqyqE8GQI4Rh85/8W8DMz27hgGXaqYZKr8Eu+xFbpgSGE\nO0MIB+A74zzgymRQZjpL8MvjnVPrPDauHwWfqcci/PIzsV2FcZ8HtjCzdJBvj1821qveZa5lO6Qt\nYvC6bF9h2vVsg/WWO4TwmxDC4fi+czu+H9a1TGY2CrgJuAB4YwhhHH6jLdl/87bXlXi11OQQwhj8\nSnXt/h5CuDSEMBWv8twVv69TbTvW8r08ihfqanEfXmV3eIVxpuPZ8qiZLY6fCXg1LsFbTyW58dPU\n59LLugC/WklnQ18I4bA4fDEF2z6E8Bpe1Vt0vBYd8wvwQsn41DzHhBCmxOHD2Qez438Zv9LeM37X\n782MO+h7M7P34N/3h/H7DpvhV9HpPNwFeKTCMgF1tN4JITwfF+wgM/t2rZ+r4lZgNzP7qJmNiP/2\nNLOd4/A+YHkI4VUzewdeL1aT2KRsixDC3/D69oDfWMr6AXCSmb3HzDYws4mp+ac9DEwzs+3MbBzw\nldS8tjazw8xsE/wAXIXfiAE/KCea2QiAWOq9CrjUzCaYm2hmB9a6blXMAE40s53j8pxdNGII4U/A\n74BvmNlIM9sdv0KqqeljZlqv46XASXWMX892mAF83sy2jc3Szqgw+WTcbcxsM/wGYZFB34+ZjYr7\n45gQwl/xS+jXCz5baZlG4nXRS4HXzexQvOCUnu8WsbSe6MP31VVmtgvwD8mAeFzsGVu2rML3s9dr\n2I5588m6A5hWYfhaIYR+vKrncjM7PG6vEebt/L8Z97mj8IYNu6f+nQZ83Mw2rGU+wK+Av5jZ6Wa2\nsZltaGZvNbM94vAZwJlmNs7Mtsfr29MeAT4WP3cIsE9qWO4xH0JYAMwGLjazMXHYZDN7d2qete6D\nc4ANzOwU8yawf4/fM0v04SeY/jitr2U+v4TBx1IffrJdht8jOJf1r7qnAXdWWCagziabcaO8FzjK\nzC6o57MF01uB3yT8OH5mXIyXjEbGUT4LXGBmK/EbOjPyplPgA8Dc+NmLgaPzqkxCCPfjLVz+GT/g\nfkF+yfA/8Btef8Dr5m5NDdsQD5ZFePC9k3U74d14q5glsdQDcDp+qfdAnOddwN/VsW6FQgi34VUA\n98b53hcHrSn4yNFx3ovxkumZIYRfDHH25wDXx0vjWtpm17MdLgf+E9/+v43LWuRy/CbfH/Abcf+O\nh2SevO9nOvBsvOw+keJmcIXLFEJ4CQ+6mfh9jKPwq4Zk+H/hV7Hz4/baEt8e0/ETzZVAuhQ8Dg+r\nl/D7bIvwliRQYTsWzGeQEMIDwJpUoFYUQrgQD7xz8f19AX6s3oK3ilkJXBdCWJz8A76P37R8X43z\neA0/hveM67sM3yZj4ijnxG0wHw+6azOTOBWvpnsJ+HtSx2uVY/7jeJg+jleh3Mi6q4Sa98EQwpo4\n/0/F6RyJb5/EJfhN+Rfx+4/ZsL4UODZ+Z5fgJ+Z78H11Pn6/ZVEycryyPChnO6zHBlc5Sa8xs7fi\nN7hHxque0jGzw/Bmb7VU45WS+T2vT4YQjmr3skj9zOw0vFnsmVXHVej3HjM7Ai/d9uFn/tVlOpjj\nPYp98VL81nhpe3YI4YttXTCRDqC+d3rTyfjl8FN4c76T27s4LWd4twIr8OqdR/F6aJHSU0lfRKRE\nVNIXESkRhX4PMbMzzeyqCsMH9ZhaBubdUi9s0LSuthq7r60wjWrf0QlmNmc48yiYbjCzyQXDPmZm\ndzV6ntKZFPp1im24f2f+NOEiM7vTzPap/smq0z3XzK4bzjRCCN8IIZw03GWR5kl/R2a2YwzjtvYq\nGUL4cQhh7fMRlU4Q0v0U+nUwsy/g7We/gT+avT3+hHK2S9lmzNus8qPvbddpy9juMJXK9P20R8cc\noJ3OzMbifaGcHEK4OYSwKoTw1xDCbSGEL8VxNjCzr5jZ02b2opnNMLPxcVhSqptu3t/GMjM7Kw47\nCH/47Oh4BfFIfH+WmZ1vZvfhT+9NMn/K9Fbz/lzmmdmnUss46GrB/KnkZ+OynJVZnz3jFcuAmS2J\nD4Dkrfdm5n0JLTX/8ZzbzWxianjeMo41sx/EK6HnzOw8K3gSMy7zjea/KrTSzP5gZm8ys6+a2Qtm\ntsBST+ma2SfMbG4c9xkzSz+1up/5D36cYf6g1Q9z5neqmT2erIN5/zgPx4dg7jezKalx/7uZPRTn\n9VO8J9JccTvvEf/+ePyud42vTzKzW3K+o3vj/y/F733v1PQujtv7T2Z2cME8P2Fmt6VezzOzGanX\nC8yfsk4cYGZPxeleZub9aFmqSsnMkmV6xFJ941TaTjnLtZuZ3R330SVmdmZq3W+K3/UAcIL5k+CX\nmtnz8d+lZjYyjr9F3N9eitP6pcVCRfyOn4vfzZNmtn/R8khGtR7Z9G9tD3YH4Y9Bb1RhnM/jXR5P\nxJ8qvhK4IQ7bEe8KInky8W34U7K7xOHn4k8xpqc3C+9NcDe858AR+GPiSX/pu+OP+e+fnQbeN8vL\neOdXI/EnAF8j9kyIP+Z+XPx7U+AdBeu0Od7fxyZ4u/8bgVuqLOMtcd1H4/3XPAD8Q8H0z8Wblb4/\nfv5avO/0s+K0PgX8KTX+IXi/KYY/dv4KsetjYL+4jhfGdR4V31sYh5+NP6g2Ib6eivcrtRf+VPV0\n/GnHpAuFZ/GnakfgT9T+FTivYD2uBU6Pf38P79Drs6lhp+V8R8k+sVFqOifE+XwqLtNn8T6SLGee\nk/AnTjfAn0d4FnguNayfdX3BB/yJ4HH4FepS4KDUPOekphvw/n+otp1ylqkPf1L0dHwfXduteVz3\nvwIfiss8inW/vbEl3t3w/azrFvoCvJO5EfHfvvF73xl/Cnib1Hbcqd0Z0S3/2r4A3fIP7wZ6cZVx\n5hIDOL7eOu7kG6UO8Imp4Q8Qu0imOPS/nnq9Hd4PTF/qvQuIXT5nAuVrwE9S443GuyJIQv9evO36\nFnVuh92B/grL+Eb8ZDYq9d6xZLrQTg07l9QPP+B90K/tjjmGRgDGFXz+FuBz8e/94jpunBq+H96B\n3CV4fyhjU8MuJ9N/P/7bD9Pwk+WgsI2BVBT6JwK3pvaDk5Ltj4fx1NT6Vgv9eanXm5DpQjwz3wV4\nKB+Dn2wewLvT/kSyPHG8AOyTej2D+KNDVA/9wu2UszzHAr+v8F3fm3nvaeADqdfvZ10XyV/Hu3Sf\nnPnMZPwkdADxR2b0r/Z/qt6p3Yt4x1WV6iF3AGbaum5Z5+Ih/cbUOEVdIhdJd+W6Dd4B3crUe9mu\nkNPjrv1s8O6TX0wNPxHvWfEJM/uteYdg6zGzTczsylh9MYCfLMZlqmuyXeKOABaltsOVVO7qN9v1\ndro75tXx/03j8hxsZr+2dd0Vf4DB3csuDSG8mpn+OPyX3y4I3t9TellPt8Hd926Hb7tt8FJzbte4\nOWYD+5rZVnhp+Kd4t+E74n2sPFzhs1lr95HgP4MHxfvJbPzE9u749yz8pDUtvs6dLrXte4lK2ymr\nWlfl2W6ut2Hwdn02Nd2L8B5r74pVeV8BCCHMw6+qzwVeMLOfmFneskgOhX7tfoVXQ3yowjgLgIPD\n4O5gNw4h1NJVcdFTcun3nwfG2+AeE4u6Qh7UDax574drfzQ5hPBUCOFYPIwvBG6ywV0sJ07HL6f3\nCt4FbNLjYLpL12yXuGvwK4h097TD/mH3WNf7M7wDvaS74jsqLEuiH//Fpx+a2bsyy3p+5vvaJIRw\nA779tk3qvaPCrnRjEL2Cd/R1bzwxL8ZPNnNCfr9HjXgyMgn9fePfsykO/aGqtJ3yxq3Ux1F2nZ/H\nTyqJ7eN7hBBWhhBODyFMwq8Av5DU3YcQrg8h7BM/G/B9WGqg0K9RLCF+DbjMzD4US8AjYskz+S2B\nK4DzzWwHAPOubmtt2bME2NEqtH4J3svp/XjPoxvHm2knkt8V8k3AoWa2j5m9gfhbn8nAeLNxQgyj\n5IcX8roQ7sNL2y+Z35Q+p9JKhBAW4b08fsvWdU+7k5nV1HVvFW/A69uXAq/FG5w1dUkdQpiFV9HN\ntHU/ivJ94DNmtpe50eZdBPfhJ/nXgFPNu8Y9Eu/xsZLZeO+qSdjOyrzOWop3911Td9QV5vkevDpt\nIfBL/P7T5sDvhzjNbLe+lbZT1u3AVmb2+XiTts+Kf4QG/Oc8/zEeK1vgx9h1sPbm8eR44h3A98/X\nzbsNf28sBLyK759F3V9LhkK/DiGES/AfMvhH/IBdgB/USZep38G7cL3LvEvnX+M3v2pxY/z/RTN7\nqMJ4x+J1wc/jHYmdE0K4O2dZH8P73LkeL7X24z9JlzgIeMzMXo7LfUxOtQh4E9VReF8+v8a7mK7m\neDygk+5pbyL+GtpwxNLzqXh9dD/wUQZ3cV3t83cT67rNbI8Qwu/wG6bfjdObh9dvE7wb7iPj6368\nC+qbq8xiNn6SvLfgdXZ5XsH7CLovVpu8o9Z1SU3jj/g9kF/G1wP4TxXeFwb/Ylk9zgWuicv0kUrb\nKWd5VuLdJx+GX+k8hZ+UipyH/6bDo3iXxQ/F98C7h74nrt+vgH+NJ++RwDfxfXIxfrVatXdJcep7\nR0SkRFTSFxEpEYW+iEiJKPRFREpEoS8iUiIKfRGREmlqL3d948aHCdtMrD6i9LwNljzV7kUQ6RpP\nL391WQhhQjOm3dTQn7DNRM7/8R3NnIV0idEXva/diyDSNT54wxOVuvwYFlXvSEus+tJ6z4+JSBso\n9EVESkShLy2j0r5I+yn0RURKRKEvLaXSvkh7KfSl5RT8Iu2j0BcRKRGFvrSFSvsi7aHQFxEpEYW+\ntI1K+yKtp9AXESkRhb60lUr7Iq2l0Je2U/CLtI5CX0SkRBT60hFU2hdpDYW+iEiJKPSlY6i0L9J8\nCn0RkRJR6EtHUWlfpLkU+tJxFPwizaPQFxEpEYW+dCSV9kWaQ6EvInUZWPMaN899kecG1nDz3BcZ\nWPNauxdJ6qDQl46l0n57JeGeDfV7nlnBNQ8v5Qe/f4FrHl7KPc+saNMSylBs1O4FEJHOlIQ7wJG7\nbL72/QMmjQVgr2035S1bvrz2tXQHhb50tFVfupvRF72v3YtRSkmYZ0N9zMiN1p4EjhwzsuXLJcOj\n0BeRXOlwl96hOn3peKrbF2kchb50BQW/SGMo9EWkbknLntG77F3X5yZM2adJSyS1UuhL11Bpv3Pc\n88wKFr9xKvuf/W/sdtxXa/rMbsd9lb2/8n0Ff5sp9EWkbgdMGstWSx5i7u1Xs9PBx1cN/t2O+yo7\nHXw8T995LUsfndOipZQ8Cn3pKirtd4akZc9T11/I03deWzH404H/2I8uaPGSSpaabIrIsCRBvtPB\nxw96DQr8TqTQF5Fhywt+BX5nUuhL19FTup0pHfxJ+CvwO4/q9KUrqW6/M2UDXoHfeRT6ItIw2Zu5\ntTbnlNZR6EvXUmm/uYq6Vi6SrsO/9aO7VG3VI+2hOn0RyVXUtXKevJu2lVr1SPso9KWr6aZu8xR1\nrZxVqZWOgr/zKPRFJFctXSvX0ixTwd9ZVKcvXU91++0xYco+NbfDf+xHF6yt41ffO+1lIYSmTXzS\nrlPC+T++o2nTF0lTNU/rTZiyT1196dQ7fll98IYnHgwhvL0Z01ZJX3qGSvytV2+AK/DbT6EvIlIi\nCn3pKSrti1Sm0BcRKRGFvvQclfZbp96ndqX9FPrSkxT8rZE8tXvPMyvavShSIz2cJSJDVutTu9I5\nVNKXnqXSfvMlT+2OGanyY7dQ6IuIlIhCX3qaSvsigyn0RURKRKEvPU+lfZF1FPpSCgp+EafQFxEp\nEYW+lIZK+yIKfRGRUlHoS6motC9lp9AXESkRhb6Ujkr7UmYKfRGRElHoSymptC9lpdCX0lLwSxkp\n9EVEKui1XwdT6EupqbQv1fTar4Pplw9ERCrotV8HU0lfSk+lfamk134dTKEvIlIiCn0RkRJR6Iug\nKh4pD4W+SKTglzJQ6IuIlIhCXyRFpX3pdQp9EZESUeiLZKi0L71MoS8iUiIKfZEcKu1Lr1LoixRQ\n8EsvUuiLiJSIQl+kgkM//X4O/fT7270YIg2j0BepgcJfeoVCX6TA0SsuXu89hb90u97oIFqkwfIC\nPy0d/Ld/7/81e3FEGkYlfZGMaoGfpdK/dBOFvkiDKPylGyj0RVLqLeXnUfhLJ1OdfgcZ6F/O7Ftn\nMO3wjzBms/HtXpzSaUTgp6neXzqRSvp1Guhfzm3XXMFA//KGT3v2rTO44TvnM/vWGQ2ftlTW6MDP\nUulfOoVK+nVKghngsOmfaei0px3+kUH/59HVQOM1O/DTVPqXdlPo16mWYG6mZp50pLWSE4DCX1pJ\noV+nMZuNb1rY1hLo7T7p9JpWlvKLKPyllRT6HaSWQG/mSUfaS1U/0gq6kdsgyQ3e5+c/PeQbvUmg\nd0JdfTNvWHeCo1dc3BGl/CK68SvNopJ+gyRVM3Mf/BUPz/k50L117gP9y7ninNO6fj16gap+pNEU\n+g2SVMnsMe197LLH3l1Z5560DFqz+hUenvNzdt/nvV25HtV0cgm/iMJfGsVCCE2b+KRdp4Tzf3xH\n06YvQ1PU7PO2a67ghu+cz5GfPo2RozbpyWah3Rj4RXQC6F0fvOGJB0MIb2/GtHuqpK827LUpaiWU\nvpGs7df5VPqXoeipG7n1PtHa6puVnXJzdNrhH+HYz521XtVNJ91IboZeKuWn6aav1KOnSvr1tmFv\n9YNOnfJgVRmbffZq4KepyafUoqdCv94wa/WDTnqwqj3KEPhZqvqRIj0V+vVqZYm33vsNeeNv3TeS\nRSvX1DzPeseX3qPSv2T1VJ1+J6v3fkN2/K37RrLf5AlM3XZsTZ+fuu1Y9ps8ga37Rg55mXtBGUv5\nRVT3L1Cikn4zWvbUM816e9BMj+83gGew+emf463bTQDgoedWFE5n6rZj2XnLPp58YWWpS/oK/Hyq\n+im30pT0m9FXfT3TrKVlTHp66fGT9y/41nd48oWV7LxlX2GJPx34lU4MeTqldZG0hkr95VSakn4z\nbqI2eppF00u/nwT5zlv2AYNL/MMJfGhd66JWPE+hUn5tVOdfPnoitw0aEXrZgB9u4DdquWqRPPl7\n7OfOasrJRYE/PAr/9tMTuT2mESXqdIk/KfUPJ/Chda2Z1HS1s6nOv7cp9NugUaH30HMr1gZ+8rob\nNPPkolJ+4yj8e5NCvw0aFXrZm7lTtx3bluDvlD6PFPjNoXr/3qLQ71JFdfrQ+hL/cKqrBvqXc9dP\nrwbgwKNP6Nl+f3qFSv/dT6HfhfJu2lZq1dNsw6mumn3rDG7+3rcBGDlqkyFdAamE33oq/XcvhX6O\nTqmuyFOplU67gn841VXTDv8Ia1a/svZv6T4q/XcXhX6OTukNM6uWZpntLPEPxZjNxnPUZ74w5M+r\nlN85FP7dQaGfoxObFG7dN7Lmdvjp4F808GrPdsWgwO9MqvrpbAr9HJ3Y3/yilWuYNW9pzQH+0HMr\nejrwpTuo9N95StP3Ti+oN8B7OfBVyu8u6uGzcyj0peso8LuXwr/9VL1TQp3cOqkaBX5vUL1/+6ik\nX0LN6GZaZKhU+m8tlfRLqBNbJ9VCpfzeppu+raHQL6FObJ1UjQK/PFT101yq3pEha9UvbSnwy0tV\nP42nkr4MWac+uSy9R6X/xlHoy5C14t6ASvmSpbr/4VHoy5A1+96AAl8qUfgPjer0u0ir6tBFuonq\n/euj0O8irWxf3+wTTLXpq5Qv9UrCXyeAylS900Va2b7+rp9ezc3f+zZrVr8yrK6Pi1S6CazAl+FS\n1U8xhX4XaVYdeju6ZSg6gSnwpZEU/utT6EtuqfvAo09g5KhNmnZV0Y0PiEn3UpPPdRT6klvqbkco\nq5QvrVD20r9CXzqi1K3Al1Yra/gr9EWk1MpW9aPQl7aqp4S/bMVqrr7zcU44eFe2GDuqiUslZVWG\n0r/a6UvXuPrOxznjyjlcfefj7V4U6XG93N5fJX1pm3rr8U84eNdB/4s0Wy9W/Sj0pS2GcuN2i7Gj\n+OIxezRhaUSq65WqH1XviIjUodurflTSl5ZT80zpBd1a9aOSvrSUAl96UTeV/BX6IiIN0C3VPgp9\naZlGl/KXrVjNxT95kGUrVjd0uiLD0enhrzp9aYlmVOsk7fYBteqRjtOpdf4KfSnUji6X66F2+9It\nOqm5p0JfClX6oZN6NOvmrdrtS7fphNK/Ql8KNeKXutRaRyRfu0r/Cn0pNNwulxX4ItW1OvzVekdE\npAO0qtWPQl+aQqV8kaFpdvC3JCWDAAAEEElEQVQr9KXhFPginUuhLw2lwBfpbAp9aZhmBH7y1O2T\nC/r19K1IA6j1jnS05Knb2Q8v5I7fzAf09K3IcCj0pSGaVa2TPG172LsmMW33iXr6VmSYVL0jXWHz\nMRvzxWP26JkfRFdncdIuCn0ZtmbevO2IH0Mf/+aGj98R6yWlpOodGZZmt9ZpVKdqy1as5uo7H+eE\ng3et72ph/JvZYMpnCAtnE+bNrDq6TT4CmziNvz16BSx/onC8ZnQWN+R1lFJRSV+GrBXNM5NO1YYb\nYkMuWS9/grBwNjZxGjb5iIqjJoEfFs6uGPjQuPVK09WD1EIlfRmSbmuPP5ySdVLCt4nTBr1OSwd+\nLVcEzaCupqUWCn0pheF2w1wp+Dsh8EFdTUttVL0juQb6l3PbNVcw0L98vWHdUspvdAuZMG/melU9\nnRL4IrVSSV9yFf2ASrcEPjTn5xTTJf61pX4FvnQRhb7kyvsBlW4KfGheHXeYN3Nt4CevRbqFqnck\nV/IDKp3427i1akYLGWC9VjzVWvXk0cNZ0i4KfalJt5XymyVdh/+3WZ+vuTlnVqXmlTohSDOpekeq\n6tTAb/XDSHk3bWtpzpmnUtVTM+5FiCQU+tK1WhmOlVrpDCX4KzWvVHt7aSaFvlTUqaV8aF041tIs\nc6gl/jxqby/NpDp9KdTJgQ/Nu1E7yPg319wOP92Ov+5O2ppE9wckSyV9ydXpgd8yy5+o2nlaWpg3\nk7B8bs3jN5vuD0iWQl+kmnoDvEMCH3R/QNan0Jf1qJTfO3R/QLJUpy+DKPBFeptCX9ZS4K+v12+E\n9vr6yfoU+gIo8ItcNvMRzrhyDpfNfKTdi9IU+uGV8lGdvkglIfN/j9GN3vJR6ItK+RWcfOTbGD1q\nRM+Gom70lo9CX6QChaL0GtXpl5xK+SLlotAvMQW+SPko9EtKgS9STgp9EZESUeiXkEr5IuWl0C8Z\nBX7n01Oy0kwK/RJR4HcHPSUrzaR2+iIdRk/JSjOppF8SKuV3j5b8ItgQqNqpNyj0S0CBL42gaqfe\noOodEamJqp16g0K/x6mUL42ifoh6g6p3epgCX0SyFPo9SoEvInkU+iIiJaLQ70Eq5YtIEYV+j1Hg\ni0glCn0RkRJRk80eoRK+iNRCJX0RkRJR6PcAlfJFpFYK/S6nwBeReij0RURKRKHfxVTKF5F6KfS7\nlAJfRIZCod+FFPgiMlQKfRGRElHodxmV8kVkOBT6XUSBLyLDpdDvEgp8EWkEhb6ISIko9LuASvki\n0igK/Q6nwBeRRlLoi4iUiIUQmjdxs6XAs02bgYhIb9ohhDChGRNuauiLiEhnUfWOiEiJKPRFREpE\noS8iUiIKfRGRElHoi4iUiEJfRKREFPoiIiWi0BcRKRGFvohIifx/as8bJZ7Iv+4AAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111fdfa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_digits: 3, \t n_samples 60, \t n_features 12\n",
      "__________________________________________________________________________________\n",
      "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "k-means++\t0.38s\t483\t0.485\t0.538\t0.510\t0.366\t0.468\t0.301\n",
      "random   \t0.32s\t483\t0.485\t0.538\t0.510\t0.366\t0.468\t0.301\n",
      "PCA-based\t0.00s\t483\t0.483\t0.539\t0.509\t0.362\t0.465\t0.304\n",
      "__________________________________________________________________________________\n",
      "(60, 3)\n",
      "(60,)\n",
      "(60,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nylLGwtIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a170c5e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_digits: 3, \t n_samples 60, \t n_features 12\n",
      "__________________________________________________________________________________\n",
      "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "k-means++\t0.35s\t564\t0.483\t0.551\t0.515\t0.363\t0.466\t0.323\n",
      "random   \t0.27s\t564\t0.483\t0.551\t0.515\t0.363\t0.466\t0.323\n",
      "PCA-based\t0.00s\t631\t0.422\t0.549\t0.478\t0.427\t0.401\t0.318\n",
      "__________________________________________________________________________________\n",
      "(60, 3)\n",
      "(60,)\n",
      "(60,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyP8AxN0U+bd9PewAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105c650d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_digits: 3, \t n_samples 60, \t n_features 12\n",
      "__________________________________________________________________________________\n",
      "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "k-means++\t0.32s\t596\t0.416\t0.542\t0.471\t0.408\t0.395\t0.312\n",
      "random   \t0.25s\t596\t0.416\t0.542\t0.471\t0.408\t0.395\t0.312\n",
      "PCA-based\t0.00s\t597\t0.484\t0.623\t0.545\t0.463\t0.465\t0.309\n",
      "__________________________________________________________________________________\n",
      "(60, 3)\n",
      "(60,)\n",
      "(60,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XuYHVWd7vHvLyTmArkQEq7hckJG\nbmP0AIeIBIOSAYIEDTIKKgQEBA8cRkWuKkQGRA4M4hwYQfDhMoxoQOEAQ+ZAHBMMKGiYgAMBCTGY\nQBISCOkQkkCYdf74requruxL7e7evXfvej/P00/37qpdtap21VurVlWtbSEERESkGPo1ugAiItJ7\nFPoiIgWi0BcRKRCFvohIgSj0RUQKRKEvIlIgCv0KzGyemZ3SBOU4zMyea3Q5amVmk81sSZ2mPc7M\nQur1I2b2xZzvzT1ud8rUl5jZp8zs3kaXo6vqua1VmGdNn7eZ3WVmM+pUlm+Y2RV5xq0a+ma2xMwm\np16fYGZrzGxSdwpZFGZ2upnN6c40QghzQgj79VCR6sLM+ptZMLM9GjH/EMIRIYR/qXXcnvh8uqK3\nQqqG+VwJfD++J/ks15vZ22a2zMyuMbP2vDCzk8xsfhxnuZn9q5l9LDPv0+N0juvRhSqALlQ4bwJO\nNbPtqo1YU03fzKYDNwKfCiHMreW90jVm1r/RZZDWZmYHAwNDCH/IDNovhLANcAQwHfhyHP8C4Frg\n74HRwO7Aj4FPZ94/HXgz/q6lPNrmaxRCeAd4BDgpz8gVf4AlwGTgK8Bq4MAq488DLgd+B6wH7ge2\nA+4G2oAngd1S4+8LzMY3jheAz6aGHQssANYBfwG+kxo2DgjAycAyYBVwUWr4R4Gn4zxXAtdUKPNx\ncT5twCLgiNSynBL/vgK4PTv/1OvT4rpaBywGTgA+BGwE3gfeBlbHcQcB1wFLY9n+CRgUh02O07kE\nWAHclvwvNa9lwDeAPwJr47odmBp+cXzvq8AZcT3tUWbZxwAPxfX/EvDl1LAr4rTvisv1n8D+Zabz\nRJzP+risn00tywXx83kNODn1nrLrocT0twJ+ALwBvAyck1n/6c9qK+D6OO5i4H+VGrfC53MMsDAu\n8zLg610s0+mp6bwMnB7/PxzYAPxXnO/bwPbAwfh+8xawHPhHYEB8T7/4+vX4mT8L7FtpPZabT4nl\nuBy4KfW6f3abAe6L63Rb4B1gWpUcGBvnezzwLjC6yvjLgPPxbfrd1LZ5X9x2/gycnRp/CPDPwBrg\nOeBC4j5Spvx3ATNy7PMj8H1ueSzT5UC/PJ93iWU6gI78uhu4JykDnokPx2VbAzwI7BKHXY1vkxvj\nZ3Z9/P8NsUxtwO+Bj2XmNx14tGqmVx3Bd9pfxI3pwznGnwf8KX7o2+JB/iLwifhh/BS4JY47FA+m\nk+OwA+IK3SsO/yTw1/gG/2H8oHNMOnTx05pBwP7AJuCv4vDfAyem5jOhTHk/hu9kh8f57Jqaf67Q\nB4bhO2Iy753o2CFPB+Zk5nkDvjFvG9/7MPD3oSP0NwPfAz4ADKZ06P8O2DFuPH+iI1COwcN1H2Dr\nuLFVCv3Hgf+TWoergUmpZd4AHIlv8NcA88pMp9SOlizLZcAA/CC+HhhWbT2UmP45+M49Ji7zY5QP\n/XPwA9QuwEjg1xXGLfX5rCLuUPH95Q501co0Fd8PDN+WNwDjU+tmSWZ6/wOYENfl2Pi5nhOHfQp4\nCg/yfnhlacec29OSUuVPzfc+Uge27GcJ7IcfbKbH7etdYKsq0/wu8ET8eyFwbpXxlwHz47ocHLe3\nBXjl5wP4/rYEODyOfy0wJy7z7sDz5Ax9Ku/zD+EHzSH4/jUfOC3P551ZnoFxmc7Ft/0TgPdSZRgN\nTIvLOgz4JXBvqW009b+T8O2xP36Qe5XOlb2DgNerZnTVEXxFtwH/l3jEqzL+PODC1OsfAg+mXk8D\n/hD//iLw68z7fwJ8q8y0byDW2OkI/R1Tw58Gjo9/PwFcCmxXpbw/ocxZALWF/ltx2QZlptEpVOJG\nthHYPfW/Q4GXUjvpRuADqeGlQv+E1OvrgBvi33eSCk5gb8qEPvDf4oa4dep/1wC3ppb531LDxgNv\nl1lX5UL/bVIBgZ9RHFhtPZSY/mPEA1t8fTTlg/wx4o4aXx9VYdxSof9a/P/QKttOxTKVGP8hYm01\n+5mWGf+bwD3x7yPwCtQEUvthzu2p2nx+nVmO5LNsi9v1IjzEDQ/+ZVWmZ/gZVnLA+g4wv8p7ltH5\nLPAQYHFmnO/QUWH8CzA5Nex/kj/0S+7zeCVhA52D9CRi7bmWzxs/yC8FLPW/p0idbWTGPxBYVWob\nrbCO1+FNcMn/9iGeJVX6ydumfxbwQeBWM7Pkn2Z2a7zQ83Zs50usTP29ocTrbeLfuwOHmNlbyQ/w\nebymjJkdbGZzzGyVma3Fd8RR6YKFEFakXr6TmvapeG3oRTN7ysyOLrNsu+Knal0WQmgDTgTOBlaY\n2UNm9sEyo++I1wKeSS3zQ/jpfWJlCOHdKrMtt9w74xtbIv131s54k8b61P9ewTf+cvPZukq5slaH\nEN4vUdY86yFb1vSyvFJhnrWsg1Km4Wclf4nb34SulMnMjjGzJ83szbh8R5DZfjPj7x0viK4wsza8\naWEUQAjhEfys9kfASjO7ycyGUvt6LGUNfjacNT6EMCKEMC6EcFnwZHkD2D59UbeEj+P71cz4+qfA\n/mb213E5H0nlxudT70uvy92B3TLZcEFcXvCMyLs9ZJXb53fH1+XK1DxvBHaIw2vdBpfFdbbF+Ga2\ndczPv8TP+t+psG3E91xgZi/ELFyD74vp9wzFD9IV5Q391/FToUPxUx8AQginhxC2iT//O+e00pYC\nv4obVvKzTQjhnDj8Z3jT0q4hhOHArfgRrqoQwoshhBPwjf8fgF+Y2aAyZdgzxyTX46d8iR3TA0MI\ns0IIk/GNcRFwczIoM52V+OnxXqllHh6XjzLvqcVy/PQzsWuFcV8DRplZOsh3w08ba1VrmfOsh7Tl\ndF6W3SpMu5Z1sEW5QwhPhhCOxbedh/DtsKYymdlg4F7gKmCHEMII/EJbsv2WWl83481S40IIw/Az\n1fbtPYRwfQhhf7zJc1/8uk619Zjnc3kWr9Tl8TjeZHdshXGm49nyrJmtiO8JeDMuwe+eSnLj56n3\npcu6FD9bSWfD0BDC1Dh8BWXWfQhhM97UW25/LbfPL8UrJSNT8xwWQhgfh3dnG8yOfwF+pn1Q/Kw/\nmRm30+dmZp/AP+/P4tcdtsXPotN5uA/wTIUyATXcvRNCeC0W7Cgz+0He91XxALCfmX3BzAbEn4PM\nbK84fCjwZghho5l9FG8XyyXeUjYqhPBfeHt7wC8sZf0EON3MPmFm/cxsTGr+aQuASWa2q5mNAC5K\nzWsnM5tqZkPwHXA9fiEGfKccY2YDAGKt91bgejMbbW6MmR2Rd9mqmAmcZmZ7xfJ8p9yIIYQ/A38A\nvmdmA83sI/gZUq5bHzPTeh+vBY6tYfxa1sNM4Gtmtku8Le3CCpNPxt3ZzLbFLxCW0+nzMbPBcXsc\nFkJ4Dz+Ffr/MeyuVaSDeFr0KeN/MjsErTun5joq19cRQfFtdb2b7AGcmA+J+cVC8s2U9vp29n2M9\nlppP1sPApArD24UQ1uBNPT8ys2Pj+hpgfp//9+M2dzx+Y8NHUj9fB75kZlvlmQ/wW+BdMzvPzAaZ\n2VZm9iEzOyAOnwlcYmYjzGw3vL097Rngi/F9nwImpoaV3OdDCEuBucC1ZjYsDhtnZh9PzTPvNjgP\n6Gdm55jfAvu3+DWzxFD8ALMmTuvSzPtX0nlfGoofbFfj1whmsOVZ9yRgVoUyATXeshlXyieB483s\nqlreW2Z6a/GLhF/Cj4wr8JrRwDjKV4GrzGwdfkFnZqnplHE0sDC+91rg86WaTEIIT+B3uPwjvsP9\nmtI1w3/DL3j9EW+beyA1bCs8WJbjwfcxOjbCR/G7YlbGWg/Aefip3lNxno8Af1XDspUVQngQbwJ4\nLM738ThoU5m3fD7OewVeM70khPDrLs7+MuCn8dQ4z73ZtayHHwG/wtf/72NZy/kRfpHvj/iFuH/F\nQ7KUUp/PdOCVeNp9GuVvgytbphDCW3jQ3YdfxzgeP2tIhv8nfha7JK6v7fH1MR0/0NwMpGvBI/Cw\negu/zrYcv5MEKqzHMvPpJITwFLApFagVhRCuxgNvBr69L8X31fvxu2LWAXeFEFYkP8At+EXLv8k5\nj834PnxQXN7V+DoZFke5LK6DJXjQ3ZmZxLl4M91bwN+S2l+r7PNfwsP0ebwJ5R46zhJyb4MhhE1x\n/mfE6RyHr5/EdfhF+Tfw64/ZsL4eODF+ZtfhB+bZ+La6BL/esjwZOZ5ZHlViPWzBOjc5Sasxsw/h\nF7gHxrOewjGzqfhtb3ma8QrJ/JrXl0MIxze6LFI7M/s6flvsJVXHVei3HjObhtduh+JH/g1F2pnj\nNYpD8Vr8Tnhte24I4ZsNLZhIE1DfO63pbPx0+CX8dr6zG1ucXmd4twJr8eadZ/F2aJHCU01fRKRA\nVNMXESkQhX4LMbNLzOzWCsM79ZhaBObdUi/roWndbjm7r60wjWqf0SlmNq878ygz3WBm48oM+6KZ\nPdLT85TmpNCvUbyH+w/mTxMuN7NZZjax+jurTneGmd3VnWmEEL4XQji9u2WR+kl/Rma2RwzjhvYq\nGUL4lxBC+/MRlQ4Q0vcp9GtgZt/A75/9Hv5o9m74E8rZLmXrMW+zyo++N1yzlbHRYSqV6fNpjKbZ\nQZudmQ3H+0I5O4TwyxDC+hDCeyGEB0MI58dx+pnZRWb2spm9YWYzzWxkHJbU6qab97ex2sy+FYcd\nhT989vl4BvFM/P8cM7vSzB7Hn94ba/6U6QPm/bksMrMzUmXsdLZg/lTyK7Es38osz0HxjKXNzFbG\nB0BKLfe25n0JrTL/8pyHzGxManipMg43s5/EM6FXzewKK/MkZizzPebfKrTOzP5oZh80s4vN7HUz\nW2qpp3TN7FQzWxjHXWxm6adWDzP/wo8LzR+0uq3E/M41s+eTZTDvH2dBfAjmCTMbnxr3v5vZ03Fe\nP8d7Ii0prucD4t9fip/1vvH16WZ2f4nP6LH4+634uR+cmt61cX3/2cymlJnnqWb2YOr1IjObmXq9\n1Pwp68RkM3spTvdGM+9Hy1JNSmaWlOkZS/WNU2k9lSjXfmb2aNxGV5rZJallvzd+1m3AKeZPgl9v\nZq/Fn+vNbGAcf1Tc3t6K0/qNxUpF/IxfjZ/Ni2Z2eLnySEa1Htn0096D3VH4Y9D9K4zzNbzL4zH4\nU8U3A3fHYXvgXUEkTyZ+GH9Kdp84fAb+FGN6enPw3gT3w3sOHIA/Jp70l/4R/DH/w7PTwPtmeRvv\n/Gog/gTgZmLPhPhj7ifFv7cBPlpmmbbD+/sYgt/3fw9wf5Uy3h+XfWu8/5qngDPLTH8GflvpkfH9\nd+J9p38rTusM4M+p8T+F95ti+GPn7xC7PgYOi8t4dVzmwfF/y+Lw7+APqo2Or/fH+5WagD9VPR1/\n2jHpQuEV/KnaAfgTte8BV5RZjjuB8+LfP8Y79PpqatjXS3xGyTbRPzWdU+J8zohl+ireR5KVmOdY\n/InTfvjzCK8Ar6aGraGjL/iAPxE8Aj9DXQUclZrnvNR0A97/D9XWU4kyDcWfFD0P30bbuzWPy/4e\n8JlY5sF0fPfG9nh3w0/Q0S30VXgncwPiz6Hxc98Lfwp459R63LPRGdFXfhpegL7yg3cDvaLKOAuJ\nARxf7xQ38v6pHXxMavhTxC6SKR/6l6de74r3AzM09b+riF0+ZwLlUuBnqfG2xrsiSEL/Mfze9VE1\nroePAGsqlHEH/GA2OPW/E8l0oZ0aNoPUFz/gfdC3d8ccQyMAI8q8/37g7+Lfh8VlHJQafhjegdx1\neH8ow1PDfkSm/378ux8m4QfLTmEbA6lc6J8GPJDaDk5P1j8exvunlrda6C9KvR5CpgvxzHyX4qF8\nAn6weQrvTvvUpDxxvABMTL2eSfzSIaqHftn1VKI8JwL/UeGzfizzv5eBo1Ovj6Sji+TL8S7dx2Xe\nMw4/CE0mfsmMfvL/qHknvzfwjqsqtUPuDtxnHd2yLsRDeofUOOW6RC4n3ZXrzngHdOtS/8t2hZwe\nt/29wbtPfiM1/DS8Z8UXzOz35h2CbcHMhpjZzbH5og0/WIzINNdku8QdACxPrYebqdzVb7br7XR3\nzBvi721ieaaY2e+so7vio+ncveyqEMLGzPRH4N/8dlXw/p7SZT3POnffuyu+7nbGa80lu8YtYS5w\nqJntiNeGf453G74H3sfKggrvzWrfRoJ/DR6U307m4ge2j8e/5+AHrUnxdcnpkm/bS1RaT1nVuirP\ndnO9M53X6yup6V6D91j7SGzKuwgghLAIP6ueAbxuZj8zs1JlkRIU+vn9Fm+G+EyFcZYCU0Ln7mAH\nhRDydFVc7im59P9fA0Za5x4Ty3WF3KkbWPPeD9u/NDmE8FII4UQ8jK8G7rXOXSwnzsNPpycE7wI2\n6XEw3aVrtkvcTfgZRLp72m5/sXts6/0F3oFe0l3xwxXKkliDf+PTbWZ2SKasV2Y+ryEhhLvx9bdL\n0u4dle1KNwbRO3hHX4/FA/MK/GAzL5Tu96gnnoxMQv/Q+Pdcyod+V1VaT6XGrdTHUXaZX8MPKond\n4v8IIawLIZwXQhiLnwF+I2m7DyH8NIQwMb434Nuw5KDQzynWEC8FbjSzz8Qa8IBY80y+S+Am4Eoz\n2x3AvKvbvHf2rAT2sAp3vwTv5fQJvOfRQfFi2mmU7gr5XuAYM5toZh8gftdnMjBebBwdwyj54oVS\nXQgPxWvbb5lflL6s0kKEEJbjvTz+g3V0T7unmeXqureKD+Dt7auAzfECZ64uqUMIc/Amuvus40tR\nbgHOMrMJ5rY27yJ4KH6Q3wyca9417nF4j4+VzMV7V03Cdk7mddYqvLvvXN1RV5jnJ/DmtGXAb/Dr\nT9sB/9HFaWa79a20nrIeAnY0s6/Fi7RDrfyX0IB/nee3474yCt/H7oL2i8fj4oG3Dd8+3zfvNvyT\nsRKwEd8+y3V/LRkK/RqEEK7Dv8jg2/gOuxTfqZMuU3+Id+H6iHmXzr/DL37lcU/8/YaZPV1hvBPx\ntuDX8I7ELgshPFqirM/hfe78FK+1rsG/ki5xFPCcmb0dy31CiWYR8FtUB+N9+fwO72K6mpPxgE66\np72X+G1o3RFrz+fi7dFrgC/QuYvrau9/lNjWbWYHhBD+gF8wvSFObxHevk3wbriPi6/X4F1Q/7LK\nLObiB8nHyrzOlucdvI+gx2OzyUfzLktqGn/Cr4H8Jr5uw7+q8PHQ+RvLajEDuCOW6XOV1lOJ8qzD\nu0+eip/pvIQflMq5Av9Oh2fxLoufjv8D7x56dly+3wL/FA/eA4Hv49vkCvxstWrvkuLU946ISIGo\npi8iUiAKfRGRAlHoi4gUiEJfRKRAFPoiIgVS117uhg3sH7bfZkA9ZyEi0nJefnPj6hDC6HpMu66h\nv/02A7juyD3qOQsRkZbz6btfqNTlR7eoeUdEpEAU+iIiBaLQFxEpEIW+iEiBKPRFRApEoS8iUiAK\nfRGRAlHoi4gUiEJfRKRAFPoiIgWi0BcRKRCFvog0lbZNm/nlwjdo27S50UVpSQp9EWkqsxev5Y4F\nq5i9eG2ji9KS6trLpohIrSaPHd7pt/Qshb6INJVhA/tz3D7bNboYLUvNOyIiBaLQFxEpEIW+iEiB\nKPRFRApEoS8iUiAKfRGRAlHoi4gUiEJfRKRAFPoiIgWi0BcRKRCFvohIgSj0RUQKRKEvIlIgCn0R\nkQJR6IuIFIhCX0SkQBT6IiIFotAXESkQhb6ISIEo9EVECkShLyJSIAp9EZECUeiLiBSIQl9EpEAU\n+iIiBaLQFxEpEIW+iEiBKPRFRApEoS8iUiAKfRGRAlHoi4gUiEJfRKRAFPoiIgWi0BcRKRCFvohI\ngSj0RUQKRKEvIlIgCn0RkQJR6IuIFIhCX0SkQBT6IiIFotAXESkQhb6ISIEo9EVECkShLyJSIAp9\nEZECUeiLiBSIQl9EpEAU+iINNnr8xLqOL5Km0BdpoNHjJ3LwRbew30kX5xp/v5Mu5uCLblHwS5cp\n9EUaaNWz83h51p3sOeXkqsG/30kXs+eUk3l51p2senZeL5VQWk3/RhdApOie++erANhzysmdXqel\nA7/UcJG8FPoiTaBS8CvwpScp9EWaRKngV+BLT1PoizSRdPAn4a/Al56kC7kiTSYb8Ap86UkKfWlq\nbZs288uFb9C2aXOji9Jrsnfx5L2dUyQPhb40tdmL13LHglXMXry20UXpFek2/Ae+sE/u2zlF8qpr\nm/6IUcPqOXkpgMljh3f63cpKXbTNczunSC3qfiH3mK8c2f73Qz/+f/WenbSYYQP7c9w+2zW6GHVX\n6S4dBb/0pF69eyd9AAAdBEQg3334Cn7pKQ29ZVNnAVJ0o8dPzH0ffjr4X3/mN+qKQbrEQgh1m/iB\ne+0Qnrr5xJrfpwOAFMno8RNrCvBax5e+59N3vzA/hHBgPabdlA9n6QygNbVt2szsxWuZPHY4wwY2\n5abXELUGuAJfuqPp9zwdAFpHcvslUIiLsyLNqOlDP00HgL6tSLdfijSrPhX6aToA9D1Fuf1SpJn1\n2dBP062gIiL5tEToZ+ksQESktJYM/TQdAEREOrR86KfpACAiRVeo0E/TdQARKaLChn6WzgJEpAgU\n+iXoACAirUqhX4UOACLSShT6NdABQET6OoV+F+lCsIj0RQr9HqKzABHpCxT6daADgIg0K4V+nekA\nICLNRKHfi3QdQEQarV+jC1Bkx3zlyC0OBCIi9aSafhPQGYCI9BaFfhPSdQARqReFfpPTWYCI9CS1\n6fcxug4gIt2hmn4fpSYgEekKhX4LUBOQiOSl0G9BOgsQkXIU+i1OBwARSVPoF4gOACKi0C8oXQcQ\nKSaFvgA6CxApCoW+bEEHAJHWpdCXinQAEGktCn3JTdcBRPo+hb50mc4CRPoe9b0jPUJ9Aon0Darp\nS49SE5BIc1PoS12pCUikuSj0pdfoLECk8dSmLw2j6wAivU81fWm4UsGvswCpRdumzcxevJbJY4cz\nbKBirRLV9KUp6SxAajF78VruWLCK2YvXNrooTU+HRGlqug4geUweO7zTbylPoS99SnIQUPhL2rCB\n/Tlun+0aXYw+QaEvfZLOAES6RqEvLUHPA4jko9CXlqMDgEh5Cn1paWoGkp6w/vxHe3eGd+9at0kr\n9KVQjvnKkfx8+DcbXQyRhtF9+iIiBaLQFxEpEIW+FIqadqToFPoiIgWi0JfCUC1fRKEvIlIoCn0p\nBNXyRZxCX0SkQBT6IiIFotCXlqemHZEOCn0RkQJR6EtLUy1fpDOFvohIgSj0pWWpli+yJYW+iEiB\nKPSlJamWL1KaQl9EpEAU+iIiBaLQl5ajph2R8hT6IiIFotCXlqJavkhlCn0RkQJR6EvLUC1fpDqF\nvohIgSj0RUQKRKEvLUFNOyL5KPSlz1Pgi+Sn0BcRKRCFvohIgSj0pU9T045IbRT6IiIFotAXESkQ\nhb70WWraEamdQl/6JAW+SNco9JvFyL3rO76ICC0Y+qvXbuDan81n9doNfWfaI/em3/izsHHTco1u\n46bRb/xZCn4RqVnLhf7ts57nwpvncfus53O/J2+Yd2Xaueb35guEZXOxMZOqBr+Nm4aNmURYNhfe\nfKFb5eir1LQj0nX9G12AnnbKlH07/c4jCXOAb55wAODBfPus5zllyr6MGj644rRLjVvr/MKi+wCw\nMZM6vU5LB36p4V0tj4gUR8uF/qjhg9uDNK9SYZ4E8/qN77H1oAHtAVpq2ukQP2XKvlUDt9zBo1Lw\nZwO/UrCXOqjUUyMOMm1r3mTuAzOZdOznGLbtyF6Zp0graLnQ74pRwwdvEdZJIK/f8F7VAE2HeK2B\nmwTm1EPG8uDjizllygZG0zn4S9XwK82nK2c73dGbB5mkaWfuAzO5+4dXAjB1+ll1nadIK1HoR9ng\nSoL/xvue4dKTJ1QM0PQZQKXATQJ+/cb3uPyOJ9v/f+HN85i7YBkPP7nE5z/8PjZs2syQPQ/vCP9M\nk052Ptnadm/U8MuVpZLunBWk2/InHfu5Tr9FJJ+Wu5BbSaULtqdM2Zerz5y4RRPP5Xc8ydaDB5QN\nqOw0k8AtNX77gSXApdMnsH7De0w9ZCxXnzmRa8/+eKf533DNjE7vzbbhp4P92p/N58b7numRi8y1\nSJYdKLvMWT11MXzYtiOZOv0sNe2I1KhQNf1KzRClasfVarCr127g1Kse6aihV6hdr167gfUb3uPS\n6RM4e9qH28uy9eAB7e/bK/X+c86f0en9Nm5ayYu3yXQuPXnCFgetnlSqht6VZp2ebnpS275IbQoV\n+rUGTrVmkttnPc/DTy7h6Al7VJ3m7bOe5/I7n+TqMyd2umZQ6n02bhpDUm34SZs+bFnjT0+nWk27\nO00rScDPXbCM2y4+ouoylNPVpqdyt2kmbfsL5/+Ws777g/b/6SAgUlqhQr+n27prCdxsQJYry8Zd\npzJkzCTeeflXDFr6IFD5rp5alqkrNfP0hebkusPts55vb87pzWsHpUw69nMsnP9bFsz7d+Y+MBOg\nWxd4deYgra5Qod/Tagm9POMmNfzrr7+ed1/4RednBq74NuecP4Mhex4OlL6Pv5r0gWfLu4ZKH7jS\nB4rbLj6i/UyhlLxnErWecVR6GGvYtiM567s/aA/qRFcv8NZ6V5AOEtLXKPSbRNKE887Lv+LdF35R\n8pkBmMH53+5f8QGuSrIXf7e4a6jEQSl7NlOtuSvPmURP3+KZXNRNdOcWzlrvCip1kNCBQJqZQr8Z\njNy7/T78QUsfrHhBOd3UE95c2OWuGJJpTj1kLJM+MqZs7b2Ws5m8bfy9/RxBJdmAzh5Aqil1kNAz\nBNLMLIRQt4kfuNcO4ambT6zb9FvKyL1rC/Bax++j6t3PzoN33MTdP7ySE//uWz0W0MmB5IBJf8P8\nuY/mrvHvNHQgy9dtyj2fWseXvuML++86P4RwYD2mrZp+s6g1wAsQ+L2hHg95JWcLyQEFqtf4dxo6\nkMPGjebF19fx9Ktrq85j/12PMh1JAAACpUlEQVSGs9f2Q5mzaJWCX2qi0Jem1Ru9adbanFOLWg4o\ny9dt4sXX17HX9kMBKgZ/Evgvvr5OgS81K9QTuSL10LbmTR684yba1rzZ6f+1PjX89Ktr24N//12G\nlxwnHfh5zghEslTTl6bUl/rM78kLt0mQl6rxK/ClJyj0Rbqpp68LlAr+egS+bi0tJoW+SDfV47pA\nOviT8M8b+HnDXLeWFpNCX5pOX2raqaenX13bHvjJ6zzyhrm6py4mhb40FQV+h+zF3P13GZ4r+POG\neT3vXJLmpdAXaULZNvzkNVSv8SvMpRLdsinSZEpdtM1zO2d3lbv1VFqLavrSNNS0U/m2zEq3c/YE\nXdgtBoW+SJPIc1tmPYNfF3aLQaEv0gR2Gjow93346eBf3raxx7pi0LWAYlCbvjSFojftLF+3iTmL\nVuWuuT/96tqGdbamtv++TaEvDVf0wE/UGuD1DPxKwZ60/SdfTyl9i5p3RFpQd7tYqHRRV23/fZtC\nX6QFdfdOnErBrrb/vk2hLw2lpp366G5tXMHeuhT6Ii1IoS3l6EKuiEiBKPSlYdS0Iz1Jt5Lmo9CX\nhlDgS0/TraT5qE1fRFqCbiXNR6EvIi1BF6/zUfOO9Do17Uhf0KrXCBT6ItIn1TuUW/UagZp3RKRP\nqnf//616jUChL71KTTvSU+odyq16jUChL71GgS89qVVDud7Upi8iUiAKfRGRAlHoS69Q045Ic1Do\ni4gUiEJf6k61fJHmodAXESkQhb7UlWr5Is1FoS8iUiAKfakb1fJFmo9CX0SkQBT6IiIFYiGE+k3c\nbBXwSt1mICLSmnYPIYyux4TrGvoiItJc1LwjIlIgCn0RkQJR6IuIFIhCX0SkQBT6IiIFotAXESkQ\nhb6ISIEo9EVECkShLyJSIP8fMC7RSnCTK/gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a18ee7bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_digits: 3, \t n_samples 60, \t n_features 12\n",
      "__________________________________________________________________________________\n",
      "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "k-means++\t0.35s\t427\t0.523\t0.608\t0.562\t0.416\t0.507\t0.311\n",
      "random   \t0.31s\t427\t0.523\t0.608\t0.562\t0.416\t0.507\t0.311\n",
      "PCA-based\t0.00s\t427\t0.523\t0.608\t0.562\t0.416\t0.507\t0.311\n",
      "__________________________________________________________________________________\n",
      "(60, 3)\n",
      "(60,)\n",
      "(60,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a18f59b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 10\n",
    "CS_dct={}\n",
    "Cluster_dct={}\n",
    "\n",
    "for x in range(0,n):\n",
    "    random_selct(trans)\n",
    "    #CS_dct['arr%i'%x]=cluster_space\n",
    "    #Cluster_dct['arr%i'%x]=clusters\n",
    "    \n",
    "\n",
    "X=np.empty([60, 4])\n",
    "\n",
    "for key,value in CS_dct.iteritems():\n",
    "    X=(np.array(X) + np.array(value)) \n",
    "    \n",
    "final = X/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ALLOW_THREADS': 1,\n",
       " 'Axes3D': mpl_toolkits.mplot3d.axes3d.Axes3D,\n",
       " 'AxisError': numpy.core._internal.AxisError,\n",
       " 'BUFSIZE': 8192,\n",
       " 'CLIP': 0,\n",
       " 'CS_dct': {},\n",
       " 'Cluster_dct': {},\n",
       " 'ComplexWarning': numpy.core.numeric.ComplexWarning,\n",
       " 'DataSource': numpy.lib._datasource.DataSource,\n",
       " 'ERR_CALL': 3,\n",
       " 'ERR_DEFAULT': 521,\n",
       " 'ERR_IGNORE': 0,\n",
       " 'ERR_LOG': 5,\n",
       " 'ERR_PRINT': 4,\n",
       " 'ERR_RAISE': 2,\n",
       " 'ERR_WARN': 1,\n",
       " 'FLOATING_POINT_SUPPORT': 1,\n",
       " 'FPE_DIVIDEBYZERO': 1,\n",
       " 'FPE_INVALID': 8,\n",
       " 'FPE_OVERFLOW': 2,\n",
       " 'FPE_UNDERFLOW': 4,\n",
       " 'False_': False,\n",
       " 'GaussianMixture': sklearn.mixture.gaussian_mixture.GaussianMixture,\n",
       " 'Imputer': sklearn.preprocessing.imputation.Imputer,\n",
       " 'In': ['',\n",
       "  u'import numpy as np\\nfrom sklearn.cluster import KMeans\\nimport pandas as pd\\nfrom mpl_toolkits.mplot3d import Axes3D\\nfrom sklearn.preprocessing import scale\\n\\nimport sklearn.metrics as sm\\nfrom sklearn.metrics import confusion_matrix\\nimport matplotlib.pyplot as plt\\nimport matplotlib\\nfrom sklearn import datasets\\nfrom sklearn.preprocessing import Imputer\\n\\nimport seaborn as sns',\n",
       "  u\"data=pd.read_table('important_txt/4Kmeans.csv', sep=',')\",\n",
       "  u\"dudes = data[data['sex'] >= 0]\\nlady_dudes = data[data['sex'] >= 1]\",\n",
       "  u'var_names=list(lady_dudes.columns.values)',\n",
       "  u\"labels_true=lady_dudes['PDS'].values\\nf2=lady_dudes['pds_ht2_y'].values\\nf3=lady_dudes['pds_skin2_y'].values\\nf4=lady_dudes['pds_bdyhair_y'].values\\nf5=lady_dudes['pds_f4_2_y'].values\\nf6=lady_dudes['pds_f5_y'].values\\nf7=lady_dudes['interview_age'].values\\nf8=lady_dudes['anthroheightcalc'].values \\nf9=lady_dudes['anthroweightcalc'].values\\nf10=lady_dudes['anthro_waist_cm'].values\\nf11=lady_dudes['hormone_scr_dhea_mean'].values\\nf12=lady_dudes['hormone_scr_hse_mean'].values\\nf13=lady_dudes['hormone_scr_ert_mean'].values\\nX=np.matrix(zip(f2,f3,f4,f5,f6,f7,f8,f9,f10,f11,f12,f13))\",\n",
       "  u\"names=['pds_ht2_y',\\n'pds_skin2_y'\\n'pds_bdyhair_y',\\n'pds_f4_2_y',\\n'pds_f5_y',\\n'interview_age',\\n'anthroheightcalc',\\n'anthroweightcalc',\\n'anthro_waist_cm',\\n'hormone_scr_dhea_mean',\\n'hormone_scr_hse_mean',\\n'hormone_scr_ert_mean']\\nlen(names)\",\n",
       "  u\"get_ipython().magic(u'matplotlib inline')\\nplt.hist(labels_true)\\ny = np.bincount(labels_true.astype(int))\\nii = np.nonzero(y)[0]\\nzip(ii,y[ii])\",\n",
       "  u'import math\\nx=math.factorial(20)\\ny=math.factorial(20-10)\\nx/y',\n",
       "  u'import math\\nx=math.factorial(70)\\ny=math.factorial(70-120)\\nfact=x/y\\nprint(fact)',\n",
       "  u'import math\\nx=math.factorial(70)\\ny=math.factorial(70-20)\\nfact=x/y\\nprint(fact)',\n",
       "  u\"target_var=pd.DataFrame(lady_dudes['PDS'].values)\",\n",
       "  u'imputer = Imputer()\\ntransformed_values = imputer.fit_transform(X)\\n# count the number of NaN values in each column\\nprint(np.isnan(transformed_values).sum()) \\ntransformed_values_scale = scale(transformed_values)\\ntrans = np.hstack((transformed_values_scale,target_var.round(decimals=0)))',\n",
       "  u'\\ndef random_selct(DATA):\\n    dictr = {}\\n    levels = [\\'lev1\\',\\'lev2\\',\\'lev3\\']\\n    i=1\\n    for lev in levels:\\n        if i < len(levels)+1:\\n            dictr[lev] = DATA[np.where(DATA[:,-1] == i)]\\n            i=i+1\\n        else:\\n            break\\n\\n    rand_dict={}\\n    target_dict={}\\n    for key, value in dictr.iteritems():\\n        #print(key)\\n        #print(value.shape)\\n        ind = np.random.permutation(value.shape[0])#random index\\n        training_idx = ind[:20]#get 20 subjects indexes\\n        training = value[training_idx,:]#select 20 subjects from the value in the dictionary\\n        labels_true = value[:,-1] #get the labels from the value in the dictiornary last column\\n        target_dict[key] = labels_true[training_idx]#add targets to dictionary\\n        rand_dict[key] = training\\n\\n        #combine\\n    data=np.vstack((rand_dict[\\'lev1\\'],rand_dict[\\'lev2\\'],rand_dict[\\'lev3\\']))\\n    data=np.delete(data,12,1)\\n    targets=np.hstack((target_dict[\\'lev1\\'],target_dict[\\'lev2\\'],target_dict[\\'lev3\\']))\\n\\n    n_samples, n_features = data.shape\\n    labels = np.round(targets)\\n    n_digits = len(np.unique(targets))\\n\\n    ############################\\n    ####start the k meaning#####\\n    ############################\\n\\n    ### making a cute table################### making a cute table###################\\n    print(\"n_digits: %d, \\\\t n_samples %d, \\\\t n_features %d\"##########################\\n          % (n_digits, n_samples, n_features))### making a cute table################\\n    print(82 * \\'_\\')##################################################################\\n    print(\\'init\\\\t\\\\ttime\\\\tinertia\\\\thomo\\\\tcompl\\\\tv-meas\\\\tARI\\\\tAMI\\\\tsilhouette\\')########\\n    #################################################################################\\n\\n    def bench_k_means(estimator, name, data):\\n        t0 = time() #time\\n        estimator.fit(data) #estimating the fit \\n        print(\\'%-9s\\\\t%.2fs\\\\t%i\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\'\\n              % (name, (time() - t0), estimator.inertia_,\\n                 metrics.homogeneity_score(labels, estimator.labels_),\\n                 metrics.completeness_score(labels, estimator.labels_),\\n                 metrics.v_measure_score(labels, estimator.labels_),\\n                 metrics.adjusted_rand_score(labels, estimator.labels_),\\n                 metrics.adjusted_mutual_info_score(labels,  estimator.labels_),\\n                 metrics.silhouette_score(data, estimator.labels_,\\n                                          metric=\\'euclidean\\',\\n                                          sample_size=sample_size)))\\n\\n    bench_k_means(KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=300),\\n                  name=\"k-means++\", data=data)\\n\\n    bench_k_means(KMeans(init=\\'random\\', n_clusters=n_digits, n_init=300),\\n                  name=\"random\", data=data)\\n\\n    # in this case the seeding of the centers is deterministic, hence we run the\\n    # kmeans algorithm only once with n_init=1\\n    pca = PCA(n_components=n_digits).fit(data)\\n    bench_k_means(KMeans(init=pca.components_, n_clusters=n_digits, n_init=1),\\n                  name=\"PCA-based\",\\n                  data=data)\\n    print(82 * \\'_\\')\\n    \\n    kmeans = KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=300)\\n    ####THINGS TO SAVE#########\\n    kmeans.fit(data)\\n    y_kmeans = kmeans.predict(data)\\n    clusters = kmeans.fit_predict(data)\\n    cluster_space = kmeans.fit_transform(data)\\n    print(cluster_space.shape)\\n    print(clusters.shape)\\n    print(y_kmeans.shape)\\n    \\n        # #############################################################################\\n    # Visualize the results on PCA-reduced data\\n\\n    reduced_data = PCA(n_components=2).fit_transform(data)\\n    kmeans = KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=10000)\\n    kmeans.fit(reduced_data)\\n\\n    # Step size of the mesh. Decrease to increase the quality of the VQ.\\n    h = .02     # point in the mesh [x_min, x_max]x[y_min, y_max].\\n\\n    # Plot the decision boundary. For that, we will assign a color to each\\n    x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\\n    y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\\n\\n    # Obtain labels for each point in mesh. Use last trained model.\\n    Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\\n\\n    # Put the result into a color plot\\n    Z = Z.reshape(xx.shape)\\n    plt.figure(1)\\n    plt.clf()\\n    plt.imshow(Z, interpolation=\\'nearest\\',\\n               extent=(xx.min(), xx.max(), yy.min(), yy.max()),\\n               cmap=plt.cm.Paired,\\n               aspect=\\'auto\\', origin=\\'lower\\')\\n\\n    plt.plot(reduced_data[:, 0], reduced_data[:, 1], \\'k.\\', markersize=2)\\n    # Plot the centroids as a white X\\n    centroids = kmeans.cluster_centers_\\n    plt.scatter(centroids[:, 0], centroids[:, 1],\\n                marker=\\'x\\', s=169, linewidths=3,\\n                color=\\'w\\', zorder=10)\\n    plt.title(\\'K-means clustering on the digits dataset (PCA-reduced data)\\\\n\\'\\n              \\'Centroids are marked with white cross\\')\\n    plt.xlim(x_min, x_max)\\n    plt.ylim(y_min, y_max)\\n    plt.xticks(())\\n    plt.yticks(())\\n    plt.show()\\n\\nn = 10\\nCS_dct={}\\nCluster_dct={}\\n\\nfor x in range(0,n):\\n    random_selct(trans)\\n    CS_dct[\\'arr%i\\'%x]=cluster_space\\n    Cluster_dct[\\'arr%i\\'%x]=clusters\\n    \\n\\nX=np.empty([60, 4])\\n\\nfor key,value in CS_dct.iteritems():\\n    X=(np.array(X) + np.array(value)) \\n    \\nfinal = X/n',\n",
       "  u\"from sklearn.mixture import GaussianMixture\\nfrom sklearn.datasets import load_iris\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.svm import SVC\\n#X = iris['data']\\n#y = iris['target']\\n#kmeans = KMeans(n_clusters=6).fit(X)\\ndistances = np.column_stack([np.sum((training - center)**2, axis=1)**0.5 for center in kmeans.cluster_centers_])\\nsvm = SVC().fit(distances.astype('int'), training_target.astype('int'))\\nprint(svm)\",\n",
       "  u'import numpy as np\\nfrom sklearn.cluster import KMeans\\nimport pandas as pd\\nfrom mpl_toolkits.mplot3d import Axes3D\\nfrom sklearn.preprocessing import scale\\n\\nimport sklearn.metrics as sm\\nfrom sklearn.metrics import confusion_matrix\\nimport matplotlib.pyplot as plt\\nimport matplotlib\\nfrom sklearn import datasets\\nfrom sklearn.preprocessing import Imputer\\n\\nimport seaborn as sns',\n",
       "  u\"data=pd.read_table('important_txt/4Kmeans.csv', sep=',')\",\n",
       "  u\"dudes = data[data['sex'] >= 0]\\nlady_dudes = data[data['sex'] >= 1]\",\n",
       "  u'var_names=list(lady_dudes.columns.values)',\n",
       "  u\"labels_true=lady_dudes['PDS'].values\\nf2=lady_dudes['pds_ht2_y'].values\\nf3=lady_dudes['pds_skin2_y'].values\\nf4=lady_dudes['pds_bdyhair_y'].values\\nf5=lady_dudes['pds_f4_2_y'].values\\nf6=lady_dudes['pds_f5_y'].values\\nf7=lady_dudes['interview_age'].values\\nf8=lady_dudes['anthroheightcalc'].values \\nf9=lady_dudes['anthroweightcalc'].values\\nf10=lady_dudes['anthro_waist_cm'].values\\nf11=lady_dudes['hormone_scr_dhea_mean'].values\\nf12=lady_dudes['hormone_scr_hse_mean'].values\\nf13=lady_dudes['hormone_scr_ert_mean'].values\\nX=np.matrix(zip(f2,f3,f4,f5,f6,f7,f8,f9,f10,f11,f12,f13))\",\n",
       "  u\"names=['pds_ht2_y',\\n'pds_skin2_y'\\n'pds_bdyhair_y',\\n'pds_f4_2_y',\\n'pds_f5_y',\\n'interview_age',\\n'anthroheightcalc',\\n'anthroweightcalc',\\n'anthro_waist_cm',\\n'hormone_scr_dhea_mean',\\n'hormone_scr_hse_mean',\\n'hormone_scr_ert_mean']\\nlen(names)\",\n",
       "  u\"get_ipython().magic(u'matplotlib inline')\\nplt.hist(labels_true)\\ny = np.bincount(labels_true.astype(int))\\nii = np.nonzero(y)[0]\\nzip(ii,y[ii])\",\n",
       "  u'import math\\nx=math.factorial(70)\\ny=math.factorial(70-20)\\nfact=x/y\\nprint(fact)',\n",
       "  u\"target_var=pd.DataFrame(lady_dudes['PDS'].values)\",\n",
       "  u'imputer = Imputer()\\ntransformed_values = imputer.fit_transform(X)\\n# count the number of NaN values in each column\\nprint(np.isnan(transformed_values).sum()) \\ntransformed_values_scale = scale(transformed_values)\\ntrans = np.hstack((transformed_values_scale,target_var.round(decimals=0)))',\n",
       "  u\"#def random_selct(data):\\ndictr = {}\\nlevels = ['lev1','lev2','lev3']\\ni=1\\nfor lev in levels:\\n    if i < len(levels)+1:\\n        dictr[lev] = trans[np.where(trans[:,-1] == i)]\\n        i=i+1\\n    else:\\n        break\\n\\nrand_dict={}\\ntarget_dict={}\\nfor key, value in dictr.iteritems():\\n    print(key)\\n    print(value.shape)\\n    ind = np.random.permutation(value.shape[0])#random index\\n    training_idx = ind[:20]#get 20 subjects indexes\\n    training = value[training_idx,:]#select 20 subjects from the value in the dictionary\\n    labels_true = value[:,-1] #get the labels from the value in the dictiornary last column\\n    target_dict[key] = labels_true[training_idx]#add targets to dictionary\\n    rand_dict[key] = training\\n    \\n\\n\\n    # for\\n# ind = np.random.permutation(transformed_values_scale.shape[0])\\n#dictr['lev3'].shape\\nrand_dict['lev2'].shape\",\n",
       "  u'indices = np.random.permutation(transformed_values_scale.shape[0])\\n\\ntraining_idx, test_idx = indices[:721], indices[721:]#80 20\\ntraining, test = transformed_values_scale[training_idx,:], transformed_values_scale[test_idx,:]\\ntraining_target, test_target = labels_true[training_idx], labels_true[test_idx]\\n\\nplt.hist(training_target)\\ny = np.bincount(training_target.astype(int))\\nii = np.nonzero(y)[0]\\nzip(ii,y[ii])',\n",
       "  u'import numpy as np\\nimport matplotlib.pyplot as plt\\nfrom numpy import *',\n",
       "  u'fig, axes = plt.subplots(nrows=6, ncols=2, sharex=True, figsize=(18, 16))\\n\\ntitles = names\\n# axes.flat returns the set of axes as a flat (1D) array instead\\n# of the two-dimensional version we used earlier\\nfor ax, title, y in zip(axes.flat, titles, training):\\n    ax.hist(y)\\n    ax.set_title(title)\\n    ax.grid(True)',\n",
       "  u'print(__doc__)\\n\\nfrom time import time\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\nfrom sklearn import metrics\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.datasets import load_digits\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.preprocessing import scale',\n",
       "  u'n_samples, n_features = training.shape\\nlabels = np.round(training_target,decimals=0)\\nn_digits = len(np.unique(labels))',\n",
       "  u'\\ndef random_selct(DATA):\\n    dictr = {}\\n    levels = [\\'lev1\\',\\'lev2\\',\\'lev3\\']\\n    i=1\\n    for lev in levels:\\n        if i < len(levels)+1:\\n            dictr[lev] = DATA[np.where(DATA[:,-1] == i)]\\n            i=i+1\\n        else:\\n            break\\n\\n    rand_dict={}\\n    target_dict={}\\n    for key, value in dictr.iteritems():\\n        #print(key)\\n        #print(value.shape)\\n        ind = np.random.permutation(value.shape[0])#random index\\n        training_idx = ind[:20]#get 20 subjects indexes\\n        training = value[training_idx,:]#select 20 subjects from the value in the dictionary\\n        labels_true = value[:,-1] #get the labels from the value in the dictiornary last column\\n        target_dict[key] = labels_true[training_idx]#add targets to dictionary\\n        rand_dict[key] = training\\n\\n        #combine\\n    data=np.vstack((rand_dict[\\'lev1\\'],rand_dict[\\'lev2\\'],rand_dict[\\'lev3\\']))\\n    data=np.delete(data,12,1)\\n    targets=np.hstack((target_dict[\\'lev1\\'],target_dict[\\'lev2\\'],target_dict[\\'lev3\\']))\\n\\n    n_samples, n_features = data.shape\\n    labels = np.round(targets)\\n    n_digits = len(np.unique(targets))\\n\\n    ############################\\n    ####start the k meaning#####\\n    ############################\\n\\n    ### making a cute table################### making a cute table###################\\n    print(\"n_digits: %d, \\\\t n_samples %d, \\\\t n_features %d\"##########################\\n          % (n_digits, n_samples, n_features))### making a cute table################\\n    print(82 * \\'_\\')##################################################################\\n    print(\\'init\\\\t\\\\ttime\\\\tinertia\\\\thomo\\\\tcompl\\\\tv-meas\\\\tARI\\\\tAMI\\\\tsilhouette\\')########\\n    #################################################################################\\n\\n    def bench_k_means(estimator, name, data):\\n        t0 = time() #time\\n        estimator.fit(data) #estimating the fit \\n        print(\\'%-9s\\\\t%.2fs\\\\t%i\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\'\\n              % (name, (time() - t0), estimator.inertia_,\\n                 metrics.homogeneity_score(labels, estimator.labels_),\\n                 metrics.completeness_score(labels, estimator.labels_),\\n                 metrics.v_measure_score(labels, estimator.labels_),\\n                 metrics.adjusted_rand_score(labels, estimator.labels_),\\n                 metrics.adjusted_mutual_info_score(labels,  estimator.labels_),\\n                 metrics.silhouette_score(data, estimator.labels_,\\n                                          metric=\\'euclidean\\',\\n                                          sample_size=sample_size)))\\n\\n    bench_k_means(KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=300),\\n                  name=\"k-means++\", data=data)\\n\\n    bench_k_means(KMeans(init=\\'random\\', n_clusters=n_digits, n_init=300),\\n                  name=\"random\", data=data)\\n\\n    # in this case the seeding of the centers is deterministic, hence we run the\\n    # kmeans algorithm only once with n_init=1\\n    pca = PCA(n_components=n_digits).fit(data)\\n    bench_k_means(KMeans(init=pca.components_, n_clusters=n_digits, n_init=1),\\n                  name=\"PCA-based\",\\n                  data=data)\\n    print(82 * \\'_\\')\\n    \\n    kmeans = KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=300)\\n    ####THINGS TO SAVE#########\\n    kmeans.fit(data)\\n    y_kmeans = kmeans.predict(data)\\n    clusters = kmeans.fit_predict(data)\\n    cluster_space = kmeans.fit_transform(data)\\n    print(cluster_space.shape)\\n    print(clusters.shape)\\n    print(y_kmeans.shape)\\n    \\n        # #############################################################################\\n    # Visualize the results on PCA-reduced data\\n\\n    reduced_data = PCA(n_components=2).fit_transform(data)\\n    kmeans = KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=10000)\\n    kmeans.fit(reduced_data)\\n\\n    # Step size of the mesh. Decrease to increase the quality of the VQ.\\n    h = .02     # point in the mesh [x_min, x_max]x[y_min, y_max].\\n\\n    # Plot the decision boundary. For that, we will assign a color to each\\n    x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\\n    y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\\n\\n    # Obtain labels for each point in mesh. Use last trained model.\\n    Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\\n\\n    # Put the result into a color plot\\n    Z = Z.reshape(xx.shape)\\n    plt.figure(1)\\n    plt.clf()\\n    plt.imshow(Z, interpolation=\\'nearest\\',\\n               extent=(xx.min(), xx.max(), yy.min(), yy.max()),\\n               cmap=plt.cm.Paired,\\n               aspect=\\'auto\\', origin=\\'lower\\')\\n\\n    plt.plot(reduced_data[:, 0], reduced_data[:, 1], \\'k.\\', markersize=2)\\n    # Plot the centroids as a white X\\n    centroids = kmeans.cluster_centers_\\n    plt.scatter(centroids[:, 0], centroids[:, 1],\\n                marker=\\'x\\', s=169, linewidths=3,\\n                color=\\'w\\', zorder=10)\\n    plt.title(\\'K-means clustering on the digits dataset (PCA-reduced data)\\\\n\\'\\n              \\'Centroids are marked with white cross\\')\\n    plt.xlim(x_min, x_max)\\n    plt.ylim(y_min, y_max)\\n    plt.xticks(())\\n    plt.yticks(())\\n    plt.show()\\n\\nn = 10\\nCS_dct={}\\nCluster_dct={}\\n\\nfor x in range(0,n):\\n    random_selct(trans)\\n    CS_dct[\\'arr%i\\'%x]=cluster_space\\n    Cluster_dct[\\'arr%i\\'%x]=clusters\\n    \\n\\nX=np.empty([60, 4])\\n\\nfor key,value in CS_dct.iteritems():\\n    X=(np.array(X) + np.array(value)) \\n    \\nfinal = X/n',\n",
       "  u'print(__doc__)\\n\\nfrom time import time\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\nfrom sklearn import metrics\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.datasets import load_digits\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.preprocessing import scale',\n",
       "  u'\\ndef random_selct(DATA):\\n    dictr = {}\\n    levels = [\\'lev1\\',\\'lev2\\',\\'lev3\\']\\n    i=1\\n    for lev in levels:\\n        if i < len(levels)+1:\\n            dictr[lev] = DATA[np.where(DATA[:,-1] == i)]\\n            i=i+1\\n        else:\\n            break\\n\\n    rand_dict={}\\n    target_dict={}\\n    for key, value in dictr.iteritems():\\n        #print(key)\\n        #print(value.shape)\\n        ind = np.random.permutation(value.shape[0])#random index\\n        training_idx = ind[:20]#get 20 subjects indexes\\n        training = value[training_idx,:]#select 20 subjects from the value in the dictionary\\n        labels_true = value[:,-1] #get the labels from the value in the dictiornary last column\\n        target_dict[key] = labels_true[training_idx]#add targets to dictionary\\n        rand_dict[key] = training\\n\\n        #combine\\n    data=np.vstack((rand_dict[\\'lev1\\'],rand_dict[\\'lev2\\'],rand_dict[\\'lev3\\']))\\n    data=np.delete(data,12,1)\\n    targets=np.hstack((target_dict[\\'lev1\\'],target_dict[\\'lev2\\'],target_dict[\\'lev3\\']))\\n\\n    n_samples, n_features = data.shape\\n    labels = np.round(targets)\\n    n_digits = len(np.unique(targets))\\n    sample_size=n_samples\\n\\n    ############################\\n    ####start the k meaning#####\\n    ############################\\n\\n    ### making a cute table################### making a cute table###################\\n    print(\"n_digits: %d, \\\\t n_samples %d, \\\\t n_features %d\"##########################\\n          % (n_digits, n_samples, n_features))### making a cute table################\\n    print(82 * \\'_\\')##################################################################\\n    print(\\'init\\\\t\\\\ttime\\\\tinertia\\\\thomo\\\\tcompl\\\\tv-meas\\\\tARI\\\\tAMI\\\\tsilhouette\\')########\\n    #################################################################################\\n\\n    def bench_k_means(estimator, name, data):\\n        t0 = time() #time\\n        estimator.fit(data) #estimating the fit \\n        print(\\'%-9s\\\\t%.2fs\\\\t%i\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\'\\n              % (name, (time() - t0), estimator.inertia_,\\n                 metrics.homogeneity_score(labels, estimator.labels_),\\n                 metrics.completeness_score(labels, estimator.labels_),\\n                 metrics.v_measure_score(labels, estimator.labels_),\\n                 metrics.adjusted_rand_score(labels, estimator.labels_),\\n                 metrics.adjusted_mutual_info_score(labels,  estimator.labels_),\\n                 metrics.silhouette_score(data, estimator.labels_,\\n                                          metric=\\'euclidean\\',\\n                                          sample_size=sample_size)))\\n\\n    bench_k_means(KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=300),\\n                  name=\"k-means++\", data=data)\\n\\n    bench_k_means(KMeans(init=\\'random\\', n_clusters=n_digits, n_init=300),\\n                  name=\"random\", data=data)\\n\\n    # in this case the seeding of the centers is deterministic, hence we run the\\n    # kmeans algorithm only once with n_init=1\\n    pca = PCA(n_components=n_digits).fit(data)\\n    bench_k_means(KMeans(init=pca.components_, n_clusters=n_digits, n_init=1),\\n                  name=\"PCA-based\",\\n                  data=data)\\n    print(82 * \\'_\\')\\n    \\n    kmeans = KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=300)\\n    ####THINGS TO SAVE#########\\n    kmeans.fit(data)\\n    y_kmeans = kmeans.predict(data)\\n    clusters = kmeans.fit_predict(data)\\n    cluster_space = kmeans.fit_transform(data)\\n    print(cluster_space.shape)\\n    print(clusters.shape)\\n    print(y_kmeans.shape)\\n    \\n        # #############################################################################\\n    # Visualize the results on PCA-reduced data\\n\\n    reduced_data = PCA(n_components=2).fit_transform(data)\\n    kmeans = KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=10000)\\n    kmeans.fit(reduced_data)\\n\\n    # Step size of the mesh. Decrease to increase the quality of the VQ.\\n    h = .02     # point in the mesh [x_min, x_max]x[y_min, y_max].\\n\\n    # Plot the decision boundary. For that, we will assign a color to each\\n    x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\\n    y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\\n\\n    # Obtain labels for each point in mesh. Use last trained model.\\n    Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\\n\\n    # Put the result into a color plot\\n    Z = Z.reshape(xx.shape)\\n    plt.figure(1)\\n    plt.clf()\\n    plt.imshow(Z, interpolation=\\'nearest\\',\\n               extent=(xx.min(), xx.max(), yy.min(), yy.max()),\\n               cmap=plt.cm.Paired,\\n               aspect=\\'auto\\', origin=\\'lower\\')\\n\\n    plt.plot(reduced_data[:, 0], reduced_data[:, 1], \\'k.\\', markersize=2)\\n    # Plot the centroids as a white X\\n    centroids = kmeans.cluster_centers_\\n    plt.scatter(centroids[:, 0], centroids[:, 1],\\n                marker=\\'x\\', s=169, linewidths=3,\\n                color=\\'w\\', zorder=10)\\n    plt.title(\\'K-means clustering on the digits dataset (PCA-reduced data)\\\\n\\'\\n              \\'Centroids are marked with white cross\\')\\n    plt.xlim(x_min, x_max)\\n    plt.ylim(y_min, y_max)\\n    plt.xticks(())\\n    plt.yticks(())\\n    plt.show()\\n\\nn = 10\\nCS_dct={}\\nCluster_dct={}\\n\\nfor x in range(0,n):\\n    random_selct(trans)\\n    CS_dct[\\'arr%i\\'%x]=cluster_space\\n    Cluster_dct[\\'arr%i\\'%x]=clusters\\n    \\n\\nX=np.empty([60, 4])\\n\\nfor key,value in CS_dct.iteritems():\\n    X=(np.array(X) + np.array(value)) \\n    \\nfinal = X/n',\n",
       "  u'cluster_space',\n",
       "  u'cluster_space = kmeans.fit_transform(data)',\n",
       "  u\"kmeans = KMeans(init='k-means++', n_clusters=n_digits, n_init=300)\",\n",
       "  u\"n = 10\\nCS_dct={}\\nCluster_dct={}\\n\\nfor x in range(0,n):\\n    random_selct(trans)\\n    CS_dct['arr%i'%x]=cluster_space\\n    Cluster_dct['arr%i'%x]=clusters\\n    \\n\\nX=np.empty([60, 4])\\n\\nfor key,value in CS_dct.iteritems():\\n    X=(np.array(X) + np.array(value)) \\n    \\nfinal = X/n\",\n",
       "  u\"n = 10\\nCS_dct={}\\nCluster_dct={}\\n\\nfor x in range(0,n):\\n    random_selct(trans)\\n    #CS_dct['arr%i'%x]=cluster_space\\n    #Cluster_dct['arr%i'%x]=clusters\\n    \\n\\nX=np.empty([60, 4])\\n\\nfor key,value in CS_dct.iteritems():\\n    X=(np.array(X) + np.array(value)) \\n    \\nfinal = X/n\",\n",
       "  u'cluster_space',\n",
       "  u'ykmeans',\n",
       "  u'local',\n",
       "  u'locals',\n",
       "  u'locals()',\n",
       "  u'globals()'],\n",
       " 'Inf': inf,\n",
       " 'Infinity': inf,\n",
       " 'KMeans': sklearn.cluster.k_means_.KMeans,\n",
       " 'MAXDIMS': 32,\n",
       " 'MAY_SHARE_BOUNDS': 0,\n",
       " 'MAY_SHARE_EXACT': -1,\n",
       " 'MachAr': numpy.core.machar.MachAr,\n",
       " 'ModuleDeprecationWarning': numpy._globals.ModuleDeprecationWarning,\n",
       " 'NAN': nan,\n",
       " 'NINF': -inf,\n",
       " 'NZERO': -0.0,\n",
       " 'NaN': nan,\n",
       " 'Out': {6: 11,\n",
       "  7: [(1, 610), (2, 271), (3, 20), (4, 2)],\n",
       "  8: 670442572800,\n",
       "  20: 11,\n",
       "  21: [(1, 610), (2, 271), (3, 20), (4, 2)],\n",
       "  25: (20, 13),\n",
       "  42: <function locals>,\n",
       "  43: {...}},\n",
       " 'PCA': sklearn.decomposition.pca.PCA,\n",
       " 'PINF': inf,\n",
       " 'PZERO': 0.0,\n",
       " 'PackageLoader': numpy._import_tools.PackageLoader,\n",
       " 'RAISE': 2,\n",
       " 'RankWarning': numpy.lib.polynomial.RankWarning,\n",
       " 'SHIFT_DIVIDEBYZERO': 0,\n",
       " 'SHIFT_INVALID': 9,\n",
       " 'SHIFT_OVERFLOW': 3,\n",
       " 'SHIFT_UNDERFLOW': 6,\n",
       " 'SVC': sklearn.svm.classes.SVC,\n",
       " 'ScalarType': (int,\n",
       "  float,\n",
       "  complex,\n",
       "  long,\n",
       "  bool,\n",
       "  str,\n",
       "  unicode,\n",
       "  buffer,\n",
       "  numpy.uint64,\n",
       "  numpy.int64,\n",
       "  numpy.unicode_,\n",
       "  numpy.datetime64,\n",
       "  numpy.uint64,\n",
       "  numpy.int64,\n",
       "  numpy.void,\n",
       "  numpy.timedelta64,\n",
       "  numpy.bool_,\n",
       "  numpy.float16,\n",
       "  numpy.uint8,\n",
       "  numpy.int8,\n",
       "  numpy.complex64,\n",
       "  numpy.float32,\n",
       "  numpy.uint16,\n",
       "  numpy.int16,\n",
       "  numpy.object_,\n",
       "  numpy.complex128,\n",
       "  numpy.float64,\n",
       "  numpy.uint32,\n",
       "  numpy.int32,\n",
       "  numpy.string_,\n",
       "  numpy.complex256,\n",
       "  numpy.float128),\n",
       " 'TooHardError': numpy.core._internal.TooHardError,\n",
       " 'True_': True,\n",
       " 'UFUNC_BUFSIZE_DEFAULT': 8192,\n",
       " 'UFUNC_PYVALS_NAME': 'UFUNC_PYVALS',\n",
       " 'VisibleDeprecationWarning': numpy._globals.VisibleDeprecationWarning,\n",
       " 'WRAP': 1,\n",
       " 'X': array([[  0.00000000e+000,   3.00393120e-307,   6.94881468e-310,\n",
       "           3.33772113e-307],\n",
       "        [  2.33650410e-307,   1.89142313e-307,   1.89139427e-307,\n",
       "           3.00396684e-307],\n",
       "        [  1.89146387e-307,   7.50991287e-308,   1.37960351e-306,\n",
       "           1.89142313e-307],\n",
       "        [  2.11395258e-307,   2.78147983e-307,   2.78151718e-307,\n",
       "           1.20161050e-306],\n",
       "        [  1.89142313e-307,   2.04721462e-306,   2.31422349e-306,\n",
       "           1.89142313e-307],\n",
       "        [  1.02358083e-306,   2.13616190e-306,   1.78012428e-306,\n",
       "           1.89139257e-307],\n",
       "        [  2.22518420e-307,   4.89544090e-307,   1.00135538e-307,\n",
       "           2.67025839e-307],\n",
       "        [  1.29061006e-306,   5.11800261e-307,   2.55900300e-307,\n",
       "           2.55900470e-307],\n",
       "        [  1.11259736e-306,   5.34048283e-307,   5.11799921e-307,\n",
       "           2.22519779e-307],\n",
       "        [  4.22790177e-307,   2.11394919e-307,   1.33510679e-306,\n",
       "           2.04717931e-306],\n",
       "        [  1.95814105e-306,   8.90088960e-308,   1.95822797e-306,\n",
       "           1.42421024e-306],\n",
       "        [  1.95813698e-306,   1.95819945e-306,   9.79067130e-307,\n",
       "           1.89142313e-307],\n",
       "        [  2.89270806e-307,   4.67289277e-307,   1.78022477e-306,\n",
       "           1.33514363e-307],\n",
       "        [  1.39073822e-307,   3.56036263e-307,   4.22791534e-307,\n",
       "           4.22787460e-307],\n",
       "        [  1.27948622e-307,   9.45752306e-308,   1.37961166e-306,\n",
       "           5.56292231e-307],\n",
       "        [  1.24611334e-306,   1.39077047e-307,   4.00529592e-307,\n",
       "           3.78291755e-307],\n",
       "        [  1.51311677e-306,   4.22796967e-307,   1.78021119e-306,\n",
       "           1.33512308e-306],\n",
       "        [  1.29061074e-306,   4.89545448e-307,   1.24609229e-306,\n",
       "           2.55903865e-307],\n",
       "        [  3.33769228e-307,   8.90098297e-308,   8.01086345e-307,\n",
       "           8.90074361e-307],\n",
       "        [  2.33650410e-307,   1.33510679e-306,   2.89272164e-307,\n",
       "           1.33513089e-307],\n",
       "        [  2.55903526e-307,   3.33774660e-307,   5.56308189e-307,\n",
       "           1.27946076e-307],\n",
       "        [  9.79068488e-307,   7.56583510e-307,   2.13614153e-306,\n",
       "           3.56047807e-307],\n",
       "        [  3.22649290e-307,   2.55904205e-307,   2.13614560e-306,\n",
       "           1.06811354e-306],\n",
       "        [  1.11258650e-306,   4.00535703e-307,   1.02361207e-306,\n",
       "           3.33773811e-307],\n",
       "        [  5.34039795e-307,   8.45574921e-307,   8.01097210e-307,\n",
       "           2.78148323e-307],\n",
       "        [  2.33642432e-307,   1.20160711e-306,   2.22517707e-306,\n",
       "           2.04716709e-306],\n",
       "        [  5.78542630e-307,   9.34588740e-307,   5.11797205e-307,\n",
       "           3.44907159e-307],\n",
       "        [  1.11258446e-306,   5.11791773e-307,   3.11524600e-307,\n",
       "           4.22792893e-307],\n",
       "        [  1.00137576e-307,   7.50990863e-308,   2.67018200e-307,\n",
       "           1.24608889e-306],\n",
       "        [  1.33510679e-306,   5.78559267e-307,   7.50993409e-308,\n",
       "           1.33511137e-307],\n",
       "        [  4.45051440e-307,   2.31417324e-306,   5.78555193e-307,\n",
       "           1.86912723e-306],\n",
       "        [  4.89532207e-307,   1.60219306e-306,   1.51312356e-306,\n",
       "           2.31415287e-306],\n",
       "        [  3.22650648e-307,   1.42416542e-306,   1.05695762e-307,\n",
       "           2.31423571e-306],\n",
       "        [  2.13622708e-306,   1.69112268e-306,   3.33779413e-307,\n",
       "           7.50982799e-308],\n",
       "        [  8.45608873e-307,   3.33779583e-307,   1.06806737e-306,\n",
       "           1.33510883e-307],\n",
       "        [  2.22524362e-307,   1.16820452e-307,   2.00274303e-307,\n",
       "           2.00274303e-307],\n",
       "        [  2.44777477e-307,   1.69112947e-306,   1.42413690e-306,\n",
       "           3.11523412e-307],\n",
       "        [  1.27950999e-307,   3.22647423e-307,   5.56293250e-307,\n",
       "           1.05700600e-307],\n",
       "        [  1.60217133e-306,   8.90098806e-307,   3.00403135e-307,\n",
       "           1.33510679e-306],\n",
       "        [  1.89148084e-307,   3.56051881e-307,   3.11519677e-307,\n",
       "           1.00136642e-307],\n",
       "        [  1.78020440e-306,   1.60216047e-306,   1.27951848e-307,\n",
       "           1.69122182e-306],\n",
       "        [  1.27948368e-307,   2.31415015e-306,   7.51014204e-308,\n",
       "           7.51012931e-308],\n",
       "        [  1.86915439e-306,   2.22517979e-306,   1.42411653e-306,\n",
       "           1.89145878e-307],\n",
       "        [  8.45604799e-307,   1.33508981e-306,   5.11803656e-307,\n",
       "           5.11803656e-307],\n",
       "        [  1.51320369e-306,   1.24610248e-306,   1.11258277e-307,\n",
       "           2.00274302e-307],\n",
       "        [  1.95818179e-306,   4.00531629e-307,   1.39073143e-307,\n",
       "           1.20159217e-306],\n",
       "        [  1.27948283e-307,   2.33650241e-307,   2.22525041e-307,\n",
       "           3.33775339e-307],\n",
       "        [  3.11527996e-307,   2.00273454e-307,   9.79080032e-307,\n",
       "           3.56049165e-307],\n",
       "        [  3.33781280e-307,   2.04717660e-306,   1.33510679e-306,\n",
       "           2.18084067e-314],\n",
       "        [  2.27153626e-314,   2.18084067e-314,   2.27153628e-314,\n",
       "           2.18084067e-314],\n",
       "        [  2.27152241e-314,   2.18084067e-314,   2.27153633e-314,\n",
       "           2.18084067e-314],\n",
       "        [  2.27153640e-314,   2.18084067e-314,   2.27153643e-314,\n",
       "           2.18084067e-314],\n",
       "        [  2.27153645e-314,   2.18084067e-314,   2.27153647e-314,\n",
       "           2.18084067e-314],\n",
       "        [  2.27153650e-314,   2.18084067e-314,   2.27153652e-314,\n",
       "           2.18084067e-314],\n",
       "        [  2.27153655e-314,   2.18084067e-314,   2.27150855e-314,\n",
       "           2.18084067e-314],\n",
       "        [  2.27150896e-314,   2.18084067e-314,   2.27150922e-314,\n",
       "           2.18084067e-314],\n",
       "        [  2.27151009e-314,   2.18084067e-314,   2.27150827e-314,\n",
       "           2.18084067e-314],\n",
       "        [  2.27150829e-314,   2.18084067e-314,   2.27150832e-314,\n",
       "           2.18084067e-314],\n",
       "        [  2.27150834e-314,   1.02930033e+001,   1.01415004e+001,\n",
       "           8.27985037e+000],\n",
       "        [  7.99310218e+000,   9.84208642e+000,   8.65296557e+000,\n",
       "           8.64896564e+000]]),\n",
       " '_': {...},\n",
       " '_20': 11,\n",
       " '_21': [(1, 610), (2, 271), (3, 20), (4, 2)],\n",
       " '_25': (20, 13),\n",
       " '_42': <function locals>,\n",
       " '_43': {...},\n",
       " '_6': 11,\n",
       " '_7': [(1, 610), (2, 271), (3, 20), (4, 2)],\n",
       " '_8': 670442572800,\n",
       " '__': <function locals>,\n",
       " '___': (20, 13),\n",
       " '__builtin__': <module '__builtin__' (built-in)>,\n",
       " '__builtins__': <module '__builtin__' (built-in)>,\n",
       " '__doc__': 'Automatically created module for IPython interactive environment',\n",
       " '__name__': '__main__',\n",
       " '__package__': None,\n",
       " '__version__': '1.13.3',\n",
       " '_dh': [u'/Users/gracer/Google Drive/ABCD'],\n",
       " '_i': u'locals()',\n",
       " '_i1': u'import numpy as np\\nfrom sklearn.cluster import KMeans\\nimport pandas as pd\\nfrom mpl_toolkits.mplot3d import Axes3D\\nfrom sklearn.preprocessing import scale\\n\\nimport sklearn.metrics as sm\\nfrom sklearn.metrics import confusion_matrix\\nimport matplotlib.pyplot as plt\\nimport matplotlib\\nfrom sklearn import datasets\\nfrom sklearn.preprocessing import Imputer\\n\\nimport seaborn as sns',\n",
       " '_i10': u'import math\\nx=math.factorial(70)\\ny=math.factorial(70-20)\\nfact=x/y\\nprint(fact)',\n",
       " '_i11': u\"target_var=pd.DataFrame(lady_dudes['PDS'].values)\",\n",
       " '_i12': u'imputer = Imputer()\\ntransformed_values = imputer.fit_transform(X)\\n# count the number of NaN values in each column\\nprint(np.isnan(transformed_values).sum()) \\ntransformed_values_scale = scale(transformed_values)\\ntrans = np.hstack((transformed_values_scale,target_var.round(decimals=0)))',\n",
       " '_i13': u'\\ndef random_selct(DATA):\\n    dictr = {}\\n    levels = [\\'lev1\\',\\'lev2\\',\\'lev3\\']\\n    i=1\\n    for lev in levels:\\n        if i < len(levels)+1:\\n            dictr[lev] = DATA[np.where(DATA[:,-1] == i)]\\n            i=i+1\\n        else:\\n            break\\n\\n    rand_dict={}\\n    target_dict={}\\n    for key, value in dictr.iteritems():\\n        #print(key)\\n        #print(value.shape)\\n        ind = np.random.permutation(value.shape[0])#random index\\n        training_idx = ind[:20]#get 20 subjects indexes\\n        training = value[training_idx,:]#select 20 subjects from the value in the dictionary\\n        labels_true = value[:,-1] #get the labels from the value in the dictiornary last column\\n        target_dict[key] = labels_true[training_idx]#add targets to dictionary\\n        rand_dict[key] = training\\n\\n        #combine\\n    data=np.vstack((rand_dict[\\'lev1\\'],rand_dict[\\'lev2\\'],rand_dict[\\'lev3\\']))\\n    data=np.delete(data,12,1)\\n    targets=np.hstack((target_dict[\\'lev1\\'],target_dict[\\'lev2\\'],target_dict[\\'lev3\\']))\\n\\n    n_samples, n_features = data.shape\\n    labels = np.round(targets)\\n    n_digits = len(np.unique(targets))\\n\\n    ############################\\n    ####start the k meaning#####\\n    ############################\\n\\n    ### making a cute table################### making a cute table###################\\n    print(\"n_digits: %d, \\\\t n_samples %d, \\\\t n_features %d\"##########################\\n          % (n_digits, n_samples, n_features))### making a cute table################\\n    print(82 * \\'_\\')##################################################################\\n    print(\\'init\\\\t\\\\ttime\\\\tinertia\\\\thomo\\\\tcompl\\\\tv-meas\\\\tARI\\\\tAMI\\\\tsilhouette\\')########\\n    #################################################################################\\n\\n    def bench_k_means(estimator, name, data):\\n        t0 = time() #time\\n        estimator.fit(data) #estimating the fit \\n        print(\\'%-9s\\\\t%.2fs\\\\t%i\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\'\\n              % (name, (time() - t0), estimator.inertia_,\\n                 metrics.homogeneity_score(labels, estimator.labels_),\\n                 metrics.completeness_score(labels, estimator.labels_),\\n                 metrics.v_measure_score(labels, estimator.labels_),\\n                 metrics.adjusted_rand_score(labels, estimator.labels_),\\n                 metrics.adjusted_mutual_info_score(labels,  estimator.labels_),\\n                 metrics.silhouette_score(data, estimator.labels_,\\n                                          metric=\\'euclidean\\',\\n                                          sample_size=sample_size)))\\n\\n    bench_k_means(KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=300),\\n                  name=\"k-means++\", data=data)\\n\\n    bench_k_means(KMeans(init=\\'random\\', n_clusters=n_digits, n_init=300),\\n                  name=\"random\", data=data)\\n\\n    # in this case the seeding of the centers is deterministic, hence we run the\\n    # kmeans algorithm only once with n_init=1\\n    pca = PCA(n_components=n_digits).fit(data)\\n    bench_k_means(KMeans(init=pca.components_, n_clusters=n_digits, n_init=1),\\n                  name=\"PCA-based\",\\n                  data=data)\\n    print(82 * \\'_\\')\\n    \\n    kmeans = KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=300)\\n    ####THINGS TO SAVE#########\\n    kmeans.fit(data)\\n    y_kmeans = kmeans.predict(data)\\n    clusters = kmeans.fit_predict(data)\\n    cluster_space = kmeans.fit_transform(data)\\n    print(cluster_space.shape)\\n    print(clusters.shape)\\n    print(y_kmeans.shape)\\n    \\n        # #############################################################################\\n    # Visualize the results on PCA-reduced data\\n\\n    reduced_data = PCA(n_components=2).fit_transform(data)\\n    kmeans = KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=10000)\\n    kmeans.fit(reduced_data)\\n\\n    # Step size of the mesh. Decrease to increase the quality of the VQ.\\n    h = .02     # point in the mesh [x_min, x_max]x[y_min, y_max].\\n\\n    # Plot the decision boundary. For that, we will assign a color to each\\n    x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\\n    y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\\n\\n    # Obtain labels for each point in mesh. Use last trained model.\\n    Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\\n\\n    # Put the result into a color plot\\n    Z = Z.reshape(xx.shape)\\n    plt.figure(1)\\n    plt.clf()\\n    plt.imshow(Z, interpolation=\\'nearest\\',\\n               extent=(xx.min(), xx.max(), yy.min(), yy.max()),\\n               cmap=plt.cm.Paired,\\n               aspect=\\'auto\\', origin=\\'lower\\')\\n\\n    plt.plot(reduced_data[:, 0], reduced_data[:, 1], \\'k.\\', markersize=2)\\n    # Plot the centroids as a white X\\n    centroids = kmeans.cluster_centers_\\n    plt.scatter(centroids[:, 0], centroids[:, 1],\\n                marker=\\'x\\', s=169, linewidths=3,\\n                color=\\'w\\', zorder=10)\\n    plt.title(\\'K-means clustering on the digits dataset (PCA-reduced data)\\\\n\\'\\n              \\'Centroids are marked with white cross\\')\\n    plt.xlim(x_min, x_max)\\n    plt.ylim(y_min, y_max)\\n    plt.xticks(())\\n    plt.yticks(())\\n    plt.show()\\n\\nn = 10\\nCS_dct={}\\nCluster_dct={}\\n\\nfor x in range(0,n):\\n    random_selct(trans)\\n    CS_dct[\\'arr%i\\'%x]=cluster_space\\n    Cluster_dct[\\'arr%i\\'%x]=clusters\\n    \\n\\nX=np.empty([60, 4])\\n\\nfor key,value in CS_dct.iteritems():\\n    X=(np.array(X) + np.array(value)) \\n    \\nfinal = X/n',\n",
       " '_i14': u\"from sklearn.mixture import GaussianMixture\\nfrom sklearn.datasets import load_iris\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.svm import SVC\\n#X = iris['data']\\n#y = iris['target']\\n#kmeans = KMeans(n_clusters=6).fit(X)\\ndistances = np.column_stack([np.sum((training - center)**2, axis=1)**0.5 for center in kmeans.cluster_centers_])\\nsvm = SVC().fit(distances.astype('int'), training_target.astype('int'))\\nprint(svm)\",\n",
       " '_i15': u'import numpy as np\\nfrom sklearn.cluster import KMeans\\nimport pandas as pd\\nfrom mpl_toolkits.mplot3d import Axes3D\\nfrom sklearn.preprocessing import scale\\n\\nimport sklearn.metrics as sm\\nfrom sklearn.metrics import confusion_matrix\\nimport matplotlib.pyplot as plt\\nimport matplotlib\\nfrom sklearn import datasets\\nfrom sklearn.preprocessing import Imputer\\n\\nimport seaborn as sns',\n",
       " '_i16': u\"data=pd.read_table('important_txt/4Kmeans.csv', sep=',')\",\n",
       " '_i17': u\"dudes = data[data['sex'] >= 0]\\nlady_dudes = data[data['sex'] >= 1]\",\n",
       " '_i18': u'var_names=list(lady_dudes.columns.values)',\n",
       " '_i19': u\"labels_true=lady_dudes['PDS'].values\\nf2=lady_dudes['pds_ht2_y'].values\\nf3=lady_dudes['pds_skin2_y'].values\\nf4=lady_dudes['pds_bdyhair_y'].values\\nf5=lady_dudes['pds_f4_2_y'].values\\nf6=lady_dudes['pds_f5_y'].values\\nf7=lady_dudes['interview_age'].values\\nf8=lady_dudes['anthroheightcalc'].values \\nf9=lady_dudes['anthroweightcalc'].values\\nf10=lady_dudes['anthro_waist_cm'].values\\nf11=lady_dudes['hormone_scr_dhea_mean'].values\\nf12=lady_dudes['hormone_scr_hse_mean'].values\\nf13=lady_dudes['hormone_scr_ert_mean'].values\\nX=np.matrix(zip(f2,f3,f4,f5,f6,f7,f8,f9,f10,f11,f12,f13))\",\n",
       " '_i2': u\"data=pd.read_table('important_txt/4Kmeans.csv', sep=',')\",\n",
       " '_i20': u\"names=['pds_ht2_y',\\n'pds_skin2_y'\\n'pds_bdyhair_y',\\n'pds_f4_2_y',\\n'pds_f5_y',\\n'interview_age',\\n'anthroheightcalc',\\n'anthroweightcalc',\\n'anthro_waist_cm',\\n'hormone_scr_dhea_mean',\\n'hormone_scr_hse_mean',\\n'hormone_scr_ert_mean']\\nlen(names)\",\n",
       " '_i21': u'%matplotlib inline\\nplt.hist(labels_true)\\ny = np.bincount(labels_true.astype(int))\\nii = np.nonzero(y)[0]\\nzip(ii,y[ii])',\n",
       " '_i22': u'import math\\nx=math.factorial(70)\\ny=math.factorial(70-20)\\nfact=x/y\\nprint(fact)',\n",
       " '_i23': u\"target_var=pd.DataFrame(lady_dudes['PDS'].values)\",\n",
       " '_i24': u'imputer = Imputer()\\ntransformed_values = imputer.fit_transform(X)\\n# count the number of NaN values in each column\\nprint(np.isnan(transformed_values).sum()) \\ntransformed_values_scale = scale(transformed_values)\\ntrans = np.hstack((transformed_values_scale,target_var.round(decimals=0)))',\n",
       " '_i25': u\"#def random_selct(data):\\ndictr = {}\\nlevels = ['lev1','lev2','lev3']\\ni=1\\nfor lev in levels:\\n    if i < len(levels)+1:\\n        dictr[lev] = trans[np.where(trans[:,-1] == i)]\\n        i=i+1\\n    else:\\n        break\\n\\nrand_dict={}\\ntarget_dict={}\\nfor key, value in dictr.iteritems():\\n    print(key)\\n    print(value.shape)\\n    ind = np.random.permutation(value.shape[0])#random index\\n    training_idx = ind[:20]#get 20 subjects indexes\\n    training = value[training_idx,:]#select 20 subjects from the value in the dictionary\\n    labels_true = value[:,-1] #get the labels from the value in the dictiornary last column\\n    target_dict[key] = labels_true[training_idx]#add targets to dictionary\\n    rand_dict[key] = training\\n    \\n\\n\\n    # for\\n# ind = np.random.permutation(transformed_values_scale.shape[0])\\n#dictr['lev3'].shape\\nrand_dict['lev2'].shape\",\n",
       " '_i26': u'indices = np.random.permutation(transformed_values_scale.shape[0])\\n\\ntraining_idx, test_idx = indices[:721], indices[721:]#80 20\\ntraining, test = transformed_values_scale[training_idx,:], transformed_values_scale[test_idx,:]\\ntraining_target, test_target = labels_true[training_idx], labels_true[test_idx]\\n\\nplt.hist(training_target)\\ny = np.bincount(training_target.astype(int))\\nii = np.nonzero(y)[0]\\nzip(ii,y[ii])',\n",
       " '_i27': u'import numpy as np\\nimport matplotlib.pyplot as plt\\nfrom numpy import *',\n",
       " '_i28': u'fig, axes = plt.subplots(nrows=6, ncols=2, sharex=True, figsize=(18, 16))\\n\\ntitles = names\\n# axes.flat returns the set of axes as a flat (1D) array instead\\n# of the two-dimensional version we used earlier\\nfor ax, title, y in zip(axes.flat, titles, training):\\n    ax.hist(y)\\n    ax.set_title(title)\\n    ax.grid(True)',\n",
       " '_i29': u'print(__doc__)\\n\\nfrom time import time\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\nfrom sklearn import metrics\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.datasets import load_digits\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.preprocessing import scale',\n",
       " '_i3': u\"dudes = data[data['sex'] >= 0]\\nlady_dudes = data[data['sex'] >= 1]\",\n",
       " '_i30': u'n_samples, n_features = training.shape\\nlabels = np.round(training_target,decimals=0)\\nn_digits = len(np.unique(labels))',\n",
       " '_i31': u'\\ndef random_selct(DATA):\\n    dictr = {}\\n    levels = [\\'lev1\\',\\'lev2\\',\\'lev3\\']\\n    i=1\\n    for lev in levels:\\n        if i < len(levels)+1:\\n            dictr[lev] = DATA[np.where(DATA[:,-1] == i)]\\n            i=i+1\\n        else:\\n            break\\n\\n    rand_dict={}\\n    target_dict={}\\n    for key, value in dictr.iteritems():\\n        #print(key)\\n        #print(value.shape)\\n        ind = np.random.permutation(value.shape[0])#random index\\n        training_idx = ind[:20]#get 20 subjects indexes\\n        training = value[training_idx,:]#select 20 subjects from the value in the dictionary\\n        labels_true = value[:,-1] #get the labels from the value in the dictiornary last column\\n        target_dict[key] = labels_true[training_idx]#add targets to dictionary\\n        rand_dict[key] = training\\n\\n        #combine\\n    data=np.vstack((rand_dict[\\'lev1\\'],rand_dict[\\'lev2\\'],rand_dict[\\'lev3\\']))\\n    data=np.delete(data,12,1)\\n    targets=np.hstack((target_dict[\\'lev1\\'],target_dict[\\'lev2\\'],target_dict[\\'lev3\\']))\\n\\n    n_samples, n_features = data.shape\\n    labels = np.round(targets)\\n    n_digits = len(np.unique(targets))\\n\\n    ############################\\n    ####start the k meaning#####\\n    ############################\\n\\n    ### making a cute table################### making a cute table###################\\n    print(\"n_digits: %d, \\\\t n_samples %d, \\\\t n_features %d\"##########################\\n          % (n_digits, n_samples, n_features))### making a cute table################\\n    print(82 * \\'_\\')##################################################################\\n    print(\\'init\\\\t\\\\ttime\\\\tinertia\\\\thomo\\\\tcompl\\\\tv-meas\\\\tARI\\\\tAMI\\\\tsilhouette\\')########\\n    #################################################################################\\n\\n    def bench_k_means(estimator, name, data):\\n        t0 = time() #time\\n        estimator.fit(data) #estimating the fit \\n        print(\\'%-9s\\\\t%.2fs\\\\t%i\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\'\\n              % (name, (time() - t0), estimator.inertia_,\\n                 metrics.homogeneity_score(labels, estimator.labels_),\\n                 metrics.completeness_score(labels, estimator.labels_),\\n                 metrics.v_measure_score(labels, estimator.labels_),\\n                 metrics.adjusted_rand_score(labels, estimator.labels_),\\n                 metrics.adjusted_mutual_info_score(labels,  estimator.labels_),\\n                 metrics.silhouette_score(data, estimator.labels_,\\n                                          metric=\\'euclidean\\',\\n                                          sample_size=sample_size)))\\n\\n    bench_k_means(KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=300),\\n                  name=\"k-means++\", data=data)\\n\\n    bench_k_means(KMeans(init=\\'random\\', n_clusters=n_digits, n_init=300),\\n                  name=\"random\", data=data)\\n\\n    # in this case the seeding of the centers is deterministic, hence we run the\\n    # kmeans algorithm only once with n_init=1\\n    pca = PCA(n_components=n_digits).fit(data)\\n    bench_k_means(KMeans(init=pca.components_, n_clusters=n_digits, n_init=1),\\n                  name=\"PCA-based\",\\n                  data=data)\\n    print(82 * \\'_\\')\\n    \\n    kmeans = KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=300)\\n    ####THINGS TO SAVE#########\\n    kmeans.fit(data)\\n    y_kmeans = kmeans.predict(data)\\n    clusters = kmeans.fit_predict(data)\\n    cluster_space = kmeans.fit_transform(data)\\n    print(cluster_space.shape)\\n    print(clusters.shape)\\n    print(y_kmeans.shape)\\n    \\n        # #############################################################################\\n    # Visualize the results on PCA-reduced data\\n\\n    reduced_data = PCA(n_components=2).fit_transform(data)\\n    kmeans = KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=10000)\\n    kmeans.fit(reduced_data)\\n\\n    # Step size of the mesh. Decrease to increase the quality of the VQ.\\n    h = .02     # point in the mesh [x_min, x_max]x[y_min, y_max].\\n\\n    # Plot the decision boundary. For that, we will assign a color to each\\n    x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\\n    y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\\n\\n    # Obtain labels for each point in mesh. Use last trained model.\\n    Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\\n\\n    # Put the result into a color plot\\n    Z = Z.reshape(xx.shape)\\n    plt.figure(1)\\n    plt.clf()\\n    plt.imshow(Z, interpolation=\\'nearest\\',\\n               extent=(xx.min(), xx.max(), yy.min(), yy.max()),\\n               cmap=plt.cm.Paired,\\n               aspect=\\'auto\\', origin=\\'lower\\')\\n\\n    plt.plot(reduced_data[:, 0], reduced_data[:, 1], \\'k.\\', markersize=2)\\n    # Plot the centroids as a white X\\n    centroids = kmeans.cluster_centers_\\n    plt.scatter(centroids[:, 0], centroids[:, 1],\\n                marker=\\'x\\', s=169, linewidths=3,\\n                color=\\'w\\', zorder=10)\\n    plt.title(\\'K-means clustering on the digits dataset (PCA-reduced data)\\\\n\\'\\n              \\'Centroids are marked with white cross\\')\\n    plt.xlim(x_min, x_max)\\n    plt.ylim(y_min, y_max)\\n    plt.xticks(())\\n    plt.yticks(())\\n    plt.show()\\n\\nn = 10\\nCS_dct={}\\nCluster_dct={}\\n\\nfor x in range(0,n):\\n    random_selct(trans)\\n    CS_dct[\\'arr%i\\'%x]=cluster_space\\n    Cluster_dct[\\'arr%i\\'%x]=clusters\\n    \\n\\nX=np.empty([60, 4])\\n\\nfor key,value in CS_dct.iteritems():\\n    X=(np.array(X) + np.array(value)) \\n    \\nfinal = X/n',\n",
       " '_i32': u'print(__doc__)\\n\\nfrom time import time\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\nfrom sklearn import metrics\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.datasets import load_digits\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.preprocessing import scale',\n",
       " '_i33': u'\\ndef random_selct(DATA):\\n    dictr = {}\\n    levels = [\\'lev1\\',\\'lev2\\',\\'lev3\\']\\n    i=1\\n    for lev in levels:\\n        if i < len(levels)+1:\\n            dictr[lev] = DATA[np.where(DATA[:,-1] == i)]\\n            i=i+1\\n        else:\\n            break\\n\\n    rand_dict={}\\n    target_dict={}\\n    for key, value in dictr.iteritems():\\n        #print(key)\\n        #print(value.shape)\\n        ind = np.random.permutation(value.shape[0])#random index\\n        training_idx = ind[:20]#get 20 subjects indexes\\n        training = value[training_idx,:]#select 20 subjects from the value in the dictionary\\n        labels_true = value[:,-1] #get the labels from the value in the dictiornary last column\\n        target_dict[key] = labels_true[training_idx]#add targets to dictionary\\n        rand_dict[key] = training\\n\\n        #combine\\n    data=np.vstack((rand_dict[\\'lev1\\'],rand_dict[\\'lev2\\'],rand_dict[\\'lev3\\']))\\n    data=np.delete(data,12,1)\\n    targets=np.hstack((target_dict[\\'lev1\\'],target_dict[\\'lev2\\'],target_dict[\\'lev3\\']))\\n\\n    n_samples, n_features = data.shape\\n    labels = np.round(targets)\\n    n_digits = len(np.unique(targets))\\n    sample_size=n_samples\\n\\n    ############################\\n    ####start the k meaning#####\\n    ############################\\n\\n    ### making a cute table################### making a cute table###################\\n    print(\"n_digits: %d, \\\\t n_samples %d, \\\\t n_features %d\"##########################\\n          % (n_digits, n_samples, n_features))### making a cute table################\\n    print(82 * \\'_\\')##################################################################\\n    print(\\'init\\\\t\\\\ttime\\\\tinertia\\\\thomo\\\\tcompl\\\\tv-meas\\\\tARI\\\\tAMI\\\\tsilhouette\\')########\\n    #################################################################################\\n\\n    def bench_k_means(estimator, name, data):\\n        t0 = time() #time\\n        estimator.fit(data) #estimating the fit \\n        print(\\'%-9s\\\\t%.2fs\\\\t%i\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\'\\n              % (name, (time() - t0), estimator.inertia_,\\n                 metrics.homogeneity_score(labels, estimator.labels_),\\n                 metrics.completeness_score(labels, estimator.labels_),\\n                 metrics.v_measure_score(labels, estimator.labels_),\\n                 metrics.adjusted_rand_score(labels, estimator.labels_),\\n                 metrics.adjusted_mutual_info_score(labels,  estimator.labels_),\\n                 metrics.silhouette_score(data, estimator.labels_,\\n                                          metric=\\'euclidean\\',\\n                                          sample_size=sample_size)))\\n\\n    bench_k_means(KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=300),\\n                  name=\"k-means++\", data=data)\\n\\n    bench_k_means(KMeans(init=\\'random\\', n_clusters=n_digits, n_init=300),\\n                  name=\"random\", data=data)\\n\\n    # in this case the seeding of the centers is deterministic, hence we run the\\n    # kmeans algorithm only once with n_init=1\\n    pca = PCA(n_components=n_digits).fit(data)\\n    bench_k_means(KMeans(init=pca.components_, n_clusters=n_digits, n_init=1),\\n                  name=\"PCA-based\",\\n                  data=data)\\n    print(82 * \\'_\\')\\n    \\n    kmeans = KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=300)\\n    ####THINGS TO SAVE#########\\n    kmeans.fit(data)\\n    y_kmeans = kmeans.predict(data)\\n    clusters = kmeans.fit_predict(data)\\n    cluster_space = kmeans.fit_transform(data)\\n    print(cluster_space.shape)\\n    print(clusters.shape)\\n    print(y_kmeans.shape)\\n    \\n        # #############################################################################\\n    # Visualize the results on PCA-reduced data\\n\\n    reduced_data = PCA(n_components=2).fit_transform(data)\\n    kmeans = KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=10000)\\n    kmeans.fit(reduced_data)\\n\\n    # Step size of the mesh. Decrease to increase the quality of the VQ.\\n    h = .02     # point in the mesh [x_min, x_max]x[y_min, y_max].\\n\\n    # Plot the decision boundary. For that, we will assign a color to each\\n    x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\\n    y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\\n\\n    # Obtain labels for each point in mesh. Use last trained model.\\n    Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\\n\\n    # Put the result into a color plot\\n    Z = Z.reshape(xx.shape)\\n    plt.figure(1)\\n    plt.clf()\\n    plt.imshow(Z, interpolation=\\'nearest\\',\\n               extent=(xx.min(), xx.max(), yy.min(), yy.max()),\\n               cmap=plt.cm.Paired,\\n               aspect=\\'auto\\', origin=\\'lower\\')\\n\\n    plt.plot(reduced_data[:, 0], reduced_data[:, 1], \\'k.\\', markersize=2)\\n    # Plot the centroids as a white X\\n    centroids = kmeans.cluster_centers_\\n    plt.scatter(centroids[:, 0], centroids[:, 1],\\n                marker=\\'x\\', s=169, linewidths=3,\\n                color=\\'w\\', zorder=10)\\n    plt.title(\\'K-means clustering on the digits dataset (PCA-reduced data)\\\\n\\'\\n              \\'Centroids are marked with white cross\\')\\n    plt.xlim(x_min, x_max)\\n    plt.ylim(y_min, y_max)\\n    plt.xticks(())\\n    plt.yticks(())\\n    plt.show()\\n\\nn = 10\\nCS_dct={}\\nCluster_dct={}\\n\\nfor x in range(0,n):\\n    random_selct(trans)\\n    CS_dct[\\'arr%i\\'%x]=cluster_space\\n    Cluster_dct[\\'arr%i\\'%x]=clusters\\n    \\n\\nX=np.empty([60, 4])\\n\\nfor key,value in CS_dct.iteritems():\\n    X=(np.array(X) + np.array(value)) \\n    \\nfinal = X/n',\n",
       " '_i34': u'cluster_space',\n",
       " '_i35': u'cluster_space = kmeans.fit_transform(data)',\n",
       " '_i36': u\"kmeans = KMeans(init='k-means++', n_clusters=n_digits, n_init=300)\",\n",
       " '_i37': u\"n = 10\\nCS_dct={}\\nCluster_dct={}\\n\\nfor x in range(0,n):\\n    random_selct(trans)\\n    CS_dct['arr%i'%x]=cluster_space\\n    Cluster_dct['arr%i'%x]=clusters\\n    \\n\\nX=np.empty([60, 4])\\n\\nfor key,value in CS_dct.iteritems():\\n    X=(np.array(X) + np.array(value)) \\n    \\nfinal = X/n\",\n",
       " '_i38': u\"n = 10\\nCS_dct={}\\nCluster_dct={}\\n\\nfor x in range(0,n):\\n    random_selct(trans)\\n    #CS_dct['arr%i'%x]=cluster_space\\n    #Cluster_dct['arr%i'%x]=clusters\\n    \\n\\nX=np.empty([60, 4])\\n\\nfor key,value in CS_dct.iteritems():\\n    X=(np.array(X) + np.array(value)) \\n    \\nfinal = X/n\",\n",
       " '_i39': u'cluster_space',\n",
       " '_i4': u'var_names=list(lady_dudes.columns.values)',\n",
       " '_i40': u'ykmeans',\n",
       " '_i41': u'local',\n",
       " '_i42': u'locals',\n",
       " '_i43': u'locals()',\n",
       " '_i44': u'globals()',\n",
       " '_i5': u\"labels_true=lady_dudes['PDS'].values\\nf2=lady_dudes['pds_ht2_y'].values\\nf3=lady_dudes['pds_skin2_y'].values\\nf4=lady_dudes['pds_bdyhair_y'].values\\nf5=lady_dudes['pds_f4_2_y'].values\\nf6=lady_dudes['pds_f5_y'].values\\nf7=lady_dudes['interview_age'].values\\nf8=lady_dudes['anthroheightcalc'].values \\nf9=lady_dudes['anthroweightcalc'].values\\nf10=lady_dudes['anthro_waist_cm'].values\\nf11=lady_dudes['hormone_scr_dhea_mean'].values\\nf12=lady_dudes['hormone_scr_hse_mean'].values\\nf13=lady_dudes['hormone_scr_ert_mean'].values\\nX=np.matrix(zip(f2,f3,f4,f5,f6,f7,f8,f9,f10,f11,f12,f13))\",\n",
       " '_i6': u\"names=['pds_ht2_y',\\n'pds_skin2_y'\\n'pds_bdyhair_y',\\n'pds_f4_2_y',\\n'pds_f5_y',\\n'interview_age',\\n'anthroheightcalc',\\n'anthroweightcalc',\\n'anthro_waist_cm',\\n'hormone_scr_dhea_mean',\\n'hormone_scr_hse_mean',\\n'hormone_scr_ert_mean']\\nlen(names)\",\n",
       " '_i7': u'%matplotlib inline\\nplt.hist(labels_true)\\ny = np.bincount(labels_true.astype(int))\\nii = np.nonzero(y)[0]\\nzip(ii,y[ii])',\n",
       " '_i8': u'import math\\nx=math.factorial(20)\\ny=math.factorial(20-10)\\nx/y',\n",
       " '_i9': u'import math\\nx=math.factorial(70)\\ny=math.factorial(70-120)\\nfact=x/y\\nprint(fact)',\n",
       " '_ih': ['',\n",
       "  u'import numpy as np\\nfrom sklearn.cluster import KMeans\\nimport pandas as pd\\nfrom mpl_toolkits.mplot3d import Axes3D\\nfrom sklearn.preprocessing import scale\\n\\nimport sklearn.metrics as sm\\nfrom sklearn.metrics import confusion_matrix\\nimport matplotlib.pyplot as plt\\nimport matplotlib\\nfrom sklearn import datasets\\nfrom sklearn.preprocessing import Imputer\\n\\nimport seaborn as sns',\n",
       "  u\"data=pd.read_table('important_txt/4Kmeans.csv', sep=',')\",\n",
       "  u\"dudes = data[data['sex'] >= 0]\\nlady_dudes = data[data['sex'] >= 1]\",\n",
       "  u'var_names=list(lady_dudes.columns.values)',\n",
       "  u\"labels_true=lady_dudes['PDS'].values\\nf2=lady_dudes['pds_ht2_y'].values\\nf3=lady_dudes['pds_skin2_y'].values\\nf4=lady_dudes['pds_bdyhair_y'].values\\nf5=lady_dudes['pds_f4_2_y'].values\\nf6=lady_dudes['pds_f5_y'].values\\nf7=lady_dudes['interview_age'].values\\nf8=lady_dudes['anthroheightcalc'].values \\nf9=lady_dudes['anthroweightcalc'].values\\nf10=lady_dudes['anthro_waist_cm'].values\\nf11=lady_dudes['hormone_scr_dhea_mean'].values\\nf12=lady_dudes['hormone_scr_hse_mean'].values\\nf13=lady_dudes['hormone_scr_ert_mean'].values\\nX=np.matrix(zip(f2,f3,f4,f5,f6,f7,f8,f9,f10,f11,f12,f13))\",\n",
       "  u\"names=['pds_ht2_y',\\n'pds_skin2_y'\\n'pds_bdyhair_y',\\n'pds_f4_2_y',\\n'pds_f5_y',\\n'interview_age',\\n'anthroheightcalc',\\n'anthroweightcalc',\\n'anthro_waist_cm',\\n'hormone_scr_dhea_mean',\\n'hormone_scr_hse_mean',\\n'hormone_scr_ert_mean']\\nlen(names)\",\n",
       "  u\"get_ipython().magic(u'matplotlib inline')\\nplt.hist(labels_true)\\ny = np.bincount(labels_true.astype(int))\\nii = np.nonzero(y)[0]\\nzip(ii,y[ii])\",\n",
       "  u'import math\\nx=math.factorial(20)\\ny=math.factorial(20-10)\\nx/y',\n",
       "  u'import math\\nx=math.factorial(70)\\ny=math.factorial(70-120)\\nfact=x/y\\nprint(fact)',\n",
       "  u'import math\\nx=math.factorial(70)\\ny=math.factorial(70-20)\\nfact=x/y\\nprint(fact)',\n",
       "  u\"target_var=pd.DataFrame(lady_dudes['PDS'].values)\",\n",
       "  u'imputer = Imputer()\\ntransformed_values = imputer.fit_transform(X)\\n# count the number of NaN values in each column\\nprint(np.isnan(transformed_values).sum()) \\ntransformed_values_scale = scale(transformed_values)\\ntrans = np.hstack((transformed_values_scale,target_var.round(decimals=0)))',\n",
       "  u'\\ndef random_selct(DATA):\\n    dictr = {}\\n    levels = [\\'lev1\\',\\'lev2\\',\\'lev3\\']\\n    i=1\\n    for lev in levels:\\n        if i < len(levels)+1:\\n            dictr[lev] = DATA[np.where(DATA[:,-1] == i)]\\n            i=i+1\\n        else:\\n            break\\n\\n    rand_dict={}\\n    target_dict={}\\n    for key, value in dictr.iteritems():\\n        #print(key)\\n        #print(value.shape)\\n        ind = np.random.permutation(value.shape[0])#random index\\n        training_idx = ind[:20]#get 20 subjects indexes\\n        training = value[training_idx,:]#select 20 subjects from the value in the dictionary\\n        labels_true = value[:,-1] #get the labels from the value in the dictiornary last column\\n        target_dict[key] = labels_true[training_idx]#add targets to dictionary\\n        rand_dict[key] = training\\n\\n        #combine\\n    data=np.vstack((rand_dict[\\'lev1\\'],rand_dict[\\'lev2\\'],rand_dict[\\'lev3\\']))\\n    data=np.delete(data,12,1)\\n    targets=np.hstack((target_dict[\\'lev1\\'],target_dict[\\'lev2\\'],target_dict[\\'lev3\\']))\\n\\n    n_samples, n_features = data.shape\\n    labels = np.round(targets)\\n    n_digits = len(np.unique(targets))\\n\\n    ############################\\n    ####start the k meaning#####\\n    ############################\\n\\n    ### making a cute table################### making a cute table###################\\n    print(\"n_digits: %d, \\\\t n_samples %d, \\\\t n_features %d\"##########################\\n          % (n_digits, n_samples, n_features))### making a cute table################\\n    print(82 * \\'_\\')##################################################################\\n    print(\\'init\\\\t\\\\ttime\\\\tinertia\\\\thomo\\\\tcompl\\\\tv-meas\\\\tARI\\\\tAMI\\\\tsilhouette\\')########\\n    #################################################################################\\n\\n    def bench_k_means(estimator, name, data):\\n        t0 = time() #time\\n        estimator.fit(data) #estimating the fit \\n        print(\\'%-9s\\\\t%.2fs\\\\t%i\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\'\\n              % (name, (time() - t0), estimator.inertia_,\\n                 metrics.homogeneity_score(labels, estimator.labels_),\\n                 metrics.completeness_score(labels, estimator.labels_),\\n                 metrics.v_measure_score(labels, estimator.labels_),\\n                 metrics.adjusted_rand_score(labels, estimator.labels_),\\n                 metrics.adjusted_mutual_info_score(labels,  estimator.labels_),\\n                 metrics.silhouette_score(data, estimator.labels_,\\n                                          metric=\\'euclidean\\',\\n                                          sample_size=sample_size)))\\n\\n    bench_k_means(KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=300),\\n                  name=\"k-means++\", data=data)\\n\\n    bench_k_means(KMeans(init=\\'random\\', n_clusters=n_digits, n_init=300),\\n                  name=\"random\", data=data)\\n\\n    # in this case the seeding of the centers is deterministic, hence we run the\\n    # kmeans algorithm only once with n_init=1\\n    pca = PCA(n_components=n_digits).fit(data)\\n    bench_k_means(KMeans(init=pca.components_, n_clusters=n_digits, n_init=1),\\n                  name=\"PCA-based\",\\n                  data=data)\\n    print(82 * \\'_\\')\\n    \\n    kmeans = KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=300)\\n    ####THINGS TO SAVE#########\\n    kmeans.fit(data)\\n    y_kmeans = kmeans.predict(data)\\n    clusters = kmeans.fit_predict(data)\\n    cluster_space = kmeans.fit_transform(data)\\n    print(cluster_space.shape)\\n    print(clusters.shape)\\n    print(y_kmeans.shape)\\n    \\n        # #############################################################################\\n    # Visualize the results on PCA-reduced data\\n\\n    reduced_data = PCA(n_components=2).fit_transform(data)\\n    kmeans = KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=10000)\\n    kmeans.fit(reduced_data)\\n\\n    # Step size of the mesh. Decrease to increase the quality of the VQ.\\n    h = .02     # point in the mesh [x_min, x_max]x[y_min, y_max].\\n\\n    # Plot the decision boundary. For that, we will assign a color to each\\n    x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\\n    y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\\n\\n    # Obtain labels for each point in mesh. Use last trained model.\\n    Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\\n\\n    # Put the result into a color plot\\n    Z = Z.reshape(xx.shape)\\n    plt.figure(1)\\n    plt.clf()\\n    plt.imshow(Z, interpolation=\\'nearest\\',\\n               extent=(xx.min(), xx.max(), yy.min(), yy.max()),\\n               cmap=plt.cm.Paired,\\n               aspect=\\'auto\\', origin=\\'lower\\')\\n\\n    plt.plot(reduced_data[:, 0], reduced_data[:, 1], \\'k.\\', markersize=2)\\n    # Plot the centroids as a white X\\n    centroids = kmeans.cluster_centers_\\n    plt.scatter(centroids[:, 0], centroids[:, 1],\\n                marker=\\'x\\', s=169, linewidths=3,\\n                color=\\'w\\', zorder=10)\\n    plt.title(\\'K-means clustering on the digits dataset (PCA-reduced data)\\\\n\\'\\n              \\'Centroids are marked with white cross\\')\\n    plt.xlim(x_min, x_max)\\n    plt.ylim(y_min, y_max)\\n    plt.xticks(())\\n    plt.yticks(())\\n    plt.show()\\n\\nn = 10\\nCS_dct={}\\nCluster_dct={}\\n\\nfor x in range(0,n):\\n    random_selct(trans)\\n    CS_dct[\\'arr%i\\'%x]=cluster_space\\n    Cluster_dct[\\'arr%i\\'%x]=clusters\\n    \\n\\nX=np.empty([60, 4])\\n\\nfor key,value in CS_dct.iteritems():\\n    X=(np.array(X) + np.array(value)) \\n    \\nfinal = X/n',\n",
       "  u\"from sklearn.mixture import GaussianMixture\\nfrom sklearn.datasets import load_iris\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.svm import SVC\\n#X = iris['data']\\n#y = iris['target']\\n#kmeans = KMeans(n_clusters=6).fit(X)\\ndistances = np.column_stack([np.sum((training - center)**2, axis=1)**0.5 for center in kmeans.cluster_centers_])\\nsvm = SVC().fit(distances.astype('int'), training_target.astype('int'))\\nprint(svm)\",\n",
       "  u'import numpy as np\\nfrom sklearn.cluster import KMeans\\nimport pandas as pd\\nfrom mpl_toolkits.mplot3d import Axes3D\\nfrom sklearn.preprocessing import scale\\n\\nimport sklearn.metrics as sm\\nfrom sklearn.metrics import confusion_matrix\\nimport matplotlib.pyplot as plt\\nimport matplotlib\\nfrom sklearn import datasets\\nfrom sklearn.preprocessing import Imputer\\n\\nimport seaborn as sns',\n",
       "  u\"data=pd.read_table('important_txt/4Kmeans.csv', sep=',')\",\n",
       "  u\"dudes = data[data['sex'] >= 0]\\nlady_dudes = data[data['sex'] >= 1]\",\n",
       "  u'var_names=list(lady_dudes.columns.values)',\n",
       "  u\"labels_true=lady_dudes['PDS'].values\\nf2=lady_dudes['pds_ht2_y'].values\\nf3=lady_dudes['pds_skin2_y'].values\\nf4=lady_dudes['pds_bdyhair_y'].values\\nf5=lady_dudes['pds_f4_2_y'].values\\nf6=lady_dudes['pds_f5_y'].values\\nf7=lady_dudes['interview_age'].values\\nf8=lady_dudes['anthroheightcalc'].values \\nf9=lady_dudes['anthroweightcalc'].values\\nf10=lady_dudes['anthro_waist_cm'].values\\nf11=lady_dudes['hormone_scr_dhea_mean'].values\\nf12=lady_dudes['hormone_scr_hse_mean'].values\\nf13=lady_dudes['hormone_scr_ert_mean'].values\\nX=np.matrix(zip(f2,f3,f4,f5,f6,f7,f8,f9,f10,f11,f12,f13))\",\n",
       "  u\"names=['pds_ht2_y',\\n'pds_skin2_y'\\n'pds_bdyhair_y',\\n'pds_f4_2_y',\\n'pds_f5_y',\\n'interview_age',\\n'anthroheightcalc',\\n'anthroweightcalc',\\n'anthro_waist_cm',\\n'hormone_scr_dhea_mean',\\n'hormone_scr_hse_mean',\\n'hormone_scr_ert_mean']\\nlen(names)\",\n",
       "  u\"get_ipython().magic(u'matplotlib inline')\\nplt.hist(labels_true)\\ny = np.bincount(labels_true.astype(int))\\nii = np.nonzero(y)[0]\\nzip(ii,y[ii])\",\n",
       "  u'import math\\nx=math.factorial(70)\\ny=math.factorial(70-20)\\nfact=x/y\\nprint(fact)',\n",
       "  u\"target_var=pd.DataFrame(lady_dudes['PDS'].values)\",\n",
       "  u'imputer = Imputer()\\ntransformed_values = imputer.fit_transform(X)\\n# count the number of NaN values in each column\\nprint(np.isnan(transformed_values).sum()) \\ntransformed_values_scale = scale(transformed_values)\\ntrans = np.hstack((transformed_values_scale,target_var.round(decimals=0)))',\n",
       "  u\"#def random_selct(data):\\ndictr = {}\\nlevels = ['lev1','lev2','lev3']\\ni=1\\nfor lev in levels:\\n    if i < len(levels)+1:\\n        dictr[lev] = trans[np.where(trans[:,-1] == i)]\\n        i=i+1\\n    else:\\n        break\\n\\nrand_dict={}\\ntarget_dict={}\\nfor key, value in dictr.iteritems():\\n    print(key)\\n    print(value.shape)\\n    ind = np.random.permutation(value.shape[0])#random index\\n    training_idx = ind[:20]#get 20 subjects indexes\\n    training = value[training_idx,:]#select 20 subjects from the value in the dictionary\\n    labels_true = value[:,-1] #get the labels from the value in the dictiornary last column\\n    target_dict[key] = labels_true[training_idx]#add targets to dictionary\\n    rand_dict[key] = training\\n    \\n\\n\\n    # for\\n# ind = np.random.permutation(transformed_values_scale.shape[0])\\n#dictr['lev3'].shape\\nrand_dict['lev2'].shape\",\n",
       "  u'indices = np.random.permutation(transformed_values_scale.shape[0])\\n\\ntraining_idx, test_idx = indices[:721], indices[721:]#80 20\\ntraining, test = transformed_values_scale[training_idx,:], transformed_values_scale[test_idx,:]\\ntraining_target, test_target = labels_true[training_idx], labels_true[test_idx]\\n\\nplt.hist(training_target)\\ny = np.bincount(training_target.astype(int))\\nii = np.nonzero(y)[0]\\nzip(ii,y[ii])',\n",
       "  u'import numpy as np\\nimport matplotlib.pyplot as plt\\nfrom numpy import *',\n",
       "  u'fig, axes = plt.subplots(nrows=6, ncols=2, sharex=True, figsize=(18, 16))\\n\\ntitles = names\\n# axes.flat returns the set of axes as a flat (1D) array instead\\n# of the two-dimensional version we used earlier\\nfor ax, title, y in zip(axes.flat, titles, training):\\n    ax.hist(y)\\n    ax.set_title(title)\\n    ax.grid(True)',\n",
       "  u'print(__doc__)\\n\\nfrom time import time\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\nfrom sklearn import metrics\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.datasets import load_digits\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.preprocessing import scale',\n",
       "  u'n_samples, n_features = training.shape\\nlabels = np.round(training_target,decimals=0)\\nn_digits = len(np.unique(labels))',\n",
       "  u'\\ndef random_selct(DATA):\\n    dictr = {}\\n    levels = [\\'lev1\\',\\'lev2\\',\\'lev3\\']\\n    i=1\\n    for lev in levels:\\n        if i < len(levels)+1:\\n            dictr[lev] = DATA[np.where(DATA[:,-1] == i)]\\n            i=i+1\\n        else:\\n            break\\n\\n    rand_dict={}\\n    target_dict={}\\n    for key, value in dictr.iteritems():\\n        #print(key)\\n        #print(value.shape)\\n        ind = np.random.permutation(value.shape[0])#random index\\n        training_idx = ind[:20]#get 20 subjects indexes\\n        training = value[training_idx,:]#select 20 subjects from the value in the dictionary\\n        labels_true = value[:,-1] #get the labels from the value in the dictiornary last column\\n        target_dict[key] = labels_true[training_idx]#add targets to dictionary\\n        rand_dict[key] = training\\n\\n        #combine\\n    data=np.vstack((rand_dict[\\'lev1\\'],rand_dict[\\'lev2\\'],rand_dict[\\'lev3\\']))\\n    data=np.delete(data,12,1)\\n    targets=np.hstack((target_dict[\\'lev1\\'],target_dict[\\'lev2\\'],target_dict[\\'lev3\\']))\\n\\n    n_samples, n_features = data.shape\\n    labels = np.round(targets)\\n    n_digits = len(np.unique(targets))\\n\\n    ############################\\n    ####start the k meaning#####\\n    ############################\\n\\n    ### making a cute table################### making a cute table###################\\n    print(\"n_digits: %d, \\\\t n_samples %d, \\\\t n_features %d\"##########################\\n          % (n_digits, n_samples, n_features))### making a cute table################\\n    print(82 * \\'_\\')##################################################################\\n    print(\\'init\\\\t\\\\ttime\\\\tinertia\\\\thomo\\\\tcompl\\\\tv-meas\\\\tARI\\\\tAMI\\\\tsilhouette\\')########\\n    #################################################################################\\n\\n    def bench_k_means(estimator, name, data):\\n        t0 = time() #time\\n        estimator.fit(data) #estimating the fit \\n        print(\\'%-9s\\\\t%.2fs\\\\t%i\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\'\\n              % (name, (time() - t0), estimator.inertia_,\\n                 metrics.homogeneity_score(labels, estimator.labels_),\\n                 metrics.completeness_score(labels, estimator.labels_),\\n                 metrics.v_measure_score(labels, estimator.labels_),\\n                 metrics.adjusted_rand_score(labels, estimator.labels_),\\n                 metrics.adjusted_mutual_info_score(labels,  estimator.labels_),\\n                 metrics.silhouette_score(data, estimator.labels_,\\n                                          metric=\\'euclidean\\',\\n                                          sample_size=sample_size)))\\n\\n    bench_k_means(KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=300),\\n                  name=\"k-means++\", data=data)\\n\\n    bench_k_means(KMeans(init=\\'random\\', n_clusters=n_digits, n_init=300),\\n                  name=\"random\", data=data)\\n\\n    # in this case the seeding of the centers is deterministic, hence we run the\\n    # kmeans algorithm only once with n_init=1\\n    pca = PCA(n_components=n_digits).fit(data)\\n    bench_k_means(KMeans(init=pca.components_, n_clusters=n_digits, n_init=1),\\n                  name=\"PCA-based\",\\n                  data=data)\\n    print(82 * \\'_\\')\\n    \\n    kmeans = KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=300)\\n    ####THINGS TO SAVE#########\\n    kmeans.fit(data)\\n    y_kmeans = kmeans.predict(data)\\n    clusters = kmeans.fit_predict(data)\\n    cluster_space = kmeans.fit_transform(data)\\n    print(cluster_space.shape)\\n    print(clusters.shape)\\n    print(y_kmeans.shape)\\n    \\n        # #############################################################################\\n    # Visualize the results on PCA-reduced data\\n\\n    reduced_data = PCA(n_components=2).fit_transform(data)\\n    kmeans = KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=10000)\\n    kmeans.fit(reduced_data)\\n\\n    # Step size of the mesh. Decrease to increase the quality of the VQ.\\n    h = .02     # point in the mesh [x_min, x_max]x[y_min, y_max].\\n\\n    # Plot the decision boundary. For that, we will assign a color to each\\n    x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\\n    y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\\n\\n    # Obtain labels for each point in mesh. Use last trained model.\\n    Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\\n\\n    # Put the result into a color plot\\n    Z = Z.reshape(xx.shape)\\n    plt.figure(1)\\n    plt.clf()\\n    plt.imshow(Z, interpolation=\\'nearest\\',\\n               extent=(xx.min(), xx.max(), yy.min(), yy.max()),\\n               cmap=plt.cm.Paired,\\n               aspect=\\'auto\\', origin=\\'lower\\')\\n\\n    plt.plot(reduced_data[:, 0], reduced_data[:, 1], \\'k.\\', markersize=2)\\n    # Plot the centroids as a white X\\n    centroids = kmeans.cluster_centers_\\n    plt.scatter(centroids[:, 0], centroids[:, 1],\\n                marker=\\'x\\', s=169, linewidths=3,\\n                color=\\'w\\', zorder=10)\\n    plt.title(\\'K-means clustering on the digits dataset (PCA-reduced data)\\\\n\\'\\n              \\'Centroids are marked with white cross\\')\\n    plt.xlim(x_min, x_max)\\n    plt.ylim(y_min, y_max)\\n    plt.xticks(())\\n    plt.yticks(())\\n    plt.show()\\n\\nn = 10\\nCS_dct={}\\nCluster_dct={}\\n\\nfor x in range(0,n):\\n    random_selct(trans)\\n    CS_dct[\\'arr%i\\'%x]=cluster_space\\n    Cluster_dct[\\'arr%i\\'%x]=clusters\\n    \\n\\nX=np.empty([60, 4])\\n\\nfor key,value in CS_dct.iteritems():\\n    X=(np.array(X) + np.array(value)) \\n    \\nfinal = X/n',\n",
       "  u'print(__doc__)\\n\\nfrom time import time\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\nfrom sklearn import metrics\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.datasets import load_digits\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.preprocessing import scale',\n",
       "  u'\\ndef random_selct(DATA):\\n    dictr = {}\\n    levels = [\\'lev1\\',\\'lev2\\',\\'lev3\\']\\n    i=1\\n    for lev in levels:\\n        if i < len(levels)+1:\\n            dictr[lev] = DATA[np.where(DATA[:,-1] == i)]\\n            i=i+1\\n        else:\\n            break\\n\\n    rand_dict={}\\n    target_dict={}\\n    for key, value in dictr.iteritems():\\n        #print(key)\\n        #print(value.shape)\\n        ind = np.random.permutation(value.shape[0])#random index\\n        training_idx = ind[:20]#get 20 subjects indexes\\n        training = value[training_idx,:]#select 20 subjects from the value in the dictionary\\n        labels_true = value[:,-1] #get the labels from the value in the dictiornary last column\\n        target_dict[key] = labels_true[training_idx]#add targets to dictionary\\n        rand_dict[key] = training\\n\\n        #combine\\n    data=np.vstack((rand_dict[\\'lev1\\'],rand_dict[\\'lev2\\'],rand_dict[\\'lev3\\']))\\n    data=np.delete(data,12,1)\\n    targets=np.hstack((target_dict[\\'lev1\\'],target_dict[\\'lev2\\'],target_dict[\\'lev3\\']))\\n\\n    n_samples, n_features = data.shape\\n    labels = np.round(targets)\\n    n_digits = len(np.unique(targets))\\n    sample_size=n_samples\\n\\n    ############################\\n    ####start the k meaning#####\\n    ############################\\n\\n    ### making a cute table################### making a cute table###################\\n    print(\"n_digits: %d, \\\\t n_samples %d, \\\\t n_features %d\"##########################\\n          % (n_digits, n_samples, n_features))### making a cute table################\\n    print(82 * \\'_\\')##################################################################\\n    print(\\'init\\\\t\\\\ttime\\\\tinertia\\\\thomo\\\\tcompl\\\\tv-meas\\\\tARI\\\\tAMI\\\\tsilhouette\\')########\\n    #################################################################################\\n\\n    def bench_k_means(estimator, name, data):\\n        t0 = time() #time\\n        estimator.fit(data) #estimating the fit \\n        print(\\'%-9s\\\\t%.2fs\\\\t%i\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\\\t%.3f\\'\\n              % (name, (time() - t0), estimator.inertia_,\\n                 metrics.homogeneity_score(labels, estimator.labels_),\\n                 metrics.completeness_score(labels, estimator.labels_),\\n                 metrics.v_measure_score(labels, estimator.labels_),\\n                 metrics.adjusted_rand_score(labels, estimator.labels_),\\n                 metrics.adjusted_mutual_info_score(labels,  estimator.labels_),\\n                 metrics.silhouette_score(data, estimator.labels_,\\n                                          metric=\\'euclidean\\',\\n                                          sample_size=sample_size)))\\n\\n    bench_k_means(KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=300),\\n                  name=\"k-means++\", data=data)\\n\\n    bench_k_means(KMeans(init=\\'random\\', n_clusters=n_digits, n_init=300),\\n                  name=\"random\", data=data)\\n\\n    # in this case the seeding of the centers is deterministic, hence we run the\\n    # kmeans algorithm only once with n_init=1\\n    pca = PCA(n_components=n_digits).fit(data)\\n    bench_k_means(KMeans(init=pca.components_, n_clusters=n_digits, n_init=1),\\n                  name=\"PCA-based\",\\n                  data=data)\\n    print(82 * \\'_\\')\\n    \\n    kmeans = KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=300)\\n    ####THINGS TO SAVE#########\\n    kmeans.fit(data)\\n    y_kmeans = kmeans.predict(data)\\n    clusters = kmeans.fit_predict(data)\\n    cluster_space = kmeans.fit_transform(data)\\n    print(cluster_space.shape)\\n    print(clusters.shape)\\n    print(y_kmeans.shape)\\n    \\n        # #############################################################################\\n    # Visualize the results on PCA-reduced data\\n\\n    reduced_data = PCA(n_components=2).fit_transform(data)\\n    kmeans = KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_init=10000)\\n    kmeans.fit(reduced_data)\\n\\n    # Step size of the mesh. Decrease to increase the quality of the VQ.\\n    h = .02     # point in the mesh [x_min, x_max]x[y_min, y_max].\\n\\n    # Plot the decision boundary. For that, we will assign a color to each\\n    x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\\n    y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\\n\\n    # Obtain labels for each point in mesh. Use last trained model.\\n    Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\\n\\n    # Put the result into a color plot\\n    Z = Z.reshape(xx.shape)\\n    plt.figure(1)\\n    plt.clf()\\n    plt.imshow(Z, interpolation=\\'nearest\\',\\n               extent=(xx.min(), xx.max(), yy.min(), yy.max()),\\n               cmap=plt.cm.Paired,\\n               aspect=\\'auto\\', origin=\\'lower\\')\\n\\n    plt.plot(reduced_data[:, 0], reduced_data[:, 1], \\'k.\\', markersize=2)\\n    # Plot the centroids as a white X\\n    centroids = kmeans.cluster_centers_\\n    plt.scatter(centroids[:, 0], centroids[:, 1],\\n                marker=\\'x\\', s=169, linewidths=3,\\n                color=\\'w\\', zorder=10)\\n    plt.title(\\'K-means clustering on the digits dataset (PCA-reduced data)\\\\n\\'\\n              \\'Centroids are marked with white cross\\')\\n    plt.xlim(x_min, x_max)\\n    plt.ylim(y_min, y_max)\\n    plt.xticks(())\\n    plt.yticks(())\\n    plt.show()\\n\\nn = 10\\nCS_dct={}\\nCluster_dct={}\\n\\nfor x in range(0,n):\\n    random_selct(trans)\\n    CS_dct[\\'arr%i\\'%x]=cluster_space\\n    Cluster_dct[\\'arr%i\\'%x]=clusters\\n    \\n\\nX=np.empty([60, 4])\\n\\nfor key,value in CS_dct.iteritems():\\n    X=(np.array(X) + np.array(value)) \\n    \\nfinal = X/n',\n",
       "  u'cluster_space',\n",
       "  u'cluster_space = kmeans.fit_transform(data)',\n",
       "  u\"kmeans = KMeans(init='k-means++', n_clusters=n_digits, n_init=300)\",\n",
       "  u\"n = 10\\nCS_dct={}\\nCluster_dct={}\\n\\nfor x in range(0,n):\\n    random_selct(trans)\\n    CS_dct['arr%i'%x]=cluster_space\\n    Cluster_dct['arr%i'%x]=clusters\\n    \\n\\nX=np.empty([60, 4])\\n\\nfor key,value in CS_dct.iteritems():\\n    X=(np.array(X) + np.array(value)) \\n    \\nfinal = X/n\",\n",
       "  u\"n = 10\\nCS_dct={}\\nCluster_dct={}\\n\\nfor x in range(0,n):\\n    random_selct(trans)\\n    #CS_dct['arr%i'%x]=cluster_space\\n    #Cluster_dct['arr%i'%x]=clusters\\n    \\n\\nX=np.empty([60, 4])\\n\\nfor key,value in CS_dct.iteritems():\\n    X=(np.array(X) + np.array(value)) \\n    \\nfinal = X/n\",\n",
       "  u'cluster_space',\n",
       "  u'ykmeans',\n",
       "  u'local',\n",
       "  u'locals',\n",
       "  u'locals()',\n",
       "  u'globals()'],\n",
       " '_ii': u'locals',\n",
       " '_iii': u'local',\n",
       " '_oh': {6: 11,\n",
       "  7: [(1, 610), (2, 271), (3, 20), (4, 2)],\n",
       "  8: 670442572800,\n",
       "  20: 11,\n",
       "  21: [(1, 610), (2, 271), (3, 20), (4, 2)],\n",
       "  25: (20, 13),\n",
       "  42: <function locals>,\n",
       "  43: {...}},\n",
       " '_sh': <module 'IPython.core.shadowns' from '/anaconda2/lib/python2.7/site-packages/IPython/core/shadowns.pyc'>,\n",
       " 'absolute': <ufunc 'absolute'>,\n",
       " 'add': <ufunc 'add'>,\n",
       " 'add_docstring': <function numpy.core.multiarray.add_docstring>,\n",
       " 'add_newdoc': <function numpy.lib.function_base.add_newdoc>,\n",
       " 'add_newdoc_ufunc': <function numpy.core.umath._add_newdoc_ufunc>,\n",
       " 'add_newdocs': <module 'numpy.add_newdocs' from '/anaconda2/lib/python2.7/site-packages/numpy/add_newdocs.pyc'>,\n",
       " 'alen': <function numpy.core.fromnumeric.alen>,\n",
       " 'all': <function numpy.core.fromnumeric.all>,\n",
       " 'allclose': <function numpy.core.numeric.allclose>,\n",
       " 'alltrue': <function numpy.core.fromnumeric.alltrue>,\n",
       " 'amax': <function numpy.core.fromnumeric.amax>,\n",
       " 'amin': <function numpy.core.fromnumeric.amin>,\n",
       " 'angle': <function numpy.lib.function_base.angle>,\n",
       " 'any': <function numpy.core.fromnumeric.any>,\n",
       " 'append': <function numpy.lib.function_base.append>,\n",
       " 'apply_along_axis': <function numpy.lib.shape_base.apply_along_axis>,\n",
       " 'apply_over_axes': <function numpy.lib.shape_base.apply_over_axes>,\n",
       " 'arange': <function numpy.core.multiarray.arange>,\n",
       " 'arccos': <ufunc 'arccos'>,\n",
       " 'arccosh': <ufunc 'arccosh'>,\n",
       " 'arcsin': <ufunc 'arcsin'>,\n",
       " 'arcsinh': <ufunc 'arcsinh'>,\n",
       " 'arctan': <ufunc 'arctan'>,\n",
       " 'arctan2': <ufunc 'arctan2'>,\n",
       " 'arctanh': <ufunc 'arctanh'>,\n",
       " 'argmax': <function numpy.core.fromnumeric.argmax>,\n",
       " 'argmin': <function numpy.core.fromnumeric.argmin>,\n",
       " 'argpartition': <function numpy.core.fromnumeric.argpartition>,\n",
       " 'argsort': <function numpy.core.fromnumeric.argsort>,\n",
       " 'argwhere': <function numpy.core.numeric.argwhere>,\n",
       " 'around': <function numpy.core.fromnumeric.around>,\n",
       " 'array': <function numpy.core.multiarray.array>,\n",
       " 'array2string': <function numpy.core.arrayprint.array2string>,\n",
       " 'array_equal': <function numpy.core.numeric.array_equal>,\n",
       " 'array_equiv': <function numpy.core.numeric.array_equiv>,\n",
       " 'array_repr': <function numpy.core.numeric.array_repr>,\n",
       " 'array_split': <function numpy.lib.shape_base.array_split>,\n",
       " 'array_str': <function numpy.core.numeric.array_str>,\n",
       " 'asanyarray': <function numpy.core.numeric.asanyarray>,\n",
       " 'asarray': <function numpy.core.numeric.asarray>,\n",
       " 'asarray_chkfinite': <function numpy.lib.function_base.asarray_chkfinite>,\n",
       " 'ascontiguousarray': <function numpy.core.numeric.ascontiguousarray>,\n",
       " 'asfarray': <function numpy.lib.type_check.asfarray>,\n",
       " 'asfortranarray': <function numpy.core.numeric.asfortranarray>,\n",
       " 'asmatrix': <function numpy.matrixlib.defmatrix.asmatrix>,\n",
       " 'asscalar': <function numpy.lib.type_check.asscalar>,\n",
       " 'atleast_1d': <function numpy.core.shape_base.atleast_1d>,\n",
       " 'atleast_2d': <function numpy.core.shape_base.atleast_2d>,\n",
       " 'atleast_3d': <function numpy.core.shape_base.atleast_3d>,\n",
       " 'average': <function numpy.lib.function_base.average>,\n",
       " 'ax': <matplotlib.axes._subplots.AxesSubplot at 0x11267d350>,\n",
       " 'axes': array([[<matplotlib.axes._subplots.AxesSubplot object at 0x111fba350>,\n",
       "         <matplotlib.axes._subplots.AxesSubplot object at 0x1123fd510>],\n",
       "        [<matplotlib.axes._subplots.AxesSubplot object at 0x11244fcd0>,\n",
       "         <matplotlib.axes._subplots.AxesSubplot object at 0x11249d590>],\n",
       "        [<matplotlib.axes._subplots.AxesSubplot object at 0x1124d8950>,\n",
       "         <matplotlib.axes._subplots.AxesSubplot object at 0x112525190>],\n",
       "        [<matplotlib.axes._subplots.AxesSubplot object at 0x112565a10>,\n",
       "         <matplotlib.axes._subplots.AxesSubplot object at 0x1125b43d0>],\n",
       "        [<matplotlib.axes._subplots.AxesSubplot object at 0x1125413d0>,\n",
       "         <matplotlib.axes._subplots.AxesSubplot object at 0x11262f990>],\n",
       "        [<matplotlib.axes._subplots.AxesSubplot object at 0x11267d350>,\n",
       "         <matplotlib.axes._subplots.AxesSubplot object at 0x1126c0ad0>]], dtype=object),\n",
       " 'bartlett': <function numpy.lib.function_base.bartlett>,\n",
       " 'base_repr': <function numpy.core.numeric.base_repr>,\n",
       " 'binary_repr': <function numpy.core.numeric.binary_repr>,\n",
       " 'bincount': <function numpy.core.multiarray.bincount>,\n",
       " 'bitwise_and': <ufunc 'bitwise_and'>,\n",
       " 'bitwise_not': <ufunc 'invert'>,\n",
       " 'bitwise_or': <ufunc 'bitwise_or'>,\n",
       " 'bitwise_xor': <ufunc 'bitwise_xor'>,\n",
       " 'blackman': <function numpy.lib.function_base.blackman>,\n",
       " 'block': <function numpy.core.shape_base.block>,\n",
       " 'bmat': <function numpy.matrixlib.defmatrix.bmat>,\n",
       " 'bool8': numpy.bool_,\n",
       " 'bool_': numpy.bool_,\n",
       " 'broadcast': numpy.broadcast,\n",
       " 'broadcast_arrays': <function numpy.lib.stride_tricks.broadcast_arrays>,\n",
       " 'broadcast_to': <function numpy.lib.stride_tricks.broadcast_to>,\n",
       " 'busday_count': <function numpy.core.multiarray.busday_count>,\n",
       " 'busday_offset': <function numpy.core.multiarray.busday_offset>,\n",
       " 'busdaycalendar': numpy.busdaycalendar,\n",
       " 'byte': numpy.int8,\n",
       " 'byte_bounds': <function numpy.lib.utils.byte_bounds>,\n",
       " 'bytes_': numpy.string_,\n",
       " 'c_': <numpy.lib.index_tricks.CClass at 0x1086eb1d0>,\n",
       " 'can_cast': <function numpy.core.multiarray.can_cast>,\n",
       " 'cast': {numpy.bool_: <function numpy.core.numerictypes.<lambda>>,\n",
       "  numpy.object_: <function numpy.core.numerictypes.<lambda>>,\n",
       "  numpy.string_: <function numpy.core.numerictypes.<lambda>>,\n",
       "  numpy.unicode_: <function numpy.core.numerictypes.<lambda>>,\n",
       "  numpy.void: <function numpy.core.numerictypes.<lambda>>,\n",
       "  numpy.int8: <function numpy.core.numerictypes.<lambda>>,\n",
       "  numpy.int16: <function numpy.core.numerictypes.<lambda>>,\n",
       "  numpy.int32: <function numpy.core.numerictypes.<lambda>>,\n",
       "  numpy.int64: <function numpy.core.numerictypes.<lambda>>,\n",
       "  numpy.int64: <function numpy.core.numerictypes.<lambda>>,\n",
       "  numpy.uint8: <function numpy.core.numerictypes.<lambda>>,\n",
       "  numpy.uint16: <function numpy.core.numerictypes.<lambda>>,\n",
       "  numpy.uint32: <function numpy.core.numerictypes.<lambda>>,\n",
       "  numpy.uint64: <function numpy.core.numerictypes.<lambda>>,\n",
       "  numpy.uint64: <function numpy.core.numerictypes.<lambda>>,\n",
       "  numpy.float16: <function numpy.core.numerictypes.<lambda>>,\n",
       "  numpy.float32: <function numpy.core.numerictypes.<lambda>>,\n",
       "  numpy.float64: <function numpy.core.numerictypes.<lambda>>,\n",
       "  numpy.float128: <function numpy.core.numerictypes.<lambda>>,\n",
       "  numpy.datetime64: <function numpy.core.numerictypes.<lambda>>,\n",
       "  numpy.timedelta64: <function numpy.core.numerictypes.<lambda>>,\n",
       "  numpy.complex64: <function numpy.core.numerictypes.<lambda>>,\n",
       "  numpy.complex128: <function numpy.core.numerictypes.<lambda>>,\n",
       "  numpy.complex256: <function numpy.core.numerictypes.<lambda>>},\n",
       " 'cbrt': <ufunc 'cbrt'>,\n",
       " 'cdouble': numpy.complex128,\n",
       " 'ceil': <ufunc 'ceil'>,\n",
       " 'cfloat': numpy.complex128,\n",
       " 'char': <module 'numpy.core.defchararray' from '/anaconda2/lib/python2.7/site-packages/numpy/core/defchararray.pyc'>,\n",
       " 'character': numpy.character,\n",
       " 'chararray': numpy.core.defchararray.chararray,\n",
       " 'choose': <function numpy.core.fromnumeric.choose>,\n",
       " 'clip': <function numpy.core.fromnumeric.clip>,\n",
       " 'clongdouble': numpy.complex256,\n",
       " 'clongfloat': numpy.complex256,\n",
       " 'column_stack': <function numpy.lib.shape_base.column_stack>,\n",
       " 'common_type': <function numpy.lib.type_check.common_type>,\n",
       " 'compare_chararrays': <function numpy.core.multiarray.compare_chararrays>,\n",
       " 'complex128': numpy.complex128,\n",
       " 'complex256': numpy.complex256,\n",
       " 'complex64': numpy.complex64,\n",
       " 'complex_': numpy.complex128,\n",
       " 'complexfloating': numpy.complexfloating,\n",
       " 'compress': <function numpy.core.fromnumeric.compress>,\n",
       " 'concatenate': <function numpy.core.multiarray.concatenate>,\n",
       " 'confusion_matrix': <function sklearn.metrics.classification.confusion_matrix>,\n",
       " 'conj': <ufunc 'conjugate'>,\n",
       " 'conjugate': <ufunc 'conjugate'>,\n",
       " 'convolve': <function numpy.core.numeric.convolve>,\n",
       " 'copy': <function numpy.lib.function_base.copy>,\n",
       " 'copysign': <ufunc 'copysign'>,\n",
       " 'copyto': <function numpy.core.multiarray.copyto>,\n",
       " 'corrcoef': <function numpy.lib.function_base.corrcoef>,\n",
       " 'correlate': <function numpy.core.numeric.correlate>,\n",
       " 'cos': <ufunc 'cos'>,\n",
       " 'cosh': <ufunc 'cosh'>,\n",
       " 'count_nonzero': <function numpy.core.numeric.count_nonzero>,\n",
       " 'cov': <function numpy.lib.function_base.cov>,\n",
       " 'cross': <function numpy.core.numeric.cross>,\n",
       " 'csingle': numpy.complex64,\n",
       " 'ctypeslib': <module 'numpy.ctypeslib' from '/anaconda2/lib/python2.7/site-packages/numpy/ctypeslib.pyc'>,\n",
       " 'cumprod': <function numpy.core.fromnumeric.cumprod>,\n",
       " 'cumproduct': <function numpy.core.fromnumeric.cumproduct>,\n",
       " 'cumsum': <function numpy.core.fromnumeric.cumsum>,\n",
       " 'data':         src_subject_id  pds_ht2_y  pds_skin2_y  pds_bdyhair_y  PDS  \\\n",
       " 0     NDAR_INV00X2TBWJ          1            1              1  1.0   \n",
       " 1     NDAR_INV028D3ELL          3            3              1  1.8   \n",
       " 2     NDAR_INV02H7G2T6          3            1              2  1.8   \n",
       " 3     NDAR_INV03NW0RKL          2            1              1  1.4   \n",
       " 4     NDAR_INV05T64PXD          3            2              2  2.0   \n",
       " 5     NDAR_INV07RAHHYH          1            1              1  1.2   \n",
       " 6     NDAR_INV09T2EBX4          2            1              1  1.2   \n",
       " 7     NDAR_INV0A9K5L4R          2            1              1  1.2   \n",
       " 8     NDAR_INV0AEBMADL          4            1              4  2.8   \n",
       " 9     NDAR_INV0B7UGM1D          3            1              1  1.4   \n",
       " 10    NDAR_INV0C1ED337          4            1              1  1.8   \n",
       " 11    NDAR_INV0C765WK4          2            2              2  1.8   \n",
       " 12    NDAR_INV0CP9XGTP          3            3              1  2.2   \n",
       " 13    NDAR_INV0D0C239B          2            1              1  1.2   \n",
       " 14    NDAR_INV0D83M5VE          3            2              2  2.0   \n",
       " 15    NDAR_INV0DBRJXKG          2            2              1  1.6   \n",
       " 16    NDAR_INV0DVK13LU          1            1              1  1.0   \n",
       " 17    NDAR_INV0EV57VEX          2            3              3  2.2   \n",
       " 18    NDAR_INV0GUTM6AM          3            3              2  2.2   \n",
       " 19    NDAR_INV0GZM9UZJ          3            2              2  1.8   \n",
       " 20    NDAR_INV0J6LY05U          3            3              1  2.0   \n",
       " 21    NDAR_INV0JWEE23L          2            2              2  2.0   \n",
       " 22    NDAR_INV0KPZW3NB          3            1              1  1.6   \n",
       " 23    NDAR_INV0L3VJZEL          1            1              1  1.0   \n",
       " 24    NDAR_INV0MRY4Z3E          3            2              3  2.4   \n",
       " 25    NDAR_INV0P0GTDY0          3            1              1  1.6   \n",
       " 26    NDAR_INV0PHTY15N          3            2              2  1.8   \n",
       " 27    NDAR_INV0RHLKA9M          4            3              4  3.0   \n",
       " 28    NDAR_INV0UPVEC1J          1            1              1  1.0   \n",
       " 29    NDAR_INV0UYDV4HJ          3            2              1  2.0   \n",
       " ...                ...        ...          ...            ...  ...   \n",
       " 2159  NDAR_INVZ1V6MUBA          2            1              1  1.4   \n",
       " 2160  NDAR_INVZ2REMPTW          3            3              2  2.2   \n",
       " 2161  NDAR_INVZ3638RYW          1            1              3  1.6   \n",
       " 2162  NDAR_INVZ3XXUKWN          2            1              1  1.2   \n",
       " 2163  NDAR_INVZ6X7VT6J          3            1              1  1.4   \n",
       " 2164  NDAR_INVZCNK7B3X          3            2              3  2.8   \n",
       " 2165  NDAR_INVZDM6F0BD          3            1              2  2.0   \n",
       " 2166  NDAR_INVZEVDMJ6J          1            2              1  1.2   \n",
       " 2167  NDAR_INVZEYJBE3G          1            2              2  1.6   \n",
       " 2168  NDAR_INVZF1WFHR3          3            1              1  1.6   \n",
       " 2169  NDAR_INVZFG1AXUD          2            3              3  2.0   \n",
       " 2170  NDAR_INVZFYGCHKB          4            3              1  2.2   \n",
       " 2171  NDAR_INVZG4U8G7X          2            2              1  1.6   \n",
       " 2172  NDAR_INVZGT6YAX7          2            1              2  1.6   \n",
       " 2173  NDAR_INVZJ8TBWKJ          2            1              1  1.4   \n",
       " 2174  NDAR_INVZK4B9G7W          1            1              1  1.2   \n",
       " 2175  NDAR_INVZM2Y9JCA          2            2              2  1.8   \n",
       " 2176  NDAR_INVZMB15684          4            1              1  1.6   \n",
       " 2177  NDAR_INVZNBBEXEJ          3            2              1  1.6   \n",
       " 2178  NDAR_INVZR16R6Y3          1            1              1  1.0   \n",
       " 2179  NDAR_INVZR9NMJBR          2            1              1  1.4   \n",
       " 2180  NDAR_INVZRBMFHKB          2            1              1  1.2   \n",
       " 2181  NDAR_INVZUGVEHNK          3            2              1  1.6   \n",
       " 2182  NDAR_INVZX24TGXN          4            2              1  1.8   \n",
       " 2183  NDAR_INVZYC44GB8          2            1              1  1.4   \n",
       " 2184  NDAR_INVZYRTFYRP          2            1              1  1.2   \n",
       " 2185  NDAR_INVZZ3P1ZFJ          3            1              1  1.4   \n",
       " 2186  NDAR_INVZZ81LEEV          2            1              1  1.4   \n",
       " 2187  NDAR_INVZZL0VA2F          3            1              2  1.6   \n",
       " 2188  NDAR_INVZZNX6W2P          2            1              1  1.2   \n",
       " \n",
       "       pds_f4_2_y  pds_f5_y  pds_m4_y  pds_m5_y  interview_age gender  \\\n",
       " 0            1.0       1.0       0.0       0.0            130      F   \n",
       " 1            1.0       1.0       0.0       0.0            109      F   \n",
       " 2            2.0       1.0       0.0       0.0            119      F   \n",
       " 3            2.0       1.0       0.0       0.0            119      F   \n",
       " 4            2.0       1.0       0.0       0.0            109      F   \n",
       " 5            2.0       1.0       0.0       0.0            119      F   \n",
       " 6            1.0       1.0       0.0       0.0            108      F   \n",
       " 7            1.0       1.0       0.0       0.0            132      F   \n",
       " 8            4.0       1.0       0.0       0.0            126      F   \n",
       " 9            1.0       1.0       0.0       0.0            117      F   \n",
       " 10           2.0       1.0       0.0       0.0            125      F   \n",
       " 11           2.0       1.0       0.0       0.0            131      F   \n",
       " 12           3.0       1.0       0.0       0.0            128      F   \n",
       " 13           1.0       1.0       0.0       0.0            108      F   \n",
       " 14           2.0       1.0       0.0       0.0            130      F   \n",
       " 15           2.0       1.0       0.0       0.0            130      F   \n",
       " 16           1.0       1.0       0.0       0.0            128      F   \n",
       " 17           2.0       1.0       0.0       0.0            129      F   \n",
       " 18           2.0       1.0       0.0       0.0            131      F   \n",
       " 19           1.0       1.0       0.0       0.0            118      F   \n",
       " 20           2.0       1.0       0.0       0.0            108      F   \n",
       " 21           3.0       1.0       0.0       0.0            131      F   \n",
       " 22           2.0       1.0       0.0       0.0            123      F   \n",
       " 23           1.0       1.0       0.0       0.0            115      F   \n",
       " 24           3.0       1.0       0.0       0.0            111      F   \n",
       " 25           2.0       1.0       0.0       0.0            129      F   \n",
       " 26           1.0       1.0       0.0       0.0            116      F   \n",
       " 27           3.0       1.0       0.0       0.0            129      F   \n",
       " 28           1.0       1.0       0.0       0.0            121      F   \n",
       " 29           3.0       1.0       0.0       0.0            131      F   \n",
       " ...          ...       ...       ...       ...            ...    ...   \n",
       " 2159         0.0       0.0       2.0       1.0            121      M   \n",
       " 2160         0.0       0.0       2.0       1.0            109      M   \n",
       " 2161         0.0       0.0       1.0       2.0            125      M   \n",
       " 2162         0.0       0.0       1.0       1.0            117      M   \n",
       " 2163         0.0       0.0       1.0       1.0            131      M   \n",
       " 2164         0.0       0.0       2.0       4.0            116      M   \n",
       " 2165         0.0       0.0       2.0       2.0            117      M   \n",
       " 2166         0.0       0.0       1.0       1.0            123      M   \n",
       " 2167         0.0       0.0       1.0       2.0            120      M   \n",
       " 2168         0.0       0.0       2.0       1.0            120      M   \n",
       " 2169         0.0       0.0       1.0       1.0            128      M   \n",
       " 2170         0.0       0.0       1.0       2.0            108      M   \n",
       " 2171         0.0       0.0       2.0       1.0            111      M   \n",
       " 2172         0.0       0.0       2.0       1.0            130      M   \n",
       " 2173         0.0       0.0       2.0       1.0            112      M   \n",
       " 2174         0.0       0.0       2.0       1.0            116      M   \n",
       " 2175         0.0       0.0       1.0       2.0            118      M   \n",
       " 2176         0.0       0.0       1.0       1.0            122      M   \n",
       " 2177         0.0       0.0       1.0       1.0            121      M   \n",
       " 2178         0.0       0.0       1.0       1.0            130      M   \n",
       " 2179         0.0       0.0       2.0       1.0            110      M   \n",
       " 2180         0.0       0.0       1.0       1.0            121      M   \n",
       " 2181         0.0       0.0       1.0       1.0            128      M   \n",
       " 2182         0.0       0.0       1.0       1.0            114      M   \n",
       " 2183         0.0       0.0       2.0       1.0            131      M   \n",
       " 2184         0.0       0.0       1.0       1.0            117      M   \n",
       " 2185         0.0       0.0       1.0       1.0            115      M   \n",
       " 2186         0.0       0.0       1.0       2.0            108      M   \n",
       " 2187         0.0       0.0       1.0       1.0            129      M   \n",
       " 2188         0.0       0.0       1.0       1.0            131      M   \n",
       " \n",
       "       anthroheightcalc  anthroweightcalc  anthro_waist_cm  \\\n",
       " 0            54.500000         68.500000            22.25   \n",
       " 1            57.500000         72.000000            23.50   \n",
       " 2            58.950000         96.600000            30.00   \n",
       " 3            54.833333         65.266667            21.80   \n",
       " 4            59.200000         94.800000            26.40   \n",
       " 5            53.140000         69.000000            23.75   \n",
       " 6            50.000000         65.083333            26.00   \n",
       " 7            58.000000         84.000000            28.00   \n",
       " 8            59.000000        141.950000            35.00   \n",
       " 9            51.900000         58.200000            22.45   \n",
       " 10           62.500000        189.000000            42.00   \n",
       " 11           58.000000        134.000000            23.00   \n",
       " 12           62.000000        109.000000            26.00   \n",
       " 13           54.300000         63.566667            20.50   \n",
       " 14           62.000000         95.000000            26.00   \n",
       " 15           55.000000         88.000000            27.50   \n",
       " 16           53.550000         70.400000            25.50   \n",
       " 17           60.750000        115.000000            30.00   \n",
       " 18           59.000000         80.500000            20.50   \n",
       " 19           57.250000         72.000000            25.00   \n",
       " 20           55.000000         61.400000            21.00   \n",
       " 21           57.250000         81.000000            25.50   \n",
       " 22           60.500000        125.000000            35.00   \n",
       " 23           55.500000         64.500000            23.00   \n",
       " 24           51.800000         74.200000            24.30   \n",
       " 25           55.000000         49.500000            25.00   \n",
       " 26           56.000000         63.000000            22.00   \n",
       " 27           58.000000         87.000000            28.00   \n",
       " 28           55.250000         93.000000            29.00   \n",
       " 29           58.000000        114.000000            28.00   \n",
       " ...                ...               ...              ...   \n",
       " 2159         59.000000         90.000000            29.00   \n",
       " 2160         56.000000         80.000000            28.00   \n",
       " 2161         49.500000         59.500000            21.75   \n",
       " 2162         56.000000         94.000000            31.00   \n",
       " 2163         55.500000        131.250000            28.40   \n",
       " 2164         57.250000         83.000000            28.00   \n",
       " 2165         59.000000         72.500000            25.00   \n",
       " 2166         54.000000         91.900000            28.00   \n",
       " 2167         57.125000         78.000000            24.80   \n",
       " 2168         57.000000         71.750000            25.00   \n",
       " 2169         57.875000         98.000000            30.50   \n",
       " 2170         56.125000         76.000000            23.25   \n",
       " 2171         53.000000         60.400000            23.00   \n",
       " 2172         52.700000         71.833333            24.75   \n",
       " 2173         52.000000         66.500000            27.00   \n",
       " 2174         55.500000         81.000000            23.50   \n",
       " 2175         54.000000         68.000000            26.00   \n",
       " 2176         55.500000        106.000000            32.00   \n",
       " 2177         53.900000         73.833333            25.00   \n",
       " 2178         57.000000         79.500000            28.00   \n",
       " 2179         55.000000         67.000000            25.00   \n",
       " 2180         56.375000         88.000000            30.00   \n",
       " 2181         48.900000         69.500000            25.00   \n",
       " 2182         57.000000         62.000000            23.00   \n",
       " 2183         56.000000         78.000000            26.00   \n",
       " 2184         53.750000         60.250000            22.50   \n",
       " 2185         56.000000         63.000000            64.00   \n",
       " 2186         53.500000         57.800000            20.50   \n",
       " 2187         63.500000        134.250000            35.00   \n",
       " 2188         56.000000         73.000000            26.00   \n",
       " \n",
       "       hormone_scr_dhea_mean  hormone_scr_hse_mean  hormone_scr_ert_mean  sex  \n",
       " 0                      1089                1.0450               16.6165    1  \n",
       " 1                       667                1.3000               39.3810    1  \n",
       " 2                      1528                1.1200               36.1655    1  \n",
       " 3                       214                1.3485               39.3290    1  \n",
       " 4                         1                   NaN                   NaN    1  \n",
       " 5                      2127                1.0105               31.3025    1  \n",
       " 6                      1018                1.2275               18.3435    1  \n",
       " 7                      1067                0.5725               12.6605    1  \n",
       " 8                        23                   NaN                   NaN    1  \n",
       " 9                        44                   NaN                   NaN    1  \n",
       " 10                        1                   NaN                   NaN    1  \n",
       " 11                     2525                1.2165               28.4050    1  \n",
       " 12                       49                   NaN                   NaN    1  \n",
       " 13                      108                0.0000                0.0000    1  \n",
       " 14                        1                   NaN                   NaN    1  \n",
       " 15                     1969                0.8255               20.9600    1  \n",
       " 16                      651                1.2950               14.9500    1  \n",
       " 17                      715                1.5605               59.6315    1  \n",
       " 18                        1                   NaN                   NaN    1  \n",
       " 19                     2356                1.3600               40.8200    1  \n",
       " 20                     1234                0.8050               22.2535    1  \n",
       " 21                       73                1.0720               44.5270    1  \n",
       " 22                     1849                1.8260               32.2820    1  \n",
       " 23                     2491                1.3330               26.9420    1  \n",
       " 24                     1588               26.3880                   NaN    1  \n",
       " 25                     2201                1.2100               50.0400    1  \n",
       " 26                        1                   NaN                   NaN    1  \n",
       " 27                      316                1.0300               46.6330    1  \n",
       " 28                        1                   NaN                   NaN    1  \n",
       " 29                     2196                1.2025               42.7685    1  \n",
       " ...                     ...                   ...                   ...  ...  \n",
       " 2159                      1                   NaN                   NaN    0  \n",
       " 2160                      1                   NaN                   NaN    0  \n",
       " 2161                    440               23.9700                   NaN    0  \n",
       " 2162                   1007               22.8995                   NaN    0  \n",
       " 2163                      1                   NaN                   NaN    0  \n",
       " 2164                   2469               60.2520                   NaN    0  \n",
       " 2165                   1076               14.2870                   NaN    0  \n",
       " 2166                      1                   NaN                   NaN    0  \n",
       " 2167                   2331               46.1600                   NaN    0  \n",
       " 2168                   1375                8.4540                   NaN    0  \n",
       " 2169                      1                   NaN                   NaN    0  \n",
       " 2170                   2240               46.3585                   NaN    0  \n",
       " 2171                   2387               34.5610                   NaN    0  \n",
       " 2172                      1                   NaN                   NaN    0  \n",
       " 2173                      1                   NaN                   NaN    0  \n",
       " 2174                   1780               27.5210                   NaN    0  \n",
       " 2175                      1                   NaN                   NaN    0  \n",
       " 2176                      1                   NaN                   NaN    0  \n",
       " 2177                      1                   NaN                   NaN    0  \n",
       " 2178                      1                   NaN                   NaN    0  \n",
       " 2179                      1                   NaN                   NaN    0  \n",
       " 2180                      1                   NaN                   NaN    0  \n",
       " 2181                   1408               28.1205                   NaN    0  \n",
       " 2182                    271               26.9495                   NaN    0  \n",
       " 2183                   1836               42.7900                   NaN    0  \n",
       " 2184                   2171               40.2000                   NaN    0  \n",
       " 2185                      1                   NaN                   NaN    0  \n",
       " 2186                      1                   NaN                   NaN    0  \n",
       " 2187                   2524               40.0535                   NaN    0  \n",
       " 2188                      1                   NaN                   NaN    0  \n",
       " \n",
       " [2189 rows x 18 columns],\n",
       " 'datasets': <module 'sklearn.datasets' from '/anaconda2/lib/python2.7/site-packages/sklearn/datasets/__init__.pyc'>,\n",
       " 'datetime64': numpy.datetime64,\n",
       " 'datetime_as_string': <function numpy.core.multiarray.datetime_as_string>,\n",
       " 'datetime_data': <function numpy.core.multiarray.datetime_data>,\n",
       " 'deg2rad': <ufunc 'deg2rad'>,\n",
       " 'degrees': <ufunc 'degrees'>,\n",
       " 'delete': <function numpy.lib.function_base.delete>,\n",
       " 'deprecate': <function numpy.lib.utils.deprecate>,\n",
       " 'deprecate_with_doc': <function numpy.lib.utils.<lambda>>,\n",
       " 'diag': <function numpy.lib.twodim_base.diag>,\n",
       " 'diag_indices': <function numpy.lib.index_tricks.diag_indices>,\n",
       " 'diag_indices_from': <function numpy.lib.index_tricks.diag_indices_from>,\n",
       " 'diagflat': <function numpy.lib.twodim_base.diagflat>,\n",
       " 'diagonal': <function numpy.core.fromnumeric.diagonal>,\n",
       " 'dictr': {'lev1': array([[ -1.63858192e+00,  -9.16001298e-01,  -8.45054583e-01, ...,\n",
       "           -2.73437790e-01,  -1.36651804e+00,   1.00000000e+00],\n",
       "         [ -4.94235846e-01,  -9.16001298e-01,  -8.45054583e-01, ...,\n",
       "           -2.18893524e-01,   4.53758326e-01,   1.00000000e+00],\n",
       "         [ -1.63858192e+00,  -9.16001298e-01,  -8.45054583e-01, ...,\n",
       "           -2.79638044e-01,  -1.89519528e-01,   1.00000000e+00],\n",
       "         ..., \n",
       "         [ -4.94235846e-01,  -9.16001298e-01,   3.25320092e-01, ...,\n",
       "           -3.61319655e-01,  -1.86705898e+00,   1.00000000e+00],\n",
       "         [ -1.63858192e+00,  -9.16001298e-01,   3.25320092e-01, ...,\n",
       "            1.83564402e-15,  -9.68080597e-15,   1.00000000e+00],\n",
       "         [ -1.63858192e+00,  -9.16001298e-01,  -8.45054583e-01, ...,\n",
       "           -1.82680444e-01,   1.16772341e+00,   1.00000000e+00]]),\n",
       "  'lev2': array([[  6.50110229e-01,   1.67694281e+00,  -8.45054583e-01, ...,\n",
       "           -2.27609823e-01,   4.57925828e-01,   2.00000000e+00],\n",
       "         [  6.50110229e-01,  -9.16001298e-01,   3.25320092e-01, ...,\n",
       "           -2.59958976e-01,   2.00221979e-01,   2.00000000e+00],\n",
       "         [  6.50110229e-01,   3.80470758e-01,   3.25320092e-01, ...,\n",
       "            1.83564402e-15,  -9.68080597e-15,   2.00000000e+00],\n",
       "         ..., \n",
       "         [  6.50110229e-01,   3.80470758e-01,   1.49569477e+00, ...,\n",
       "           -3.20613637e-01,  -5.67640118e-01,   2.00000000e+00],\n",
       "         [  1.79445630e+00,   3.80470758e-01,   3.25320092e-01, ...,\n",
       "           -3.61409513e-01,  -1.74047113e+00,   2.00000000e+00],\n",
       "         [ -4.94235846e-01,   3.80470758e-01,   3.25320092e-01, ...,\n",
       "           -2.25992366e-01,   1.40414896e+00,   2.00000000e+00]]),\n",
       "  'lev3': array([[  1.79445630e+00,  -9.16001298e-01,   2.66606944e+00,\n",
       "            2.93012189e+00,  -1.91891602e-01,   7.40559566e-01,\n",
       "            9.51505926e-01,   2.44586432e+00,   1.77609214e+00,\n",
       "           -8.57248410e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,   1.67694281e+00,   2.66606944e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,   1.15591689e+00,\n",
       "            6.52034004e-01,   1.42620882e-01,   3.06248470e-01,\n",
       "           -5.27213448e-01,  -2.76133552e-01,   1.03913196e+00,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,   3.80470758e-01,   2.66606944e+00,\n",
       "            2.49624989e-01,   5.21705294e+00,   1.57127421e+00,\n",
       "            1.84992169e+00,   3.16051947e+00,   2.61600281e+00,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   2.97341487e+00,   2.66606944e+00,\n",
       "            2.49624989e-01,  -1.91891602e-01,   1.43282177e+00,\n",
       "            1.02637391e+00,  -3.18446958e-01,  -3.23684531e-01,\n",
       "           -4.20205525e-01,  -2.59958976e-01,   1.93330140e+00,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   3.25320092e-01,\n",
       "            1.58987344e+00,   5.21705294e+00,  -1.05932216e+00,\n",
       "            1.10124189e+00,   1.88629562e+00,   6.21214970e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   3.80470758e-01,   1.49569477e+00,\n",
       "            2.49624989e-01,   5.21705294e+00,   1.57127421e+00,\n",
       "            5.02298043e-01,   6.03688723e-01,   7.26203804e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,   2.97341487e+00,   3.25320092e-01,\n",
       "            2.49624989e-01,  -1.91891602e-01,   1.86749804e-01,\n",
       "            9.51505926e-01,  -1.84318132e-01,  -1.16359520e+00,\n",
       "           -4.30343118e-01,  -2.67057818e-01,   6.18735273e-01,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   2.66606944e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,  -1.47467948e+00,\n",
       "            3.52562082e-01,   1.45596564e+00,   1.77609214e+00,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,  -9.16001298e-01,   3.25320092e-01,\n",
       "            1.58987344e+00,   5.21705294e+00,   6.02107125e-01,\n",
       "            1.99965765e+00,   1.60965492e+00,   3.06248470e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [ -4.94235846e-01,   1.67694281e+00,   3.25320092e-01,\n",
       "            1.58987344e+00,   5.21705294e+00,   4.63654685e-01,\n",
       "            6.52034004e-01,   6.03688723e-01,  -8.71803063e-03,\n",
       "            2.04946025e-01,   4.12475798e-02,   3.64514259e+00,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,   3.80470758e-01,   3.25320092e-01,\n",
       "            2.49624989e-01,   5.21705294e+00,   1.43282177e+00,\n",
       "            1.91730288e+00,   1.47552609e+00,  -1.13706864e-01,\n",
       "           -8.39226023e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,   7.40559566e-01,\n",
       "            1.52050258e+00,   2.37251262e+00,   1.56611447e+00,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,   1.67694281e+00,   2.66606944e+00,\n",
       "            2.93012189e+00,  -1.91891602e-01,   8.79012006e-01,\n",
       "            1.55044977e+00,   1.03122436e+00,   1.61860889e+00,\n",
       "           -3.12071203e-01,  -2.44323552e-01,   1.48886144e+00,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,   5.21705294e+00,   8.79012006e-01,\n",
       "            1.40071381e+00,   1.27433285e+00,   7.26203804e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,  -3.67059959e-01,\n",
       "           -9.66458021e-02,   3.64771751e-01,   9.62708028e-02,\n",
       "            9.76529468e-01,  -2.71820332e-01,  -1.02265912e+00,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,   3.80470758e-01,   2.66606944e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,   7.40559566e-01,\n",
       "           -3.21249744e-01,  -7.16641911e-01,  -6.38651031e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,  -9.16001298e-01,   2.66606944e+00,\n",
       "            2.93012189e+00,  -1.91891602e-01,  -9.20869721e-01,\n",
       "           -2.46381763e-01,  -1.50785925e-01,  -3.23684531e-01,\n",
       "            1.04523982e+00,  -2.09907648e-01,   2.45743915e-01,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   2.97341487e+00,   1.49569477e+00,\n",
       "            2.49624989e-01,  -1.91891602e-01,   3.25202244e-01,\n",
       "            2.44886554e+00,   2.74136689e+00,   2.19604747e+00,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,  -9.16001298e-01,   3.25320092e-01,\n",
       "            2.49624989e-01,   5.21705294e+00,   4.63654685e-01,\n",
       "            1.84992169e+00,   1.10667182e+00,   1.14615914e+00,\n",
       "            1.78190489e+00,  -1.47815246e-01,   1.88080125e-01,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,   3.80470758e-01,  -8.45054583e-01,\n",
       "            1.58987344e+00,   5.21705294e+00,   8.79012006e-01,\n",
       "            9.51505926e-01,   1.04799046e+00,   1.25114797e+00,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,  -3.67059959e-01,\n",
       "           -1.56540187e-01,  -5.69938507e-01,  -1.26858403e+00,\n",
       "            4.92177818e-01,   4.28824205e+00,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,  -5.05512399e-01,\n",
       "            1.55044977e+00,   1.61175068e+00,   5.16226137e-01,\n",
       "            5.96405293e-02,   1.16906268e+01,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   2.97341487e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,   1.86749804e-01,\n",
       "            7.41875581e-01,   1.53281028e+00,   1.46112564e+00,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,   2.97341487e+00,   2.66606944e+00,\n",
       "            2.49624989e-01,  -1.91891602e-01,   1.01746445e+00,\n",
       "            5.02298043e-01,   3.20243473e+00,   1.98606981e+00,\n",
       "           -1.80282498e-01,  -2.07032168e-01,   2.17738072e+00,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,  -9.16001298e-01,   2.66606944e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,  -1.47467948e+00,\n",
       "            5.02298043e-01,   1.81923121e+00,   1.77609214e+00,\n",
       "            1.65800098e+00,  -2.59958976e-01,   1.38591614e+00,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   2.97341487e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,  -9.01550776e-02,\n",
       "           -2.46381763e-01,  -1.07292161e+00,  -8.48628698e-01,\n",
       "            1.90242960e+00,  -1.71807535e-01,   8.84333331e-01,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   3.25320092e-01,\n",
       "            1.58987344e+00,   5.21705294e+00,  -6.43964840e-01,\n",
       "            2.44886554e+00,   2.55693975e+00,   1.56611447e+00,\n",
       "           -5.22707851e-01,  -1.73964145e-01,   1.03744893e+00,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,   7.40559566e-01,\n",
       "            4.72350850e-01,  -3.06288514e-02,  -3.23684531e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,   5.21705294e+00,   6.02107125e-01,\n",
       "            3.37588485e-01,   1.10667182e+00,   6.21214970e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,  -9.16001298e-01,   2.66606944e+00,\n",
       "            2.93012189e+00,  -1.91891602e-01,  -1.61313192e+00,\n",
       "           -9.66458021e-02,   1.69348544e+00,   1.19865355e+00,\n",
       "           -5.54247028e-01,  -7.93428730e-02,   1.22999550e+00,\n",
       "            3.00000000e+00],\n",
       "         [ -4.94235846e-01,   1.67694281e+00,   3.25320092e-01,\n",
       "            1.58987344e+00,   5.21705294e+00,   1.15591689e+00,\n",
       "            5.32245235e-01,   4.65368370e-01,   6.21214970e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   3.80470758e-01,   3.25320092e-01,\n",
       "            2.49624989e-01,   5.21705294e+00,   1.86749804e-01,\n",
       "            3.22614889e-01,  -6.32811394e-01,  -7.96134282e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   3.25320092e-01,\n",
       "            2.49624989e-01,   5.21705294e+00,   1.01746445e+00,\n",
       "            1.84992169e+00,   2.99285844e+00,   2.19604747e+00,\n",
       "           -3.71770360e-01,  -2.26261942e-01,   1.43528500e+00,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,  -2.28607518e-01,\n",
       "           -8.45325608e-01,  -6.95684282e-01,  -3.23684531e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,  -9.01550776e-02,\n",
       "            1.25097785e+00,   1.65157018e+00,   1.77609214e+00,\n",
       "            1.09592778e+00,  -2.32462196e-01,  -1.33378478e-01,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   3.80470758e-01,   3.25320092e-01,\n",
       "            1.58987344e+00,   5.21705294e+00,   6.02107125e-01,\n",
       "            1.92478967e+00,   8.97095530e-01,  -2.18695698e-01,\n",
       "           -4.44986307e-01,  -1.45478919e-01,   9.28292454e-01,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,  -9.16001298e-01,   1.49569477e+00,\n",
       "            1.58987344e+00,   5.21705294e+00,   1.43282177e+00,\n",
       "           -1.44426945e+00,   2.74136689e+00,   2.51101397e+00,\n",
       "            1.52846507e+00,  -2.03347959e-01,   6.11716983e-02,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   3.80470758e-01,   3.25320092e-01,\n",
       "            2.49624989e-01,   5.21705294e+00,   3.25202244e-01,\n",
       "            1.40071381e+00,   6.24646352e-01,   9.62708028e-02,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   3.80470758e-01,   1.49569477e+00,\n",
       "           -2.97594938e-16,   0.00000000e+00,   1.86749804e-01,\n",
       "            3.52562082e-01,   5.87903659e-02,  -1.13706864e-01,\n",
       "           -1.28468135e-01,  -1.24541828e-01,   1.39413093e+00,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,   4.63654685e-01,\n",
       "            9.05241494e-02,   1.42620882e-01,  -3.23684531e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   2.97341487e+00,   3.25320092e-01,\n",
       "            1.58987344e+00,  -1.91891602e-01,   1.86749804e-01,\n",
       "           -6.66986099e-02,  -6.07662240e-01,  -3.86677831e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,   5.21705294e+00,   1.01746445e+00,\n",
       "            1.34081943e+00,   6.16263300e-01,  -2.18695698e-01,\n",
       "            1.23898048e+00,   4.88068083e+00,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,   2.97341487e+00,   2.66606944e+00,\n",
       "            2.49624989e-01,  -1.91891602e-01,  -9.20869721e-01,\n",
       "            2.22426160e+00,   3.60062968e+00,   0.00000000e+00,\n",
       "            1.90693520e+00,  -2.68765134e-01,  -6.42094130e-01,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   3.80470758e-01,   1.49569477e+00,\n",
       "            2.93012189e+00,   5.21705294e+00,  -3.67059959e-01,\n",
       "            1.84992169e+00,   1.40007863e+00,   1.14615914e+00,\n",
       "            1.55775145e+00,  -2.05234993e-01,  -3.89840091e-01,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   2.97341487e+00,   2.66606944e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,   1.01746445e+00,\n",
       "            9.88939917e-01,   3.53775680e+00,   2.82598047e+00,\n",
       "            3.91928290e-01,  -6.33480142e-02,   4.21388629e+00,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,   1.67694281e+00,   2.66606944e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,  -6.43964840e-01,\n",
       "            5.02298043e-01,   1.10667182e+00,   1.25114797e+00,\n",
       "           -3.62759166e-01,  -2.83412112e-01,  -1.54576633e-01,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            2.93012189e+00,  -1.91891602e-01,   6.02107125e-01,\n",
       "            1.55044977e+00,   2.02880750e+00,   1.46112564e+00,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,  -5.05512399e-01,\n",
       "            2.06868991e-01,  -2.92316763e-02,   9.62708028e-02,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,   1.67694281e+00,  -8.45054583e-01,\n",
       "            1.58987344e+00,   5.21705294e+00,  -9.01550776e-02,\n",
       "            6.52034004e-01,   1.01445825e+00,   9.36181471e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            2.93012189e+00,  -1.91891602e-01,   6.02107125e-01,\n",
       "           -3.96117725e-01,  -5.48980878e-01,  -1.58355053e+00,\n",
       "           -7.71642072e-01,  -2.10985953e-01,   9.85074658e-01,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,   3.80470758e-01,   1.49569477e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,   4.63654685e-01,\n",
       "            1.84992169e+00,   1.81923121e+00,   1.25114797e+00,\n",
       "           -7.22080507e-01,  -2.11435247e-01,   2.79805790e+00,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,   1.67694281e+00,   3.25320092e-01,\n",
       "            1.58987344e+00,  -1.91891602e-01,   1.86749804e-01,\n",
       "            3.52562082e-01,   1.16255883e+00,   9.36181471e-01,\n",
       "            1.58027943e+00,  -1.86274795e-01,   9.96008681e-02,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,   5.21705294e+00,   8.79012006e-01,\n",
       "            6.52034004e-01,   4.36027690e-01,   5.68720553e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,   7.40559566e-01,\n",
       "            1.55044977e+00,   7.29434497e-01,   7.26203804e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,   1.15591689e+00,\n",
       "            1.32584583e+00,   8.62166150e-01,   9.62708028e-02,\n",
       "           -5.49741431e-01,  -2.62115586e-01,   3.41195722e-01,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,   1.67694281e+00,   1.49569477e+00,\n",
       "            2.49624989e-01,  -1.91891602e-01,   1.86749804e-01,\n",
       "            5.30901591e-02,  -3.07968143e-01,  -6.12124474e-02,\n",
       "            1.33247161e+00,  -2.02808806e-01,   1.05371254e-01,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,   1.67694281e+00,   3.25320092e-01,\n",
       "            1.58987344e+00,   5.21705294e+00,   1.29436933e+00,\n",
       "            2.74833746e+00,   2.82519741e+00,   1.14615914e+00,\n",
       "           -5.15949456e-01,  -2.06223439e-01,   1.59966087e+00,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,  -6.43964840e-01,\n",
       "            2.47746909e-01,   4.90101391e-02,  -5.33662198e-01,\n",
       "            1.74698651e+00,  -1.53925642e-01,   2.69948047e+00,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   3.80470758e-01,   1.49569477e+00,\n",
       "            2.49624989e-01,   5.21705294e+00,   1.57127421e+00,\n",
       "            2.14939362e+00,   4.41797722e+00,   3.45591347e+00,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,  -9.01550776e-02,\n",
       "            8.01769965e-01,   2.19646853e+00,   1.14615914e+00,\n",
       "            1.97001355e+00,  -1.90767733e-01,   2.19152619e+00,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,   4.82973630e-02,\n",
       "            1.02637391e+00,   1.00705624e-01,  -5.33662198e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,   1.15591689e+00,\n",
       "            5.92139619e-01,   9.13861633e-01,   1.46112564e+00,\n",
       "            1.11620297e+00,  -1.52847337e-01,   1.45864705e+00,\n",
       "            3.00000000e+00],\n",
       "         [ -1.63858192e+00,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,   5.21705294e+00,   1.57127421e+00,\n",
       "            1.13867588e+00,   5.91114145e-01,   4.11237303e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   2.97341487e+00,   3.25320092e-01,\n",
       "            2.49624989e-01,   5.21705294e+00,   4.63654685e-01,\n",
       "            1.84992169e+00,   6.87519239e-01,   5.16226137e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   3.80470758e-01,   1.49569477e+00,\n",
       "            1.58987344e+00,   5.21705294e+00,   1.43282177e+00,\n",
       "            1.84992169e+00,   7.71349755e-01,   7.26203804e-01,\n",
       "           -2.20832869e-01,  -2.55196462e-01,   1.71522888e+00,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,   3.80470758e-01,   2.66606944e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,   1.86749804e-01,\n",
       "            9.51505926e-01,   7.31530260e-01,   9.62708028e-02,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [ -4.94235846e-01,   2.97341487e+00,   2.66606944e+00,\n",
       "            2.49624989e-01,  -1.91891602e-01,  -1.19777460e+00,\n",
       "            5.77166023e-01,   1.31624811e+00,   1.35613680e+00,\n",
       "            1.83597205e+00,  -3.13874231e-01,   8.30516464e-01,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,   5.21705294e+00,   7.40559566e-01,\n",
       "            1.55044977e+00,   1.44199389e+00,   9.36181471e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,   1.29436933e+00,\n",
       "            6.52034004e-01,   2.26451399e-01,  -2.18695698e-01,\n",
       "           -6.30842173e-01,  -6.76612345e-02,   4.43139780e+00,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,  -9.16001298e-01,   2.66606944e+00,\n",
       "            2.93012189e+00,   5.21705294e+00,   8.79012006e-01,\n",
       "            1.89983368e+00,   1.91354054e+00,   1.04117030e+00,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00]])},\n",
       " 'diff': <function numpy.lib.function_base.diff>,\n",
       " 'digitize': <function numpy.core.multiarray.digitize>,\n",
       " 'disp': <function numpy.lib.function_base.disp>,\n",
       " 'divide': <ufunc 'divide'>,\n",
       " 'divmod': <ufunc 'divmod'>,\n",
       " 'dot': <function numpy.core.multiarray.dot>,\n",
       " 'double': numpy.float64,\n",
       " 'dsplit': <function numpy.lib.shape_base.dsplit>,\n",
       " 'dstack': <function numpy.lib.shape_base.dstack>,\n",
       " 'dtype': numpy.dtype,\n",
       " 'dudes':         src_subject_id  pds_ht2_y  pds_skin2_y  pds_bdyhair_y  PDS  \\\n",
       " 0     NDAR_INV00X2TBWJ          1            1              1  1.0   \n",
       " 1     NDAR_INV028D3ELL          3            3              1  1.8   \n",
       " 2     NDAR_INV02H7G2T6          3            1              2  1.8   \n",
       " 3     NDAR_INV03NW0RKL          2            1              1  1.4   \n",
       " 4     NDAR_INV05T64PXD          3            2              2  2.0   \n",
       " 5     NDAR_INV07RAHHYH          1            1              1  1.2   \n",
       " 6     NDAR_INV09T2EBX4          2            1              1  1.2   \n",
       " 7     NDAR_INV0A9K5L4R          2            1              1  1.2   \n",
       " 8     NDAR_INV0AEBMADL          4            1              4  2.8   \n",
       " 9     NDAR_INV0B7UGM1D          3            1              1  1.4   \n",
       " 10    NDAR_INV0C1ED337          4            1              1  1.8   \n",
       " 11    NDAR_INV0C765WK4          2            2              2  1.8   \n",
       " 12    NDAR_INV0CP9XGTP          3            3              1  2.2   \n",
       " 13    NDAR_INV0D0C239B          2            1              1  1.2   \n",
       " 14    NDAR_INV0D83M5VE          3            2              2  2.0   \n",
       " 15    NDAR_INV0DBRJXKG          2            2              1  1.6   \n",
       " 16    NDAR_INV0DVK13LU          1            1              1  1.0   \n",
       " 17    NDAR_INV0EV57VEX          2            3              3  2.2   \n",
       " 18    NDAR_INV0GUTM6AM          3            3              2  2.2   \n",
       " 19    NDAR_INV0GZM9UZJ          3            2              2  1.8   \n",
       " 20    NDAR_INV0J6LY05U          3            3              1  2.0   \n",
       " 21    NDAR_INV0JWEE23L          2            2              2  2.0   \n",
       " 22    NDAR_INV0KPZW3NB          3            1              1  1.6   \n",
       " 23    NDAR_INV0L3VJZEL          1            1              1  1.0   \n",
       " 24    NDAR_INV0MRY4Z3E          3            2              3  2.4   \n",
       " 25    NDAR_INV0P0GTDY0          3            1              1  1.6   \n",
       " 26    NDAR_INV0PHTY15N          3            2              2  1.8   \n",
       " 27    NDAR_INV0RHLKA9M          4            3              4  3.0   \n",
       " 28    NDAR_INV0UPVEC1J          1            1              1  1.0   \n",
       " 29    NDAR_INV0UYDV4HJ          3            2              1  2.0   \n",
       " ...                ...        ...          ...            ...  ...   \n",
       " 2159  NDAR_INVZ1V6MUBA          2            1              1  1.4   \n",
       " 2160  NDAR_INVZ2REMPTW          3            3              2  2.2   \n",
       " 2161  NDAR_INVZ3638RYW          1            1              3  1.6   \n",
       " 2162  NDAR_INVZ3XXUKWN          2            1              1  1.2   \n",
       " 2163  NDAR_INVZ6X7VT6J          3            1              1  1.4   \n",
       " 2164  NDAR_INVZCNK7B3X          3            2              3  2.8   \n",
       " 2165  NDAR_INVZDM6F0BD          3            1              2  2.0   \n",
       " 2166  NDAR_INVZEVDMJ6J          1            2              1  1.2   \n",
       " 2167  NDAR_INVZEYJBE3G          1            2              2  1.6   \n",
       " 2168  NDAR_INVZF1WFHR3          3            1              1  1.6   \n",
       " 2169  NDAR_INVZFG1AXUD          2            3              3  2.0   \n",
       " 2170  NDAR_INVZFYGCHKB          4            3              1  2.2   \n",
       " 2171  NDAR_INVZG4U8G7X          2            2              1  1.6   \n",
       " 2172  NDAR_INVZGT6YAX7          2            1              2  1.6   \n",
       " 2173  NDAR_INVZJ8TBWKJ          2            1              1  1.4   \n",
       " 2174  NDAR_INVZK4B9G7W          1            1              1  1.2   \n",
       " 2175  NDAR_INVZM2Y9JCA          2            2              2  1.8   \n",
       " 2176  NDAR_INVZMB15684          4            1              1  1.6   \n",
       " 2177  NDAR_INVZNBBEXEJ          3            2              1  1.6   \n",
       " 2178  NDAR_INVZR16R6Y3          1            1              1  1.0   \n",
       " 2179  NDAR_INVZR9NMJBR          2            1              1  1.4   \n",
       " 2180  NDAR_INVZRBMFHKB          2            1              1  1.2   \n",
       " 2181  NDAR_INVZUGVEHNK          3            2              1  1.6   \n",
       " 2182  NDAR_INVZX24TGXN          4            2              1  1.8   \n",
       " 2183  NDAR_INVZYC44GB8          2            1              1  1.4   \n",
       " 2184  NDAR_INVZYRTFYRP          2            1              1  1.2   \n",
       " 2185  NDAR_INVZZ3P1ZFJ          3            1              1  1.4   \n",
       " 2186  NDAR_INVZZ81LEEV          2            1              1  1.4   \n",
       " 2187  NDAR_INVZZL0VA2F          3            1              2  1.6   \n",
       " 2188  NDAR_INVZZNX6W2P          2            1              1  1.2   \n",
       " \n",
       "       pds_f4_2_y  pds_f5_y  pds_m4_y  pds_m5_y  interview_age gender  \\\n",
       " 0            1.0       1.0       0.0       0.0            130      F   \n",
       " 1            1.0       1.0       0.0       0.0            109      F   \n",
       " 2            2.0       1.0       0.0       0.0            119      F   \n",
       " 3            2.0       1.0       0.0       0.0            119      F   \n",
       " 4            2.0       1.0       0.0       0.0            109      F   \n",
       " 5            2.0       1.0       0.0       0.0            119      F   \n",
       " 6            1.0       1.0       0.0       0.0            108      F   \n",
       " 7            1.0       1.0       0.0       0.0            132      F   \n",
       " 8            4.0       1.0       0.0       0.0            126      F   \n",
       " 9            1.0       1.0       0.0       0.0            117      F   \n",
       " 10           2.0       1.0       0.0       0.0            125      F   \n",
       " 11           2.0       1.0       0.0       0.0            131      F   \n",
       " 12           3.0       1.0       0.0       0.0            128      F   \n",
       " 13           1.0       1.0       0.0       0.0            108      F   \n",
       " 14           2.0       1.0       0.0       0.0            130      F   \n",
       " 15           2.0       1.0       0.0       0.0            130      F   \n",
       " 16           1.0       1.0       0.0       0.0            128      F   \n",
       " 17           2.0       1.0       0.0       0.0            129      F   \n",
       " 18           2.0       1.0       0.0       0.0            131      F   \n",
       " 19           1.0       1.0       0.0       0.0            118      F   \n",
       " 20           2.0       1.0       0.0       0.0            108      F   \n",
       " 21           3.0       1.0       0.0       0.0            131      F   \n",
       " 22           2.0       1.0       0.0       0.0            123      F   \n",
       " 23           1.0       1.0       0.0       0.0            115      F   \n",
       " 24           3.0       1.0       0.0       0.0            111      F   \n",
       " 25           2.0       1.0       0.0       0.0            129      F   \n",
       " 26           1.0       1.0       0.0       0.0            116      F   \n",
       " 27           3.0       1.0       0.0       0.0            129      F   \n",
       " 28           1.0       1.0       0.0       0.0            121      F   \n",
       " 29           3.0       1.0       0.0       0.0            131      F   \n",
       " ...          ...       ...       ...       ...            ...    ...   \n",
       " 2159         0.0       0.0       2.0       1.0            121      M   \n",
       " 2160         0.0       0.0       2.0       1.0            109      M   \n",
       " 2161         0.0       0.0       1.0       2.0            125      M   \n",
       " 2162         0.0       0.0       1.0       1.0            117      M   \n",
       " 2163         0.0       0.0       1.0       1.0            131      M   \n",
       " 2164         0.0       0.0       2.0       4.0            116      M   \n",
       " 2165         0.0       0.0       2.0       2.0            117      M   \n",
       " 2166         0.0       0.0       1.0       1.0            123      M   \n",
       " 2167         0.0       0.0       1.0       2.0            120      M   \n",
       " 2168         0.0       0.0       2.0       1.0            120      M   \n",
       " 2169         0.0       0.0       1.0       1.0            128      M   \n",
       " 2170         0.0       0.0       1.0       2.0            108      M   \n",
       " 2171         0.0       0.0       2.0       1.0            111      M   \n",
       " 2172         0.0       0.0       2.0       1.0            130      M   \n",
       " 2173         0.0       0.0       2.0       1.0            112      M   \n",
       " 2174         0.0       0.0       2.0       1.0            116      M   \n",
       " 2175         0.0       0.0       1.0       2.0            118      M   \n",
       " 2176         0.0       0.0       1.0       1.0            122      M   \n",
       " 2177         0.0       0.0       1.0       1.0            121      M   \n",
       " 2178         0.0       0.0       1.0       1.0            130      M   \n",
       " 2179         0.0       0.0       2.0       1.0            110      M   \n",
       " 2180         0.0       0.0       1.0       1.0            121      M   \n",
       " 2181         0.0       0.0       1.0       1.0            128      M   \n",
       " 2182         0.0       0.0       1.0       1.0            114      M   \n",
       " 2183         0.0       0.0       2.0       1.0            131      M   \n",
       " 2184         0.0       0.0       1.0       1.0            117      M   \n",
       " 2185         0.0       0.0       1.0       1.0            115      M   \n",
       " 2186         0.0       0.0       1.0       2.0            108      M   \n",
       " 2187         0.0       0.0       1.0       1.0            129      M   \n",
       " 2188         0.0       0.0       1.0       1.0            131      M   \n",
       " \n",
       "       anthroheightcalc  anthroweightcalc  anthro_waist_cm  \\\n",
       " 0            54.500000         68.500000            22.25   \n",
       " 1            57.500000         72.000000            23.50   \n",
       " 2            58.950000         96.600000            30.00   \n",
       " 3            54.833333         65.266667            21.80   \n",
       " 4            59.200000         94.800000            26.40   \n",
       " 5            53.140000         69.000000            23.75   \n",
       " 6            50.000000         65.083333            26.00   \n",
       " 7            58.000000         84.000000            28.00   \n",
       " 8            59.000000        141.950000            35.00   \n",
       " 9            51.900000         58.200000            22.45   \n",
       " 10           62.500000        189.000000            42.00   \n",
       " 11           58.000000        134.000000            23.00   \n",
       " 12           62.000000        109.000000            26.00   \n",
       " 13           54.300000         63.566667            20.50   \n",
       " 14           62.000000         95.000000            26.00   \n",
       " 15           55.000000         88.000000            27.50   \n",
       " 16           53.550000         70.400000            25.50   \n",
       " 17           60.750000        115.000000            30.00   \n",
       " 18           59.000000         80.500000            20.50   \n",
       " 19           57.250000         72.000000            25.00   \n",
       " 20           55.000000         61.400000            21.00   \n",
       " 21           57.250000         81.000000            25.50   \n",
       " 22           60.500000        125.000000            35.00   \n",
       " 23           55.500000         64.500000            23.00   \n",
       " 24           51.800000         74.200000            24.30   \n",
       " 25           55.000000         49.500000            25.00   \n",
       " 26           56.000000         63.000000            22.00   \n",
       " 27           58.000000         87.000000            28.00   \n",
       " 28           55.250000         93.000000            29.00   \n",
       " 29           58.000000        114.000000            28.00   \n",
       " ...                ...               ...              ...   \n",
       " 2159         59.000000         90.000000            29.00   \n",
       " 2160         56.000000         80.000000            28.00   \n",
       " 2161         49.500000         59.500000            21.75   \n",
       " 2162         56.000000         94.000000            31.00   \n",
       " 2163         55.500000        131.250000            28.40   \n",
       " 2164         57.250000         83.000000            28.00   \n",
       " 2165         59.000000         72.500000            25.00   \n",
       " 2166         54.000000         91.900000            28.00   \n",
       " 2167         57.125000         78.000000            24.80   \n",
       " 2168         57.000000         71.750000            25.00   \n",
       " 2169         57.875000         98.000000            30.50   \n",
       " 2170         56.125000         76.000000            23.25   \n",
       " 2171         53.000000         60.400000            23.00   \n",
       " 2172         52.700000         71.833333            24.75   \n",
       " 2173         52.000000         66.500000            27.00   \n",
       " 2174         55.500000         81.000000            23.50   \n",
       " 2175         54.000000         68.000000            26.00   \n",
       " 2176         55.500000        106.000000            32.00   \n",
       " 2177         53.900000         73.833333            25.00   \n",
       " 2178         57.000000         79.500000            28.00   \n",
       " 2179         55.000000         67.000000            25.00   \n",
       " 2180         56.375000         88.000000            30.00   \n",
       " 2181         48.900000         69.500000            25.00   \n",
       " 2182         57.000000         62.000000            23.00   \n",
       " 2183         56.000000         78.000000            26.00   \n",
       " 2184         53.750000         60.250000            22.50   \n",
       " 2185         56.000000         63.000000            64.00   \n",
       " 2186         53.500000         57.800000            20.50   \n",
       " 2187         63.500000        134.250000            35.00   \n",
       " 2188         56.000000         73.000000            26.00   \n",
       " \n",
       "       hormone_scr_dhea_mean  hormone_scr_hse_mean  hormone_scr_ert_mean  sex  \n",
       " 0                      1089                1.0450               16.6165    1  \n",
       " 1                       667                1.3000               39.3810    1  \n",
       " 2                      1528                1.1200               36.1655    1  \n",
       " 3                       214                1.3485               39.3290    1  \n",
       " 4                         1                   NaN                   NaN    1  \n",
       " 5                      2127                1.0105               31.3025    1  \n",
       " 6                      1018                1.2275               18.3435    1  \n",
       " 7                      1067                0.5725               12.6605    1  \n",
       " 8                        23                   NaN                   NaN    1  \n",
       " 9                        44                   NaN                   NaN    1  \n",
       " 10                        1                   NaN                   NaN    1  \n",
       " 11                     2525                1.2165               28.4050    1  \n",
       " 12                       49                   NaN                   NaN    1  \n",
       " 13                      108                0.0000                0.0000    1  \n",
       " 14                        1                   NaN                   NaN    1  \n",
       " 15                     1969                0.8255               20.9600    1  \n",
       " 16                      651                1.2950               14.9500    1  \n",
       " 17                      715                1.5605               59.6315    1  \n",
       " 18                        1                   NaN                   NaN    1  \n",
       " 19                     2356                1.3600               40.8200    1  \n",
       " 20                     1234                0.8050               22.2535    1  \n",
       " 21                       73                1.0720               44.5270    1  \n",
       " 22                     1849                1.8260               32.2820    1  \n",
       " 23                     2491                1.3330               26.9420    1  \n",
       " 24                     1588               26.3880                   NaN    1  \n",
       " 25                     2201                1.2100               50.0400    1  \n",
       " 26                        1                   NaN                   NaN    1  \n",
       " 27                      316                1.0300               46.6330    1  \n",
       " 28                        1                   NaN                   NaN    1  \n",
       " 29                     2196                1.2025               42.7685    1  \n",
       " ...                     ...                   ...                   ...  ...  \n",
       " 2159                      1                   NaN                   NaN    0  \n",
       " 2160                      1                   NaN                   NaN    0  \n",
       " 2161                    440               23.9700                   NaN    0  \n",
       " 2162                   1007               22.8995                   NaN    0  \n",
       " 2163                      1                   NaN                   NaN    0  \n",
       " 2164                   2469               60.2520                   NaN    0  \n",
       " 2165                   1076               14.2870                   NaN    0  \n",
       " 2166                      1                   NaN                   NaN    0  \n",
       " 2167                   2331               46.1600                   NaN    0  \n",
       " 2168                   1375                8.4540                   NaN    0  \n",
       " 2169                      1                   NaN                   NaN    0  \n",
       " 2170                   2240               46.3585                   NaN    0  \n",
       " 2171                   2387               34.5610                   NaN    0  \n",
       " 2172                      1                   NaN                   NaN    0  \n",
       " 2173                      1                   NaN                   NaN    0  \n",
       " 2174                   1780               27.5210                   NaN    0  \n",
       " 2175                      1                   NaN                   NaN    0  \n",
       " 2176                      1                   NaN                   NaN    0  \n",
       " 2177                      1                   NaN                   NaN    0  \n",
       " 2178                      1                   NaN                   NaN    0  \n",
       " 2179                      1                   NaN                   NaN    0  \n",
       " 2180                      1                   NaN                   NaN    0  \n",
       " 2181                   1408               28.1205                   NaN    0  \n",
       " 2182                    271               26.9495                   NaN    0  \n",
       " 2183                   1836               42.7900                   NaN    0  \n",
       " 2184                   2171               40.2000                   NaN    0  \n",
       " 2185                      1                   NaN                   NaN    0  \n",
       " 2186                      1                   NaN                   NaN    0  \n",
       " 2187                   2524               40.0535                   NaN    0  \n",
       " 2188                      1                   NaN                   NaN    0  \n",
       " \n",
       " [2189 rows x 18 columns],\n",
       " 'e': 2.718281828459045,\n",
       " 'ediff1d': <function numpy.lib.arraysetops.ediff1d>,\n",
       " 'einsum': <function numpy.core.einsumfunc.einsum>,\n",
       " 'einsum_path': <function numpy.core.einsumfunc.einsum_path>,\n",
       " 'emath': <module 'numpy.lib.scimath' from '/anaconda2/lib/python2.7/site-packages/numpy/lib/scimath.pyc'>,\n",
       " 'empty': <function numpy.core.multiarray.empty>,\n",
       " 'empty_like': <function numpy.core.multiarray.empty_like>,\n",
       " 'equal': <ufunc 'equal'>,\n",
       " 'errstate': numpy.core.numeric.errstate,\n",
       " 'euler_gamma': 0.5772156649015329,\n",
       " 'exit': <IPython.core.autocall.ZMQExitAutocall at 0x10773bb90>,\n",
       " 'exp': <ufunc 'exp'>,\n",
       " 'exp2': <ufunc 'exp2'>,\n",
       " 'expand_dims': <function numpy.lib.shape_base.expand_dims>,\n",
       " 'expm1': <ufunc 'expm1'>,\n",
       " 'extract': <function numpy.lib.function_base.extract>,\n",
       " 'eye': <function numpy.lib.twodim_base.eye>,\n",
       " 'f10': array([ 22.25 ,  23.5  ,  30.   ,  21.8  ,  26.4  ,  23.75 ,  26.   ,\n",
       "         28.   ,  35.   ,  22.45 ,  42.   ,  23.   ,  26.   ,  20.5  ,\n",
       "         26.   ,  27.5  ,  25.5  ,  30.   ,  20.5  ,  25.   ,  21.   ,\n",
       "         25.5  ,  35.   ,  23.   ,  24.3  ,  25.   ,  22.   ,  28.   ,\n",
       "         29.   ,  28.   ,  25.   ,  39.   ,  25.6  ,  25.   ,  25.   ,\n",
       "         29.   ,  28.   ,  32.   ,  36.5  ,  32.   ,  32.   ,  21.   ,\n",
       "         24.   ,  20.   ,  30.5  ,  29.5  ,  25.2  ,  28.   ,  27.   ,\n",
       "         28.   ,  30.   ,  22.   ,  25.   ,  25.   ,  27.5  ,  27.   ,\n",
       "         22.5  ,  21.   ,  22.   ,  23.   ,  24.   ,  32.   ,  35.25 ,\n",
       "         23.75 ,  24.   ,  30.5  ,  75.   ,  29.5  ,  25.   ,  36.   ,\n",
       "         27.5  ,  24.75 ,  20.5  ,  30.   ,  22.   ,  27.   ,  24.   ,\n",
       "         21.   ,  24.   ,  23.5  ,  28.   ,  27.   ,  24.   ,  35.   ,\n",
       "         23.   ,  23.   ,  20.   ,  27.   ,  23.   ,  25.   ,  31.   ,\n",
       "         26.   ,  24.   ,  28.75 ,  26.   ,  21.   ,  24.25 ,  24.   ,\n",
       "         30.   ,  26.5  ,  23.7  ,  28.5  ,  28.   ,  22.   ,  26.5  ,\n",
       "         22.   ,  27.   ,  34.25 ,  28.   ,  28.   ,  25.75 ,  20.5  ,\n",
       "         29.5  ,  32.   ,  22.   ,  26.   ,  25.   ,  33.   ,  26.5  ,\n",
       "         29.   ,  21.   ,  26.   ,  28.   ,  26.   ,  29.5  ,  25.   ,\n",
       "         21.5  ,  24.   ,  24.   ,  36.   ,  21.   ,  24.75 ,  23.   ,\n",
       "         23.   ,  23.   ,  24.   ,  22.   ,  24.   ,  26.   ,  29.   ,\n",
       "         21.   ,  34.   ,  27.5  ,  28.   ,  20.25 ,  26.   ,  34.   ,\n",
       "         26.5  ,  30.5  ,  33.5  ,  23.5  ,  24.   ,  22.5  ,  24.   ,\n",
       "         25.   ,  34.25 ,  30.   ,  30.5  ,  25.   ,  24.   ,  27.   ,\n",
       "         33.   ,  23.5  ,  25.   ,  30.   ,  22.5  ,  25.   ,  27.5  ,\n",
       "         27.   ,  26.   ,  27.   ,  25.   ,  25.   ,  28.5  ,  29.5  ,\n",
       "         21.5  ,  23.   ,  27.   ,  26.75 ,  25.   ,  34.   ,  30.5  ,\n",
       "         19.5  ,  25.   ,  25.25 ,  24.   ,  29.   ,  33.   ,  23.5  ,\n",
       "         23.5  ,  31.   ,  23.   ,  21.   ,  20.   ,  25.   ,  24.   ,\n",
       "         27.   ,  27.   ,  26.   ,  24.5  ,  26.   ,  20.5  ,  35.   ,\n",
       "         24.5  ,  24.25 ,  23.5  ,  26.5  ,  32.5  ,  22.25 ,  27.5  ,\n",
       "         25.   ,  30.   ,  36.   ,  23.5  ,  27.5  ,  27.5  ,  22.5  ,\n",
       "         22.5  ,  37.   ,  20.75 ,  23.5  ,  23.   ,  40.   ,  29.   ,\n",
       "         22.   ,  25.25 ,  29.   ,  28.   ,  26.   ,  24.   ,  23.75 ,\n",
       "         24.   ,  37.   ,  36.   ,  22.   ,  25.4  ,  22.5  ,  25.   ,\n",
       "         27.5  ,  26.   ,  23.   ,  33.   ,  24.   ,  23.   ,  24.   ,\n",
       "         20.   ,  30.   ,  27.   ,  33.   ,  29.75 ,  28.   ,  26.25 ,\n",
       "         28.   ,  27.5  ,  24.   ,  22.   ,  34.5  ,  33.25 ,  24.   ,\n",
       "         23.   ,  35.5  ,  25.   ,  33.   ,  21.25 ,  23.   ,  26.   ,\n",
       "         32.   ,  22.5  ,  31.   ,  24.   ,  30.   ,  22.   ,  21.   ,\n",
       "         32.   ,  25.   ,  28.   ,  26.   ,  25.   ,  23.   ,  34.5  ,\n",
       "         26.5  ,  31.   ,  24.   ,  26.5  ,  37.   ,  30.5  ,  30.5  ,\n",
       "         29.5  ,  22.   ,  26.5  ,  23.5  ,  23.75 ,  28.   ,  32.   ,\n",
       "         23.   ,  24.   ,  26.25 ,  32.5  ,  30.25 ,  20.5  ,  30.   ,\n",
       "         22.   ,  25.5  ,  21.5  ,  27.5  ,  21.   ,  28.   ,  23.5  ,\n",
       "         29.5  ,  32.   ,  29.7  ,  20.   ,  29.   ,  27.   ,  32.8  ,\n",
       "         26.5  ,  25.   ,  26.5  ,  24.5  ,  28.2  ,  27.   ,  24.   ,\n",
       "         25.   ,  23.75 ,  28.   ,  27.   ,  22.   ,  26.5  ,  33.5  ,\n",
       "         25.   ,  36.   ,  26.   ,  23.5  ,  35.   ,  29.   ,  25.25 ,\n",
       "         27.5  ,  27.   ,  26.5  ,  24.   ,  25.5  ,  27.5  ,  39.5  ,\n",
       "         23.   ,  27.5  ,  25.5  ,  24.75 ,  28.   ,  24.   ,  22.5  ,\n",
       "         27.   ,  22.5  ,  23.25 ,  31.   ,  24.   ,  23.   ,  25.   ,\n",
       "         24.   ,  21.   ,  21.5  ,  23.5  ,  25.   ,  27.5  ,  26.   ,\n",
       "         25.   ,  37.   ,  26.   ,  18.25 ,  29.5  ,  27.5  ,  24.   ,\n",
       "         21.5  ,  27.   ,  21.5  ,  22.   ,  26.5  ,  23.   ,  28.   ,\n",
       "         34.   ,  25.   ,  25.75 ,  28.   ,  23.   ,  29.5  ,  32.75 ,\n",
       "         26.5  ,  26.   ,  27.5  ,  35.   ,  39.5  ,  35.5  ,  30.   ,\n",
       "         23.5  ,  25.5  ,  27.5  ,  25.   ,  22.   ,  23.5  ,  26.   ,\n",
       "         23.   ,  27.5  ,  26.   ,  24.75 ,  21.   ,  26.   ,  22.   ,\n",
       "         27.25 ,  22.8  ,  22.2  ,  26.5  ,  22.25 ,  25.   ,  24.   ,\n",
       "         26.   ,  25.   ,  25.5  ,  31.5  ,  31.5  ,  30.   ,  32.   ,\n",
       "         29.5  ,  21.5  ,  32.25 ,  23.5  ,  23.   ,  29.5  ,  24.   ,\n",
       "         25.5  ,  23.5  ,  24.5  ,  23.5  ,  22.75 ,  27.5  ,  30.   ,\n",
       "         24.   ,  23.   ,  65.5  ,  25.   ,  21.75 ,  25.   ,  37.   ,\n",
       "         23.   ,  38.   ,  24.5  ,  24.   ,  25.5  ,  25.   ,  18.   ,\n",
       "         25.   ,  25.   ,  25.   ,  26.   ,  23.5  ,  24.   ,  23.   ,\n",
       "         30.   ,  21.25 ,  27.   ,  22.   ,  22.   ,  27.   ,  34.4  ,\n",
       "         28.   ,  21.25 ,  23.5  ,  21.5  ,  22.5  ,  35.   ,  26.   ,\n",
       "         24.   ,  24.2  ,  25.5  ,  27.   ,  23.   ,  40.   ,  38.5  ,\n",
       "         24.   ,  23.   ,  23.5  ,  27.   ,  25.75 ,  26.   ,  25.   ,\n",
       "         26.   ,  42.   ,  25.75 ,  31.   ,  26.   ,  25.25 ,  37.   ,\n",
       "         25.   ,  23.   ,  28.   ,  35.5  ,  28.   ,  25.5  ,  23.5  ,\n",
       "         24.5  ,  25.5  ,  24.   ,  22.5  ,  22.   ,  22.75 ,  22.   ,\n",
       "         26.5  ,  23.5  ,  24.7  ,  23.   ,  22.5  ,  28.5  ,  22.   ,\n",
       "         26.   ,  25.   ,  22.5  ,  25.5  ,  19.5  ,  29.   ,  26.   ,\n",
       "         23.1  ,  22.5  ,  31.   ,  22.   ,  33.   ,  26.375,     nan,\n",
       "         25.5  ,  21.   ,  22.75 ,  21.   ,  25.   ,  25.   ,  28.   ,\n",
       "         20.   ,  26.5  ,  29.5  ,  31.   ,  35.5  ,  21.   ,  30.5  ,\n",
       "         24.   ,  26.   ,  21.5  ,  27.5  ,  23.5  ,  25.   ,  30.5  ,\n",
       "         31.   ,  23.5  ,  24.5  ,  29.   ,  23.5  ,  23.   ,  24.   ,\n",
       "         27.   ,  26.   ,  36.   ,  33.75 ,  33.   ,  20.5  ,  24.   ,\n",
       "         32.2  ,  28.   ,  22.   ,  21.   ,  25.   ,  24.   ,  24.5  ,\n",
       "         25.   ,  32.   ,  24.   ,  28.5  ,  40.   ,  30.   ,  26.   ,\n",
       "         23.   ,  25.75 ,  23.   ,  32.   ,  32.5  ,  23.5  ,  33.5  ,\n",
       "         19.5  ,  27.   ,  27.   ,  31.   ,  25.   ,  23.5  ,  26.5  ,\n",
       "         27.   ,  30.   ,  29.25 ,  20.5  ,  21.75 ,  22.   ,  26.   ,\n",
       "         31.   ,  23.5  ,  27.8  ,  24.25 ,  27.   ,  24.75 ,  23.   ,\n",
       "         26.5  ,  22.75 ,  21.   ,  26.5  ,  32.   ,  27.5  ,  23.8  ,\n",
       "         24.5  ,  31.   ,  26.   ,  35.   ,  24.   ,  21.   ,  25.   ,\n",
       "         30.   ,  28.5  ,  23.   ,  27.   ,  28.   ,  26.   ,  25.5  ,\n",
       "         32.5  ,  26.8  ,  26.   ,  19.   ,  26.   ,  23.   ,  27.   ,\n",
       "         28.   ,  22.   ,  24.   ,  22.   ,  26.5  ,  26.5  ,  24.   ,\n",
       "         30.   ,  32.5  ,  23.   ,  30.   ,  22.8  ,  22.5  ,  23.25 ,\n",
       "         23.3  ,  23.25 ,  24.   ,  27.   ,  24.   ,  21.   ,  22.5  ,\n",
       "         31.   ,  23.   ,  24.5  ,  29.25 ,  25.3  ,  25.75 ,  24.5  ,\n",
       "         30.   ,  24.5  ,  27.   ,  24.   ,  31.25 ,  24.5  ,  23.   ,\n",
       "         24.5  ,  23.   ,  21.   ,  26.5  ,  31.   ,  25.5  ,  28.   ,\n",
       "         21.5  ,  21.   ,  27.   ,  29.   ,  25.   ,  33.5  ,  21.5  ,\n",
       "         21.   ,  31.   ,  26.25 ,  27.   ,  28.   ,  26.   ,  23.   ,\n",
       "         25.5  ,  31.   ,  24.5  ,  26.   ,  21.   ,  22.7  ,  35.   ,\n",
       "         25.   ,  24.   ,  24.   ,  24.   ,  26.25 ,  32.5  ,  25.5  ,\n",
       "         21.5  ,  30.5  ,  29.   ,  24.25 ,  27.   ,  28.   ,  23.   ,\n",
       "         30.5  ,  29.5  ,  27.25 ,  24.   ,  25.8  ,  25.5  ,  31.5  ,\n",
       "         28.   ,  28.5  ,  25.   ,  32.   ,  25.5  ,  25.5  ,  26.   ,\n",
       "         24.5  ,  24.   ,  22.   ,  27.   ,  24.25 ,  26.   ,  23.   ,\n",
       "         20.   ,  24.75 ,  24.   ,  26.   ,  24.   ,  29.   ,  27.   ,\n",
       "         26.   ,  23.   ,  28.5  ,  26.   ,  23.75 ,  25.   ,  25.   ,\n",
       "         28.   ,  27.   ,  23.5  ,  28.25 ,  25.   ,  23.   ,  25.25 ,\n",
       "         27.5  ,  34.5  ,  21.5  ,  43.   ,  27.   ,  30.   ,  24.   ,\n",
       "         30.   ,  28.   ,  28.5  ,  30.5  ,  31.5  ,  34.6  ,  25.   ,\n",
       "         22.5  ,  21.5  ,  24.   ,  24.75 ,  44.75 ,  30.5  ,  31.   ,\n",
       "         30.5  ,  24.5  ,  22.   ,  28.45 ,  24.5  ,  23.   ,  32.   ,\n",
       "         36.   ,  23.   ,  19.   ,  24.   ,  27.   ,  27.75 ,  23.   ,\n",
       "         25.75 ,  24.5  ,  36.   ,  23.   ,  25.   ,  29.5  ,  30.   ,\n",
       "         24.   ,  22.   ,  19.25 ,  26.   ,  23.   ,  26.   ,  23.5  ,\n",
       "         28.   ,  22.   ,  24.   ,  22.   ,  24.5  ,  30.   ,  33.5  ,\n",
       "         30.   ,  26.   ,  28.5  ,  30.   ,  24.5  ,  21.75 ,  22.6  ,\n",
       "         23.5  ,  26.   ,  24.   ,  39.   ,  27.   ,  24.   ,  29.   ,\n",
       "         25.   ,  32.   ,  27.   ,  24.   ,  32.75 ,  30.   ,  21.5  ,\n",
       "         21.25 ,  27.   ,  24.   ,  26.   ,  24.   ,  28.   ,  23.   ,\n",
       "         36.55 ,  25.5  ,  33.   ,  25.   ,  30.   ,  29.   ,  33.5  ,\n",
       "         21.   ,  29.75 ,  25.75 ,  27.   ,  23.5  ,  34.5  ,  28.   ,\n",
       "         25.   ,  27.5  ,  24.25 ,  23.   ,  26.875,  22.   ,  29.   ,\n",
       "         26.5  ,  28.   ,  24.5  ,  26.5  ,  23.5  ,  23.   ,  24.3  ,\n",
       "         29.   ,  33.   ,  26.   ,  29.   ,  23.   ,  24.   ,  35.   ,\n",
       "         19.   ,  26.   ,  35.   ,  22.5  ,  32.   ,  21.5  ,  31.   ,\n",
       "         35.   ,  27.5  ,  31.5  ,  24.25 ,  24.   ,  29.   ,  23.5  ,\n",
       "         25.5  ,  31.5  ,  29.   ,  36.8  ,  22.5  ,  23.   ,  27.   ,\n",
       "         25.   ,  61.   ,  23.   ,  24.   ,  26.8  ,  35.5  ,  29.   ,\n",
       "         25.9  ,  23.5  ,  22.   ,  29.   ,  25.   ,  25.   ,  19.   ]),\n",
       " 'f11': array([1089,  667, 1528,  214,    1, 2127, 1018, 1067,   23,   44,    1,\n",
       "        2525,   49,  108,    1, 1969,  651,  715,    1, 2356, 1234,   73,\n",
       "        1849, 2491, 1588, 2201,    1,  316,    1, 2196,    1,    1,    1,\n",
       "         411, 1622,   57,  911,  130, 1365, 2555,    1,    1, 2514,    1,\n",
       "        1134,    1, 2205, 2089,    1,    1,    1,    1, 2222, 2123,  232,\n",
       "        1154,    1,  402,    1, 1925,  138,    1, 1800, 1276,    1,  412,\n",
       "           1,  366,  903, 2031,    1,  513, 1784, 1462,   20,    1,  590,\n",
       "         769,    1,    1,  827, 1664,  304,    1,    1,  353,    1,    1,\n",
       "           1, 1531,    1, 1595,    1,    1, 1930,    1,    1,    1,    1,\n",
       "           1,    1, 1880,    1, 1397,  226,    1, 2378, 2534,  310,    1,\n",
       "        2186, 2037, 1499,    1,    1, 1921,    1,    1,  966,  680,    1,\n",
       "         978,  777, 2224, 1666,    1, 1510,   78,    1, 2333,  101,  886,\n",
       "          19, 2259,  916,    1,  630, 1998,   39,  421,    1, 2427, 1418,\n",
       "        2557, 2034,    1,    1, 1081,    1, 1915,  968,    1, 1377,    1,\n",
       "           1,  507,    1, 2368, 2248,    1,    1,    1, 1978, 1684, 1353,\n",
       "           1,    1,  170,    1,  148, 1651, 2437, 1924,    1, 2006,    1,\n",
       "         685,  492, 1265,  276,    1, 1952,    1,    1, 1741, 1015, 2214,\n",
       "           1, 1220,    1,    1, 2466,    1,    1, 2042, 2311, 1837,  990,\n",
       "           1,    1,    1, 1014,    1,    1, 1086,    1, 2063,    1,  561,\n",
       "         248, 1712,  673, 2494,    1,  719, 1829,  504,   21,    1,  568,\n",
       "         386,   36, 2155,    1, 1069,    1,    1,    1,    1,  900, 2492,\n",
       "        1792, 2144,  187, 1226,  930,    1, 1149,    1,  517, 2272, 2266,\n",
       "           1, 1594,    1,    1, 1102, 1502, 2516, 1826, 2355,    1,    1,\n",
       "        1929,    1,    1,    1,    1, 1534, 2397,  508,    1,    1,  553,\n",
       "         816,    1, 2077,    1,    1,    1,  985,    1,   26,    1,    1,\n",
       "        2160,  988, 1798, 1047,    1,  818, 2371,    1,  324, 2508,  965,\n",
       "           1,    1,    1,  823,  496, 2258,  179, 2366,    1, 1340,    1,\n",
       "           1,  286, 1221,    1, 1373,    1, 1280, 2094, 1918, 1770, 1028,\n",
       "         378,  445,    1,    1,  837, 2304, 2017,    1,    1, 2274,    1,\n",
       "        1814,  961,  620,  899,   58, 2057, 1113, 2001, 1984,    1,   31,\n",
       "         624, 2399, 2488, 2256, 1096, 1520, 2357, 2406,    1, 1778,  113,\n",
       "        1615,  567,   92,    1,  762, 2352,  664,  708,  397,  807, 2473,\n",
       "           1,    1,    1,  109,  750,    1,    1, 2303, 1574, 2220,  102,\n",
       "         200,  782, 1488,    1,  592,    1,    1,    1,    1, 1189,    1,\n",
       "           1,  228, 1607,    1,  320,    1,    1,    1,    1,  272,    1,\n",
       "           1,    1,    1,  631, 1823,    1,  327, 1818,  625,    1,    1,\n",
       "        1779, 1725,    1,    1,    1, 1766,    1,    1,    1, 1162,    1,\n",
       "           1,    1, 2284,    1,  904, 1104, 1440,    1,  759,    1, 2250,\n",
       "           1,  851,    1, 1739,  292,    1,    1,    1, 1856,    1, 2554,\n",
       "        2421,  117,    1, 2005,    1, 1053,    1,    1,    1,    1,  820,\n",
       "         454, 1715,  212,    1, 1902,    1, 1497,    1, 2420,    1,    1,\n",
       "          47, 2474, 2478, 2174,    1,   50, 1022,  725,  731, 1443,    1,\n",
       "           1, 1168, 2184,    1,  295, 1757,    1, 2323, 2192,  389,    1,\n",
       "        1708,  145, 2141, 2415, 1450, 2134,    1, 1727,    1, 1996,  178,\n",
       "           1,    1, 1887,  670, 2147, 2111,    1,  367,    1, 2522, 2032,\n",
       "        2298,    1,    1, 1613,   51,    1,    1, 2343, 2244, 1679, 2084,\n",
       "           1,    1,    1, 1453,    1,  860, 1339, 2301, 1884,  315,    1,\n",
       "           1, 1085, 1639,    1,  894,  958,    1, 2477,    1,    1,  603,\n",
       "         473,    1,    1,    1,    1, 1299,  119,  330, 1156,    1, 1410,\n",
       "        1118, 1292,    1, 1985, 2191, 2455, 2527,    1,    1, 1075,    1,\n",
       "         963,    1,    1,   19,    1,  305,  480,  676,    1,  891,    1,\n",
       "        2345,    1,    1,    4,    1,  205, 2320, 2167, 1249,    1, 1132,\n",
       "        2043, 1504, 2022, 2347,  939,  110,  462, 1771,    1,    1,  294,\n",
       "         849, 1748,  586,   33, 2206,    1, 2039, 1445, 1260,    1, 1337,\n",
       "        2190,    1,    1, 2223,    1,    1,  300, 2076, 1501, 1405,  971,\n",
       "           1,    1, 2482,    1,    1,    1,    1, 2073, 1928,    1,    1,\n",
       "        1706, 1663, 1744,  301,    1,    1,    1,    1,    1, 2377,   99,\n",
       "           1,    1, 1145, 1306,    1,    1,   19, 1927,  866,  240,  533,\n",
       "         143,  144,    1,   52,  580, 2517, 2553,    1,    1,    1, 1630,\n",
       "           1, 2268, 2187, 1335,    1,    1,   34, 1577,  841,    1,    1,\n",
       "         296, 2328, 2360, 2426,  926, 1525,    1, 1143, 1180, 1993, 2552,\n",
       "        1908,    1,    1,   69,    1,  912,    1,  895,    1,    1,    1,\n",
       "        2211,    1,    1, 1192, 1652,    1,  694, 1064,    1,    1,   95,\n",
       "           1,  375, 1172, 1429, 1967, 1800, 1987,  666, 2348,    1,  675,\n",
       "           1,  183,  615,  379,    1,    1,  123,    1,  987,    1, 1688,\n",
       "           1,    1,  326, 1813,  512,  511, 2376, 2335,    1, 2168, 2291,\n",
       "           1,    1,  635,    1,    1,    1,    1, 2025, 2087,    1,  289,\n",
       "        2318, 1164, 1942,    1, 2229, 2046,  709,    1, 2226,  137,    1,\n",
       "        1980, 1852,    1,  633,    1, 1212,    1, 1906, 1201,   19,    1,\n",
       "        1094,  208,    1,    1,  763, 2172,    1, 1606,    1,    1,  556,\n",
       "           1, 2232, 1068,   59,    1,    1, 2533, 1721,    1,    1,    1,\n",
       "         638, 2004, 2373,  168,    1,    1, 1797,    1,    1,  121,  450,\n",
       "        2405, 1895, 1923,    1,    1,  314,    1,    1,    1,  794, 2526,\n",
       "           1, 1775,  681,  660,    1,  655,   28,    1,    1,    1,    1,\n",
       "        2016,    1,    1,   74,    1, 1763,    1, 1733,    1,    1,  588,\n",
       "        1730,    1,  393, 1362, 1638,   30, 1783, 1144,    1,    1,    1,\n",
       "          42,  241,  738, 1831,   19, 1686,    1,    1, 2339, 2487, 2115,\n",
       "         334,    1, 2019,    1,    1, 1845,    1,    1, 1476,    1,  576,\n",
       "        1936,    1, 2044,    1, 2414,    1,  180,    1,  206,  331,  308,\n",
       "        2035, 2178, 2024,    1,    1,    1,    1,    1,  626, 1886,    1,\n",
       "        2484, 1027,  224,    1,  989,    1,    1,    1, 1302, 2503,    1,\n",
       "        2098,    1,    1,    1,    1,    1, 2137, 2261,  299, 1786,  279,\n",
       "         311]),\n",
       " 'f12': array([  1.045 ,   1.3   ,   1.12  ,   1.3485,      nan,   1.0105,\n",
       "          1.2275,   0.5725,      nan,      nan,      nan,   1.2165,\n",
       "             nan,   0.    ,      nan,   0.8255,   1.295 ,   1.5605,\n",
       "             nan,   1.36  ,   0.805 ,   1.072 ,   1.826 ,   1.333 ,\n",
       "         26.388 ,   1.21  ,      nan,   1.03  ,      nan,   1.2025,\n",
       "             nan,      nan,      nan,   1.12  ,   1.4595,      nan,\n",
       "          3.01  ,   0.78  ,   1.61  ,   1.118 ,      nan,      nan,\n",
       "          1.92  ,      nan,   0.9545,      nan,   1.81  ,   0.473 ,\n",
       "             nan,      nan,      nan,      nan,   1.4895,   1.332 ,\n",
       "          1.3525,   0.899 ,      nan,   1.0805,      nan,   1.5915,\n",
       "          1.843 ,      nan,   0.76  ,   1.3715,      nan,   1.17  ,\n",
       "             nan,   1.4315,   1.119 ,   0.674 ,      nan,   1.15  ,\n",
       "          0.9985,   0.983 ,      nan,      nan,   0.659 ,   1.7655,\n",
       "             nan,      nan,   0.5665,   1.339 ,  51.7625,      nan,\n",
       "             nan,   0.5155,      nan,      nan,      nan,   0.887 ,\n",
       "             nan,   0.35  ,      nan,      nan,   0.9625,      nan,\n",
       "             nan,      nan,      nan,      nan,      nan,  31.728 ,\n",
       "             nan,   1.1725,   2.02  ,      nan,   0.9145,   1.9035,\n",
       "         52.418 ,      nan,   1.121 ,   1.4615,   1.738 ,      nan,\n",
       "             nan,   1.722 ,      nan,      nan,   2.796 ,   0.9505,\n",
       "             nan,  11.0875,   0.38  ,   1.7995,   1.453 ,      nan,\n",
       "          1.4645,   1.561 ,      nan,   0.9195,   1.401 ,   0.7995,\n",
       "          0.    ,   0.8155,  16.5265,      nan,   0.74  ,   1.05  ,\n",
       "             nan,   1.2705,      nan,   0.9995,   1.1525,   2.028 ,\n",
       "          1.31  ,      nan,      nan,   1.032 ,      nan,   1.8355,\n",
       "          0.9655,      nan,   0.8875,      nan,      nan,   1.207 ,\n",
       "             nan,   1.12  ,   1.551 ,      nan,      nan,      nan,\n",
       "          1.2535,   1.2   ,   1.4805,      nan,      nan,   1.32  ,\n",
       "             nan,   1.331 ,   1.054 ,   0.602 ,   1.7345,      nan,\n",
       "          1.0685,      nan,   0.76  ,   0.7405,   0.948 ,   0.7195,\n",
       "             nan,  30.1795,      nan,      nan,   1.65  ,   0.9   ,\n",
       "          0.7825,      nan,   0.7615,      nan,      nan,   1.88  ,\n",
       "             nan,      nan,   1.3575,   1.05  ,   1.04  ,   1.223 ,\n",
       "             nan,      nan,      nan,   0.722 ,      nan,      nan,\n",
       "          1.2755,      nan,   1.028 ,      nan,   0.7905,   2.115 ,\n",
       "          1.3985,   1.2035,   1.3735,      nan,      nan,   1.0005,\n",
       "          0.6995,      nan,      nan,   1.114 ,   2.12  ,      nan,\n",
       "          1.0895,      nan,   0.6   ,      nan,      nan,      nan,\n",
       "             nan,   0.871 ,   1.139 ,   1.18  ,   1.0005,   1.593 ,\n",
       "          0.7385,   1.02  ,      nan,   1.35  ,      nan,   1.61  ,\n",
       "          0.9465,   0.607 ,      nan,   1.835 ,      nan,      nan,\n",
       "          0.828 ,   0.945 ,   0.96  ,   0.472 ,   1.6635,      nan,\n",
       "             nan,   1.089 ,      nan,      nan,      nan,      nan,\n",
       "          1.586 ,   1.576 ,   2.18  ,      nan,      nan,   0.32  ,\n",
       "          1.1335,      nan,   0.54  ,      nan,      nan,      nan,\n",
       "          0.742 ,      nan,      nan,      nan,      nan,   1.331 ,\n",
       "          0.845 ,   1.486 ,   1.126 ,      nan,   0.546 ,   1.7295,\n",
       "             nan,   1.0185,   1.268 ,   2.26  ,      nan,      nan,\n",
       "             nan,   0.843 ,   1.5   ,   1.1455,   1.768 ,   1.744 ,\n",
       "             nan,   1.576 ,      nan,      nan,   1.136 ,  26.4275,\n",
       "             nan,   0.7005,      nan,   0.725 ,   0.887 ,   1.69  ,\n",
       "          0.    ,   2.05  ,   1.2035,   1.934 ,      nan,      nan,\n",
       "         67.6165,   0.    ,   1.4665,      nan,      nan,   1.1625,\n",
       "             nan,   1.1985,   0.4335,   2.13  ,   0.7445,      nan,\n",
       "          1.193 ,   1.3935,   1.0825,   1.7505,      nan,      nan,\n",
       "          1.4145,   2.06  ,   2.0035,   1.12  ,   1.044 ,   1.3455,\n",
       "          1.27  ,   1.053 ,      nan,   0.809 ,   1.604 ,   1.805 ,\n",
       "          1.6735,   1.139 ,      nan,   0.4915,   1.1425,   1.0345,\n",
       "          0.638 ,   1.4725,   2.053 ,   1.6105,      nan,      nan,\n",
       "             nan,   1.56  ,   1.1615,      nan,      nan,   1.153 ,\n",
       "          1.979 ,   2.075 ,   2.971 ,   1.4735,   0.315 ,   0.8475,\n",
       "             nan,   0.413 ,      nan,      nan,      nan,      nan,\n",
       "          0.696 ,      nan,      nan,   1.364 ,   0.8805,      nan,\n",
       "          1.5985,      nan,      nan,      nan,      nan,   1.415 ,\n",
       "             nan,      nan,      nan,      nan,   1.8205,   1.1865,\n",
       "             nan,   1.53  ,   1.0445,   1.7   ,      nan,      nan,\n",
       "          1.236 ,   1.559 ,      nan,      nan,      nan,   1.2725,\n",
       "             nan,      nan,      nan,   1.3655,      nan,      nan,\n",
       "             nan,   1.105 ,      nan,   1.045 ,   0.9425,   1.0365,\n",
       "             nan,   0.936 ,      nan,   0.    ,      nan,   0.6315,\n",
       "             nan,   1.071 ,   2.125 ,      nan,      nan,      nan,\n",
       "          1.4935,      nan,   1.3145,   1.3155,   2.18  ,      nan,\n",
       "          1.1365,      nan,   0.9955,      nan,      nan,      nan,\n",
       "             nan,   1.3925,   1.3075,   1.4055,   1.4045,      nan,\n",
       "          1.    ,      nan,   1.    ,      nan,   2.26  ,      nan,\n",
       "             nan,      nan,   1.4715,   1.3585,   1.108 ,      nan,\n",
       "             nan,   1.689 ,   1.11  ,  11.6405,   1.0495,      nan,\n",
       "             nan,   0.82  ,   1.98  ,      nan,   1.1   ,   1.273 ,\n",
       "             nan,   1.1275,   2.2795,   1.757 ,      nan,   0.543 ,\n",
       "          1.91  ,   1.435 ,   1.2875,   1.4145,   1.02  ,      nan,\n",
       "          1.4455,      nan,   0.    ,   1.3505,      nan,      nan,\n",
       "          0.9175,   1.8735,   1.681 ,   1.23  ,      nan,   1.217 ,\n",
       "             nan,   1.2175,   1.102 ,   1.1935,      nan,      nan,\n",
       "          0.9435,      nan,      nan,      nan,  34.3755,  34.6775,\n",
       "          1.943 ,   2.675 ,      nan,      nan,      nan,   0.8825,\n",
       "             nan,   1.592 ,   1.391 ,   1.0115,  29.724 ,   1.5725,\n",
       "             nan,      nan,   0.991 ,   0.7695,      nan,   0.909 ,\n",
       "          0.654 ,      nan,   1.071 ,      nan,      nan,   0.778 ,\n",
       "          1.422 ,      nan,      nan,      nan,      nan,   1.8055,\n",
       "          1.5405,   0.841 ,   0.6605,      nan,   1.79  ,   1.1245,\n",
       "          0.79  ,      nan,   0.982 ,   1.42  ,  42.5025,   0.5245,\n",
       "             nan,      nan,   2.013 ,      nan,   0.846 ,      nan,\n",
       "             nan,   0.    ,      nan,   0.95  ,   2.2295,   0.946 ,\n",
       "             nan,   0.623 ,      nan,   1.0555,      nan,      nan,\n",
       "          0.7485,      nan,   0.452 ,   1.5   ,   1.4245,   0.91  ,\n",
       "             nan,   2.214 ,   1.901 ,   1.041 ,   0.92  ,   1.44  ,\n",
       "          0.895 ,   1.3275,   0.9895,   1.6585,      nan,      nan,\n",
       "          2.239 ,   0.738 ,   1.2495,   0.8835,      nan,   1.37  ,\n",
       "             nan,   0.999 ,   1.568 ,  24.8265,      nan,   1.202 ,\n",
       "          2.1345,      nan,      nan,   2.0085,      nan,      nan,\n",
       "          1.36  ,   1.413 ,   0.904 ,   2.08  ,   1.84  ,      nan,\n",
       "             nan,   2.0125,      nan,      nan,      nan,      nan,\n",
       "          1.1225,   0.552 ,      nan,      nan,   0.    ,   1.4675,\n",
       "          1.3845,   1.9355,      nan,      nan,      nan,      nan,\n",
       "             nan,   2.2705,   1.3925,      nan,      nan,   1.0125,\n",
       "          0.5645,      nan,      nan,   0.    ,   1.1115,   0.882 ,\n",
       "          2.01  ,   1.834 ,   1.39  ,   1.05  ,      nan,      nan,\n",
       "          2.15  ,   2.6765,   2.203 ,      nan,      nan,      nan,\n",
       "          0.7765,      nan,   1.4505,   1.53  ,   0.689 ,      nan,\n",
       "             nan,      nan,   1.9055,   0.84  ,      nan,      nan,\n",
       "          1.108 ,   2.1365,   0.9615,   2.26  ,   0.8345,   1.601 ,\n",
       "             nan,   0.682 ,   0.9285,   1.02  ,   2.03  ,   1.658 ,\n",
       "             nan,      nan,   0.5095,      nan,   1.649 ,      nan,\n",
       "          1.251 ,      nan,      nan,      nan,   1.1265,      nan,\n",
       "             nan,   0.685 ,   0.986 ,      nan,   0.928 ,   0.6675,\n",
       "             nan,      nan,   0.721 ,      nan,   2.61  ,   0.8845,\n",
       "          0.866 ,   1.438 ,   0.87  ,   1.7395,   0.7875,   1.2655,\n",
       "             nan,   1.599 ,      nan,   0.9805,  22.1025,   2.15  ,\n",
       "             nan,      nan,   1.274 ,      nan,   0.504 ,      nan,\n",
       "          1.091 ,      nan,      nan,   1.419 ,   0.7755,   1.54  ,\n",
       "          1.3085,   0.8515,   1.71  ,      nan,   2.0775,   0.75  ,\n",
       "             nan,      nan,  63.3085,      nan,      nan,      nan,\n",
       "             nan,   1.54  ,   1.392 ,      nan,   1.0585,   1.437 ,\n",
       "          2.0025,   1.362 ,      nan,   1.241 ,   1.1495,   0.6145,\n",
       "             nan,   1.403 ,   1.079 ,      nan,   0.801 ,   1.73  ,\n",
       "             nan,   1.6035,      nan,   1.2825,      nan,   1.6985,\n",
       "          1.5355,   0.    ,      nan,   1.54  ,   2.393 ,      nan,\n",
       "             nan,   1.0435,   1.0105,      nan,   0.9965,      nan,\n",
       "             nan,   0.536 ,      nan,   0.949 ,   1.1675,      nan,\n",
       "             nan,      nan,   1.505 ,   1.8185,      nan,      nan,\n",
       "             nan,   1.8285,   0.9965,   1.563 ,   1.5085,      nan,\n",
       "             nan,   2.23  ,      nan,      nan,   2.127 ,   2.224 ,\n",
       "          0.8035,   1.2305,   0.96  ,      nan,      nan,   1.89  ,\n",
       "             nan,      nan,      nan,   0.58  ,   2.6435,      nan,\n",
       "          1.716 ,   1.7   ,   1.0195,      nan,   0.868 ,      nan,\n",
       "             nan,      nan,      nan,      nan,   0.72  ,      nan,\n",
       "             nan,   1.742 ,      nan,   0.8355,      nan,   1.4475,\n",
       "             nan,      nan,   1.1465,   1.645 ,      nan,   1.64  ,\n",
       "         34.3115,   1.025 ,      nan,   1.26  ,   0.5295,      nan,\n",
       "             nan,      nan,      nan,   0.9975,   0.7265,   1.0915,\n",
       "          0.    ,   0.8385,      nan,      nan,   0.8715,   2.382 ,\n",
       "          1.4655,   1.3275,      nan,   0.949 ,      nan,      nan,\n",
       "          2.1075,      nan,      nan,   1.8125,      nan,   1.5305,\n",
       "          0.5915,      nan,  39.799 ,      nan,   0.82  ,      nan,\n",
       "          1.509 ,      nan,  60.738 ,   1.304 ,   1.887 ,   0.9375,\n",
       "          1.5575,   0.33  ,      nan,      nan,      nan,      nan,\n",
       "             nan,   1.08  ,   1.181 ,      nan,   0.763 ,   0.5955,\n",
       "          2.19  ,      nan,   1.429 ,      nan,      nan,      nan,\n",
       "          0.747 ,   1.813 ,      nan,   0.556 ,      nan,      nan,\n",
       "             nan,      nan,      nan,   1.835 ,   1.55  ,   1.4815,\n",
       "          0.7825,   0.5555,   1.309 ]),\n",
       " 'f13': array([ 16.6165,  39.381 ,  36.1655,  39.329 ,      nan,  31.3025,\n",
       "         18.3435,  12.6605,      nan,      nan,      nan,  28.405 ,\n",
       "             nan,   0.    ,      nan,  20.96  ,  14.95  ,  59.6315,\n",
       "             nan,  40.82  ,  22.2535,  44.527 ,  32.282 ,  26.942 ,\n",
       "             nan,  50.04  ,      nan,  46.633 ,      nan,  42.7685,\n",
       "             nan,      nan,      nan,  57.79  ,  35.7735,      nan,\n",
       "         83.467 ,  31.999 ,  31.33  ,  32.9205,      nan,      nan,\n",
       "         40.43  ,      nan,  27.2355,      nan,  32.64  ,  21.0665,\n",
       "             nan,      nan,      nan,      nan,  21.095 ,  23.2545,\n",
       "         44.7665,  17.642 ,      nan,  41.3875,      nan,  53.757 ,\n",
       "         53.804 ,      nan,  27.31  ,  30.151 ,      nan,  63.02  ,\n",
       "             nan,  56.2305,  15.0305,  49.31  ,      nan,  77.07  ,\n",
       "         20.048 ,  46.339 ,      nan,      nan,  10.513 ,  64.3245,\n",
       "             nan,      nan,  19.966 ,  33.974 ,      nan,      nan,\n",
       "             nan,  16.087 ,      nan,      nan,      nan,  28.6275,\n",
       "             nan,  21.13  ,      nan,      nan,  12.8145,      nan,\n",
       "             nan,      nan,      nan,      nan,      nan,      nan,\n",
       "             nan,  35.682 ,  61.83  ,      nan,  37.2125,  36.247 ,\n",
       "             nan,      nan,  30.9585,  32.4135,  31.233 ,      nan,\n",
       "             nan,  39.479 ,      nan,      nan,  79.1495,  52.8855,\n",
       "             nan,      nan,  18.52  ,  23.4045,  30.7655,      nan,\n",
       "         24.991 ,  33.753 ,      nan,  33.0565,  36.298 ,  11.729 ,\n",
       "          0.    ,  37.038 ,      nan,      nan,  38.23  ,  18.7505,\n",
       "             nan,   8.608 ,      nan,  30.0345,  26.7505,  32.4775,\n",
       "         50.62  ,      nan,      nan,  18.0775,      nan,  24.6115,\n",
       "         20.845 ,      nan,  16.513 ,      nan,      nan,  52.2445,\n",
       "             nan,  32.416 ,  42.654 ,      nan,      nan,      nan,\n",
       "         30.5675,  27.828 ,  40.757 ,      nan,      nan,  41.71  ,\n",
       "             nan,  51.104 ,  20.907 ,   8.1975,  28.1275,      nan,\n",
       "         32.009 ,      nan,  11.22  ,  12.3585,  15.5045,  15.2605,\n",
       "             nan,      nan,      nan,      nan,  39.22  ,   0.    ,\n",
       "         25.7195,      nan,  22.7265,      nan,      nan,  40.7125,\n",
       "             nan,      nan,  32.984 ,  46.2   ,  29.567 ,  15.142 ,\n",
       "             nan,      nan,      nan,  17.647 ,      nan,      nan,\n",
       "         13.5455,      nan,  27.44  ,      nan,  19.748 ,  43.639 ,\n",
       "         36.7335,  36.7905,  43.9425,      nan,      nan,  18.476 ,\n",
       "         10.03  ,      nan,      nan,  48.556 ,  48.223 ,      nan,\n",
       "         38.5765,      nan,  37.95  ,      nan,      nan,      nan,\n",
       "             nan,  26.695 ,  42.2375,  16.63  ,  26.8415,  41.6415,\n",
       "         18.456 ,  22.697 ,      nan,  22.3   ,      nan,  88.0235,\n",
       "         24.8475,  27.9265,      nan,  32.363 ,      nan,      nan,\n",
       "         13.62  ,  31.562 ,  40.2415,  20.263 ,  33.959 ,      nan,\n",
       "             nan,  26.283 ,      nan,      nan,      nan,      nan,\n",
       "         34.157 ,  46.293 ,  41.048 ,      nan,      nan,  17.03  ,\n",
       "         19.812 ,      nan,  41.16  ,      nan,      nan,      nan,\n",
       "         19.7365,      nan,      nan,      nan,      nan,  28.933 ,\n",
       "         20.861 ,  33.5815,  12.4605,      nan,  19.7545,  52.817 ,\n",
       "             nan,  27.2445,  38.3775,  95.77  ,      nan,      nan,\n",
       "             nan,  15.071 ,  21.5   ,  28.138 ,  32.581 ,  36.014 ,\n",
       "             nan,  33.5765,      nan,      nan,  50.92  ,      nan,\n",
       "             nan,  24.423 ,      nan,  14.5875,  15.925 ,  51.19  ,\n",
       "          0.    ,  33.4   ,  52.8725,  36.1415,      nan,      nan,\n",
       "             nan,   0.    ,  36.2235,      nan,      nan,  33.418 ,\n",
       "             nan,  29.2575,  23.432 ,  60.41  ,  17.1385,      nan,\n",
       "         23.54  ,  16.609 ,  22.35  ,  25.0015,      nan,      nan,\n",
       "         60.8355,  40.58  ,  49.3365,  50.96  ,  17.1995,  18.9715,\n",
       "         50.73  ,   0.    ,      nan,  28.959 ,  44.608 ,  31.4775,\n",
       "         53.45  ,  29.883 ,      nan,  11.8725,  45.1485,  11.37  ,\n",
       "         16.788 ,  63.941 ,  65.054 ,  44.7015,      nan,      nan,\n",
       "             nan,  55.1   ,  21.51  ,      nan,      nan,  51.8385,\n",
       "         20.366 ,  33.5515,  49.8135,  52.5805,   8.041 ,  13.4565,\n",
       "             nan,  15.1005,      nan,      nan,      nan,      nan,\n",
       "         24.3865,      nan,      nan,  49.5115,  39.061 ,      nan,\n",
       "         46.612 ,      nan,      nan,      nan,      nan,  12.9225,\n",
       "             nan,      nan,      nan,      nan,  53.7955,  24.3035,\n",
       "             nan,   0.    ,  24.4395,  62.641 ,      nan,      nan,\n",
       "         30.3515,   0.    ,      nan,      nan,      nan,  27.755 ,\n",
       "             nan,      nan,      nan,  23.568 ,      nan,      nan,\n",
       "             nan,  12.324 ,      nan,  19.994 ,  18.7295,  49.029 ,\n",
       "             nan,  12.598 ,      nan,   0.    ,      nan,  13.021 ,\n",
       "             nan,  24.7375,  49.0145,      nan,      nan,      nan,\n",
       "         38.434 ,      nan,  57.336 ,  43.332 ,  61.55  ,      nan,\n",
       "         42.889 ,      nan,  11.5375,      nan,      nan,      nan,\n",
       "             nan,  20.1955,  51.576 ,  31.42  ,  39.9855,      nan,\n",
       "         46.72  ,      nan,  31.11  ,      nan,  42.0355,      nan,\n",
       "             nan,      nan,  22.1285,  42.0675,  29.345 ,      nan,\n",
       "             nan,  66.397 ,  13.3985,      nan,  22.438 ,      nan,\n",
       "             nan,  33.52  ,  51.05  ,      nan,  65.3   ,  32.003 ,\n",
       "             nan,  30.728 ,  22.5485,  45.25  ,      nan,  30.0475,\n",
       "         37.89  ,  34.4305,  26.935 ,  31.882 ,  27.64  ,      nan,\n",
       "         24.776 ,      nan,  19.048 ,  41.5715,      nan,      nan,\n",
       "         39.2365,  51.0625,  32.242 ,  38.09  ,      nan,  36.3735,\n",
       "             nan,  39.6955,  30.3885,  40.919 ,      nan,      nan,\n",
       "         22.539 ,      nan,      nan,      nan,      nan,      nan,\n",
       "         21.4415,  34.0135,      nan,      nan,      nan,  29.225 ,\n",
       "             nan,  19.428 ,  16.6095,  30.514 ,      nan,  53.7945,\n",
       "             nan,      nan,  26.472 ,  27.9145,      nan,  15.3895,\n",
       "         24.1155,      nan,  25.6555,      nan,      nan,   8.787 ,\n",
       "         36.3325,      nan,      nan,      nan,      nan,  33.011 ,\n",
       "         35.0305,  31.9675,  14.8245,      nan,  53.03  ,  23.9495,\n",
       "         41.6   ,      nan,  36.373 ,  38.09  ,      nan,  23.419 ,\n",
       "             nan,      nan,  17.4815,      nan,  42.092 ,      nan,\n",
       "             nan,   0.    ,      nan,  36.17  ,  38.012 ,  59.7095,\n",
       "             nan,  22.2895,      nan,  33.8345,      nan,      nan,\n",
       "          3.307 ,      nan,  48.933 ,  56.86  ,  28.803 ,  30.8   ,\n",
       "             nan,  86.246 ,  29.1145,  19.7315,  46.23  ,  52.44  ,\n",
       "         17.02  ,  37.8385,  31.7385,  34.1885,      nan,      nan,\n",
       "         52.0525,  14.111 ,  30.183 ,  33.908 ,      nan,  60.04  ,\n",
       "             nan,  34.645 ,  24.75  ,      nan,      nan,  26.2315,\n",
       "         23.977 ,      nan,      nan,  26.91  ,      nan,      nan,\n",
       "         48.5845,  33.0785,  41.256 ,  55.72  ,  36.66  ,      nan,\n",
       "             nan,  43.908 ,      nan,      nan,      nan,      nan,\n",
       "         28.64  ,  21.3845,      nan,      nan,   0.    ,  29.932 ,\n",
       "         26.6945,  56.0385,      nan,      nan,      nan,      nan,\n",
       "             nan,  32.5595,  45.9585,      nan,      nan,  25.034 ,\n",
       "         24.2675,      nan,      nan,   0.    ,  22.353 ,  17.832 ,\n",
       "         86.4   ,  67.238 ,  68.58  ,  27.3245,      nan,      nan,\n",
       "         77.81  ,  41.0335,  73.647 ,      nan,      nan,      nan,\n",
       "          7.5935,      nan,  33.4005,  34.91  ,  17.264 ,      nan,\n",
       "             nan,      nan,  26.5645,  17.256 ,      nan,      nan,\n",
       "         37.9245,  38.727 ,  36.1195,  42.51  ,  17.8935,  17.1905,\n",
       "             nan,  19.812 ,  34.6355,  41.01  ,  60.    ,  41.424 ,\n",
       "             nan,      nan,  10.409 ,      nan,  59.281 ,      nan,\n",
       "         18.5015,      nan,      nan,      nan,  38.859 ,      nan,\n",
       "             nan,  19.584 ,  28.0735,      nan,  24.0385,  23.451 ,\n",
       "             nan,      nan,  32.486 ,      nan,  47.72  ,  19.338 ,\n",
       "         16.7415,  34.982 ,  48.57  ,  35.0995,  18.6735,  37.943 ,\n",
       "             nan,  53.631 ,      nan,  34.305 ,      nan,  74.72  ,\n",
       "             nan,      nan,  31.837 ,      nan,  14.692 ,      nan,\n",
       "         30.0215,      nan,      nan,  53.627 ,  30.7365,  65.62  ,\n",
       "         80.354 ,  29.7515,  67.35  ,      nan,  30.4555,  19.05  ,\n",
       "             nan,      nan,      nan,      nan,      nan,      nan,\n",
       "             nan,  45.1275,  22.1215,      nan,  39.2135,  51.8295,\n",
       "         40.384 ,  39.9695,      nan,  24.256 ,  26.7385,  16.668 ,\n",
       "             nan,  35.184 ,  39.926 ,      nan,  27.7185,  34.4475,\n",
       "             nan,  49.3475,      nan,  21.737 ,      nan,  37.1795,\n",
       "         22.4365,   0.    ,      nan,  27.95  ,  33.024 ,      nan,\n",
       "             nan,  22.5115,  36.1535,      nan,  24.9775,      nan,\n",
       "             nan,  13.4345,      nan,   0.    ,  16.5675,      nan,\n",
       "             nan,      nan,  61.012 ,  41.0565,      nan,      nan,\n",
       "             nan,  73.0795,  35.6365,  39.7065,  60.952 ,      nan,\n",
       "             nan,  43.    ,      nan,      nan,  44.618 ,  37.5345,\n",
       "         30.172 ,  22.4065,  53.68  ,      nan,      nan,  67.42  ,\n",
       "             nan,      nan,      nan,  17.1   ,  49.91  ,      nan,\n",
       "         51.8675,  65.38  ,  19.6245,      nan,  20.008 ,      nan,\n",
       "             nan,      nan,      nan,      nan,  44.06  ,      nan,\n",
       "             nan,  40.7835,      nan,  31.5805,      nan,  29.1715,\n",
       "             nan,      nan,  55.069 ,  30.4135,      nan,  80.16  ,\n",
       "             nan,  29.1705,      nan,  21.7175,  22.518 ,      nan,\n",
       "             nan,      nan,      nan,  41.838 ,  15.8845,  19.7565,\n",
       "          0.    ,  25.223 ,      nan,      nan,  51.1115,  56.002 ,\n",
       "         47.991 ,  40.0805,      nan,  43.7765,      nan,      nan,\n",
       "         31.6935,      nan,      nan,  32.124 ,      nan,  47.473 ,\n",
       "         19.532 ,      nan,      nan,      nan,  44.03  ,      nan,\n",
       "         39.307 ,      nan,      nan,  31.371 ,  42.327 ,  37.9285,\n",
       "         44.849 ,  46.32  ,      nan,      nan,      nan,      nan,\n",
       "             nan,  84.1   ,  30.83  ,      nan,  35.8605,  14.6855,\n",
       "         88.96  ,      nan,  22.6625,      nan,      nan,      nan,\n",
       "         26.9815,  44.8795,      nan,  10.371 ,      nan,      nan,\n",
       "             nan,      nan,      nan,  38.453 ,  48.2375,  42.8325,\n",
       "         26.5845,  11.9505,  51.1875]),\n",
       " 'f2': array([1, 3, 3, 2, 3, 1, 2, 2, 4, 3, 4, 2, 3, 2, 3, 2, 1, 2, 3, 3, 3, 2, 3,\n",
       "        1, 3, 3, 3, 4, 1, 3, 1, 4, 4, 3, 3, 4, 3, 3, 3, 3, 3, 2, 3, 1, 3, 3,\n",
       "        2, 2, 2, 2, 3, 2, 2, 1, 2, 2, 2, 4, 3, 2, 4, 3, 2, 2, 3, 2, 3, 3, 1,\n",
       "        3, 2, 2, 3, 2, 3, 3, 2, 3, 3, 2, 3, 4, 3, 3, 1, 2, 2, 2, 2, 3, 4, 2,\n",
       "        3, 3, 2, 2, 2, 2, 2, 3, 3, 3, 3, 2, 3, 3, 2, 3, 2, 4, 1, 1, 3, 3, 2,\n",
       "        2, 2, 4, 2, 3, 1, 3, 1, 3, 3, 2, 1, 4, 3, 4, 2, 3, 4, 1, 2, 2, 3, 1,\n",
       "        4, 3, 2, 4, 2, 2, 2, 3, 3, 3, 4, 1, 2, 2, 1, 3, 2, 4, 3, 1, 2, 1, 2,\n",
       "        2, 3, 4, 3, 2, 1, 2, 3, 2, 3, 2, 2, 1, 3, 3, 4, 2, 2, 4, 2, 2, 2, 3,\n",
       "        3, 3, 3, 3, 1, 2, 2, 2, 3, 1, 4, 4, 2, 3, 3, 2, 2, 3, 3, 3, 2, 4, 2,\n",
       "        3, 2, 3, 4, 4, 3, 1, 3, 3, 2, 3, 3, 2, 2, 3, 1, 3, 2, 4, 3, 1, 2, 1,\n",
       "        2, 3, 3, 2, 3, 2, 2, 2, 3, 3, 2, 3, 3, 1, 2, 3, 3, 2, 3, 3, 2, 3, 3,\n",
       "        3, 3, 1, 2, 1, 2, 1, 1, 2, 3, 3, 2, 1, 1, 2, 3, 1, 3, 3, 3, 3, 2, 4,\n",
       "        3, 2, 4, 3, 2, 2, 3, 3, 3, 2, 1, 3, 1, 1, 2, 2, 4, 4, 1, 3, 2, 4, 3,\n",
       "        4, 3, 1, 3, 3, 1, 3, 2, 3, 3, 4, 1, 1, 3, 3, 1, 3, 3, 2, 1, 2, 3, 4,\n",
       "        3, 3, 3, 3, 2, 3, 3, 1, 4, 3, 1, 4, 3, 3, 3, 2, 2, 1, 2, 2, 2, 2, 3,\n",
       "        1, 4, 2, 3, 1, 2, 3, 3, 1, 3, 3, 3, 3, 3, 1, 3, 4, 2, 2, 1, 4, 2, 2,\n",
       "        2, 2, 2, 3, 3, 3, 1, 2, 3, 3, 3, 2, 2, 4, 1, 3, 2, 1, 2, 3, 4, 2, 1,\n",
       "        2, 3, 2, 2, 3, 1, 3, 4, 2, 1, 3, 1, 1, 4, 2, 1, 2, 2, 3, 1, 2, 2, 2,\n",
       "        1, 2, 2, 2, 2, 4, 3, 3, 4, 2, 1, 2, 2, 2, 4, 2, 2, 3, 2, 3, 2, 2, 3,\n",
       "        3, 3, 2, 3, 2, 3, 1, 3, 3, 2, 4, 3, 3, 1, 2, 2, 2, 2, 3, 3, 3, 2, 2,\n",
       "        3, 3, 4, 1, 3, 2, 2, 3, 1, 2, 2, 3, 3, 3, 3, 3, 1, 3, 1, 3, 2, 1, 3,\n",
       "        3, 4, 2, 2, 3, 2, 4, 3, 2, 3, 2, 1, 3, 3, 3, 2, 2, 1, 1, 3, 1, 3, 1,\n",
       "        3, 2, 2, 3, 2, 2, 3, 1, 3, 2, 3, 3, 1, 2, 3, 2, 2, 3, 4, 1, 3, 2, 3,\n",
       "        1, 3, 1, 1, 2, 4, 2, 2, 2, 1, 3, 4, 2, 2, 1, 3, 1, 1, 2, 3, 2, 3, 3,\n",
       "        3, 2, 3, 2, 2, 2, 2, 3, 3, 3, 2, 3, 2, 2, 3, 3, 3, 2, 3, 3, 3, 2, 2,\n",
       "        3, 1, 2, 4, 1, 3, 2, 4, 1, 1, 3, 4, 3, 3, 3, 2, 3, 4, 3, 3, 3, 1, 3,\n",
       "        2, 2, 1, 2, 3, 2, 1, 1, 3, 4, 3, 2, 4, 3, 2, 2, 2, 4, 3, 2, 3, 3, 2,\n",
       "        2, 3, 4, 4, 3, 3, 1, 3, 2, 1, 1, 2, 3, 1, 4, 1, 2, 4, 1, 1, 2, 3, 3,\n",
       "        1, 2, 2, 2, 3, 2, 2, 4, 2, 3, 3, 3, 2, 1, 3, 3, 3, 2, 3, 1, 1, 2, 3,\n",
       "        2, 3, 2, 3, 1, 2, 2, 4, 3, 3, 3, 2, 1, 3, 3, 2, 2, 3, 2, 2, 3, 2, 3,\n",
       "        1, 2, 3, 2, 3, 3, 2, 4, 1, 2, 2, 4, 3, 2, 3, 2, 2, 3, 2, 2, 3, 3, 2,\n",
       "        3, 3, 3, 3, 4, 3, 3, 1, 1, 3, 4, 3, 2, 3, 3, 1, 1, 1, 2, 2, 3, 3, 3,\n",
       "        2, 2, 2, 2, 2, 3, 3, 3, 4, 4, 2, 2, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 2,\n",
       "        1, 1, 4, 3, 3, 3, 3, 1, 2, 2, 3, 3, 1, 3, 4, 1, 3, 3, 3, 1, 1, 3, 2,\n",
       "        1, 3, 2, 4, 3, 1, 3, 3, 3, 2, 3, 2, 2, 4, 1, 4, 3, 2, 4, 1, 1, 1, 3,\n",
       "        3, 3, 1, 1, 4, 2, 3, 3, 3, 2, 3, 3, 2, 3, 1, 2, 1, 1, 2, 3, 1, 3, 3,\n",
       "        3, 3, 2, 3, 3, 3, 3, 1, 2, 2, 3, 3, 2, 2, 2, 4, 1, 1, 1, 3, 2, 3, 2,\n",
       "        1, 2, 2, 3, 2, 2, 3, 3, 3, 2, 3, 2, 3, 1, 3, 3, 1, 2, 1, 3, 2, 3, 2,\n",
       "        3, 3, 3, 3, 3, 3, 3, 2, 4, 4, 1, 3, 1, 2, 2, 3, 3, 2, 3, 3, 3, 1, 3,\n",
       "        3, 1, 2, 3, 4, 2]),\n",
       " 'f3': array([1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 3, 1, 2, 2, 1, 3, 3, 2, 3, 2, 1,\n",
       "        1, 2, 1, 2, 3, 1, 2, 1, 2, 1, 4, 2, 4, 1, 2, 3, 3, 2, 1, 3, 1, 2, 3,\n",
       "        4, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 4, 3, 2, 2, 1, 3, 2, 3, 2, 1, 2, 2,\n",
       "        3, 1, 2, 3, 1, 1, 2, 1, 3, 2, 1, 2, 1, 2, 3, 1, 1, 1, 2, 1, 1, 3, 2,\n",
       "        1, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 3, 2, 1, 3, 1, 1, 1, 1, 2,\n",
       "        3, 1, 2, 3, 3, 2, 1, 1, 1, 2, 2, 1, 3, 1, 4, 1, 1, 1, 1, 1, 1, 2, 1,\n",
       "        2, 1, 2, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 2, 2, 1, 3, 3, 2, 2, 2, 1,\n",
       "        1, 1, 2, 1, 1, 1, 2, 2, 1, 3, 1, 3, 1, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2,\n",
       "        1, 2, 1, 2, 1, 2, 1, 3, 2, 1, 1, 3, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2,\n",
       "        2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 4, 1, 1, 1, 3, 3, 2, 2, 3, 2, 2, 1,\n",
       "        2, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 2, 3, 1, 2, 2, 1, 1, 1, 3, 1, 2, 1,\n",
       "        1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 3, 1, 2, 2, 1, 2, 2, 1,\n",
       "        3, 2, 1, 2, 2, 3, 2, 3, 2, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2,\n",
       "        3, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 3, 2, 2, 1, 2, 2, 2, 1, 3, 2,\n",
       "        2, 2, 2, 1, 4, 2, 4, 2, 4, 2, 1, 1, 3, 1, 1, 1, 1, 2, 1, 2, 3, 2, 3,\n",
       "        2, 2, 1, 2, 2, 2, 4, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 3, 1, 1, 3, 2, 1,\n",
       "        1, 2, 1, 2, 2, 3, 1, 1, 1, 3, 3, 2, 2, 1, 2, 1, 4, 2, 1, 1, 2, 2, 1,\n",
       "        3, 1, 2, 1, 3, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2,\n",
       "        3, 1, 1, 2, 2, 2, 3, 1, 1, 3, 1, 3, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1,\n",
       "        1, 3, 1, 3, 1, 2, 2, 1, 2, 2, 1, 2, 3, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2,\n",
       "        3, 1, 1, 1, 2, 1, 4, 3, 2, 2, 1, 2, 2, 1, 4, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "        3, 1, 1, 1, 2, 1, 2, 3, 2, 2, 3, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 1,\n",
       "        4, 1, 1, 1, 2, 1, 1, 2, 3, 4, 1, 2, 4, 2, 2, 1, 1, 1, 4, 2, 2, 2, 2,\n",
       "        1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 3, 2, 2, 4, 3, 2, 2, 2, 2, 2,\n",
       "        2, 1, 3, 2, 1, 3, 2, 2, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 2, 4, 2, 1, 2,\n",
       "        2, 2, 1, 3, 1, 3, 1, 1, 1, 1, 2, 1, 2, 3, 1, 1, 2, 2, 1, 2, 2, 2, 2,\n",
       "        1, 3, 1, 1, 1, 2, 1, 2, 3, 1, 1, 1, 3, 1, 2, 2, 3, 1, 3, 1, 1, 1, 2,\n",
       "        1, 1, 1, 2, 2, 3, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 3, 1, 1, 1,\n",
       "        2, 1, 1, 2, 1, 2, 1, 3, 2, 2, 3, 2, 2, 2, 3, 1, 3, 3, 2, 1, 1, 1, 2,\n",
       "        3, 2, 1, 1, 1, 1, 1, 1, 2, 2, 3, 1, 1, 1, 2, 1, 2, 1, 1, 2, 3, 1, 1,\n",
       "        1, 2, 2, 2, 2, 1, 1, 3, 2, 1, 1, 2, 2, 2, 1, 3, 1, 2, 1, 2, 2, 2, 1,\n",
       "        1, 2, 3, 2, 3, 3, 2, 2, 2, 3, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 1, 2,\n",
       "        1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 2, 3, 2,\n",
       "        1, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 3, 1, 2, 2, 3, 2,\n",
       "        1, 2, 1, 1, 2, 1, 1, 3, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 3,\n",
       "        2, 1, 3, 4, 1, 2, 2, 1, 1, 2, 2, 2, 1, 4, 2, 1, 1, 1, 1, 2, 2, 2, 3,\n",
       "        1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 3,\n",
       "        1, 2, 1, 2, 2, 2, 1, 2, 1, 1, 3, 4, 2, 1, 1, 2, 1, 2, 1, 1, 3, 1, 1,\n",
       "        3, 2, 2, 1, 1, 2, 2, 1, 3, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1,\n",
       "        1, 1, 1, 2, 2, 2]),\n",
       " 'f4': array([1, 1, 2, 1, 2, 1, 1, 1, 4, 1, 1, 2, 1, 1, 2, 1, 1, 3, 2, 2, 1, 2, 1,\n",
       "        1, 3, 1, 2, 4, 1, 1, 1, 4, 2, 4, 2, 4, 2, 2, 2, 2, 2, 1, 3, 1, 1, 2,\n",
       "        2, 1, 3, 3, 3, 1, 2, 1, 3, 1, 1, 2, 2, 2, 2, 2, 2, 1, 3, 2, 2, 2, 2,\n",
       "        3, 1, 1, 2, 1, 2, 2, 1, 3, 1, 1, 2, 4, 3, 4, 1, 2, 1, 1, 1, 4, 1, 2,\n",
       "        1, 4, 2, 2, 2, 1, 3, 2, 1, 1, 2, 1, 3, 2, 2, 3, 1, 2, 1, 1, 1, 1, 1,\n",
       "        1, 3, 4, 2, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 4, 1, 1, 1, 2, 1, 1, 2, 1,\n",
       "        2, 1, 1, 3, 4, 1, 1, 2, 3, 2, 1, 2, 1, 1, 1, 2, 2, 4, 3, 1, 2, 3, 1,\n",
       "        1, 1, 2, 1, 2, 1, 2, 2, 1, 3, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "        1, 1, 3, 3, 1, 1, 1, 3, 1, 1, 1, 1, 4, 2, 1, 2, 1, 1, 1, 1, 1, 4, 1,\n",
       "        3, 1, 1, 4, 1, 2, 3, 2, 1, 2, 1, 3, 4, 1, 3, 2, 1, 2, 1, 1, 1, 2, 1,\n",
       "        2, 4, 1, 2, 3, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 2, 1, 2, 2, 3, 1, 1, 1,\n",
       "        3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 3, 1, 2, 2, 1,\n",
       "        1, 3, 3, 1, 1, 2, 1, 3, 2, 2, 1, 2, 2, 4, 2, 2, 1, 2, 1, 3, 1, 1, 3,\n",
       "        3, 3, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 3, 2, 1, 1, 2, 1, 1, 1, 3, 2,\n",
       "        1, 3, 1, 2, 1, 3, 3, 2, 4, 3, 1, 4, 1, 3, 2, 2, 1, 1, 1, 1, 3, 2, 1,\n",
       "        1, 2, 1, 1, 1, 2, 3, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 3, 1, 1,\n",
       "        1, 1, 1, 2, 3, 2, 1, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1,\n",
       "        1, 3, 1, 1, 3, 1, 2, 4, 2, 2, 3, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2,\n",
       "        2, 1, 2, 1, 2, 4, 3, 1, 4, 2, 2, 2, 2, 1, 3, 1, 1, 2, 2, 2, 2, 2, 3,\n",
       "        3, 2, 2, 2, 1, 1, 1, 1, 2, 2, 1, 3, 3, 1, 1, 1, 1, 1, 2, 2, 3, 1, 1,\n",
       "        2, 3, 1, 1, 2, 2, 2, 3, 1, 1, 1, 2, 1, 1, 2, 3, 4, 1, 1, 2, 1, 1, 2,\n",
       "        2, 2, 2, 2, 3, 1, 1, 3, 2, 2, 2, 1, 1, 2, 2, 1, 4, 1, 1, 1, 2, 1, 1,\n",
       "        2, 1, 1, 2, 1, 1, 2, 3, 3, 1, 1, 3, 2, 1, 2, 1, 2, 1, 4, 1, 1, 1, 1,\n",
       "        1, 2, 2, 1, 2, 4, 2, 1, 1, 2, 3, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "        3, 2, 3, 2, 1, 3, 1, 2, 2, 1, 1, 1, 1, 1, 3, 1, 3, 3, 3, 4, 2, 1, 1,\n",
       "        3, 1, 2, 4, 1, 3, 1, 1, 2, 1, 1, 4, 2, 3, 1, 1, 1, 2, 1, 2, 3, 1, 1,\n",
       "        2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 3, 2, 1, 1, 2, 1, 1, 1, 2, 1, 3, 1, 2,\n",
       "        2, 2, 1, 1, 1, 3, 1, 2, 2, 1, 1, 1, 1, 1, 4, 2, 2, 3, 2, 2, 1, 2, 2,\n",
       "        1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 3, 2, 1, 2, 3, 1, 3, 1, 1, 2, 1, 1, 2,\n",
       "        4, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "        1, 2, 1, 1, 1, 3, 1, 3, 1, 4, 2, 2, 2, 1, 2, 3, 1, 3, 1, 1, 2, 1, 1,\n",
       "        1, 2, 1, 3, 2, 2, 2, 2, 2, 3, 1, 3, 1, 2, 2, 1, 1, 1, 3, 1, 1, 2, 1,\n",
       "        1, 1, 2, 3, 2, 2, 3, 1, 1, 2, 2, 1, 2, 2, 3, 1, 3, 1, 2, 1, 2, 2, 1,\n",
       "        1, 3, 1, 3, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 3, 1, 2, 3, 1, 2, 1, 3, 2,\n",
       "        1, 1, 3, 2, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 3, 2, 1, 4, 1, 1, 1, 3,\n",
       "        1, 1, 3, 2, 3, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 3, 1, 2, 3, 1, 2, 2,\n",
       "        2, 1, 1, 4, 1, 2, 2, 4, 1, 1, 2, 2, 1, 1, 2, 4, 1, 2, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 2, 4, 1, 2, 2, 1, 1, 1, 1, 1, 3, 3, 2,\n",
       "        3, 2, 1, 1, 2, 1, 1, 2, 3, 4, 1, 1, 1, 1, 1, 3, 2, 2, 1, 2, 3, 2, 2,\n",
       "        2, 1, 2, 3, 2, 2]),\n",
       " 'f5': array([  1.,   1.,   2.,   2.,   2.,   2.,   1.,   1.,   4.,   1.,   2.,\n",
       "          2.,   3.,   1.,   2.,   2.,   1.,   2.,   2.,   1.,   2.,   3.,\n",
       "          2.,   1.,   3.,   2.,   1.,   3.,   1.,   3.,   2.,   2.,   2.,\n",
       "          2.,   1.,   4.,   2.,   2.,   1.,   3.,   3.,   2.,   2.,   2.,\n",
       "          2.,   3.,   1.,   1.,   3.,   2.,   2.,   2.,   1.,   1.,   2.,\n",
       "          2.,   1.,   2.,   3.,   1.,   2.,   2.,   3.,   1.,   2.,   2.,\n",
       "          1.,   2.,   2.,   2.,   2.,   2.,   3.,   2.,   3.,   2.,   1.,\n",
       "          2.,   2.,   1.,   1.,   2.,   2.,   3.,   1.,   2.,   1.,   3.,\n",
       "          1.,   1.,   2.,   2.,   2.,   1.,   3.,   1.,   2.,   2.,   3.,\n",
       "          1.,   1.,   2.,   3.,   1.,   3.,   2.,   2.,   3.,   1.,   2.,\n",
       "          1.,   1.,   2.,   2.,   1.,   2.,   1.,   1.,   3.,   2.,   1.,\n",
       "          2.,   3.,   2.,   2.,   2.,   1.,   1.,   1.,   4.,   1.,   1.,\n",
       "          2.,   2.,   1.,   1.,   1.,   1.,   2.,   2.,   2.,   1.,   1.,\n",
       "          2.,   1.,   2.,   3.,   1.,   1.,   3.,   1.,   1.,   1.,   2.,\n",
       "          2.,   4.,   3.,   1.,   1.,   3.,   2.,   2.,   1.,   2.,   2.,\n",
       "          1.,   2.,   2.,   1.,   1.,   3.,   2.,   3.,   1.,   2.,   1.,\n",
       "          1.,   1.,   2.,   1.,   2.,   1.,   1.,   2.,   1.,   3.,   2.,\n",
       "          3.,   1.,   3.,   1.,   2.,   2.,   1.,   3.,   1.,   1.,   3.,\n",
       "          1.,   2.,   1.,   1.,   2.,   1.,   1.,   3.,   2.,   2.,   1.,\n",
       "          1.,   4.,   2.,   2.,   1.,   1.,   2.,   1.,   1.,   2.,   2.,\n",
       "          1.,   1.,   2.,   2.,   2.,   2.,   2.,   2.,   2.,   1.,   1.,\n",
       "          1.,   2.,   2.,   1.,   1.,   1.,   2.,   3.,   2.,   1.,   2.,\n",
       "          2.,   2.,   1.,   1.,   1.,   1.,   2.,   2.,   1.,   2.,   3.,\n",
       "          1.,   2.,   1.,   1.,   2.,   2.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   2.,   1.,   2.,   1.,   3.,   2.,   2.,   2.,   2.,\n",
       "          2.,   3.,   2.,   1.,   1.,   2.,   3.,   1.,   2.,   2.,   2.,\n",
       "          1.,   1.,   2.,   2.,   1.,   1.,   2.,   2.,   1.,   1.,   2.,\n",
       "          3.,   1.,   3.,   2.,   2.,   2.,   1.,   1.,   1.,   1.,   3.,\n",
       "          2.,   2.,   2.,   1.,   3.,   1.,   1.,   1.,   2.,   2.,   2.,\n",
       "          1.,   2.,   2.,   2.,   3.,   2.,   2.,   3.,   2.,   3.,   2.,\n",
       "          2.,   3.,   2.,   3.,   2.,   1.,   2.,   2.,   1.,   2.,   1.,\n",
       "          1.,   3.,   1.,   2.,   1.,   3.,   1.,   2.,   2.,   2.,   3.,\n",
       "          2.,   1.,   1.,   2.,   2.,   2.,   2.,   1.,   2.,   2.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   2.,   1.,   2.,   3.,   2.,   2.,\n",
       "          2.,   1.,   1.,   2.,   3.,   2.,   1.,   4.,   1.,   1.,   1.,\n",
       "          2.,   2.,   2.,   3.,   2.,   2.,   2.,   1.,   2.,   1.,   3.,\n",
       "          1.,   1.,   2.,   2.,   3.,   2.,   1.,   1.,   2.,   1.,   3.,\n",
       "          1.,   2.,   1.,   1.,   1.,   2.,   2.,   1.,   1.,   2.,   2.,\n",
       "          2.,   1.,   3.,   2.,   4.,   2.,   2.,   3.,   2.,   2.,   2.,\n",
       "          1.,   2.,   2.,   2.,   2.,   1.,   2.,   3.,   3.,   3.,   1.,\n",
       "          2.,   1.,   3.,   1.,   1.,   2.,   2.,   2.,   2.,   3.,   1.,\n",
       "          2.,   1.,   2.,   2.,   2.,   1.,   2.,   1.,   2.,   3.,   2.,\n",
       "          1.,   2.,   2.,   2.,   3.,   3.,   1.,   2.,   1.,   3.,   2.,\n",
       "          1.,   2.,   3.,   1.,   1.,   2.,   2.,   2.,   1.,   1.,   3.,\n",
       "          3.,   2.,   1.,  nan,   1.,   2.,   3.,   2.,   1.,   3.,   1.,\n",
       "          2.,   2.,   1.,   1.,   1.,   2.,   1.,   3.,   1.,   1.,   1.,\n",
       "          3.,   1.,   1.,   2.,   2.,   1.,   1.,   2.,   3.,   2.,   2.,\n",
       "          2.,   2.,   2.,   2.,   1.,   2.,   2.,   2.,   1.,   2.,   1.,\n",
       "          1.,   1.,   3.,   1.,   1.,   1.,   2.,   2.,   1.,   1.,   1.,\n",
       "          3.,   2.,   2.,   3.,   1.,   1.,   1.,   2.,   1.,   2.,   2.,\n",
       "          2.,   1.,   2.,   3.,   1.,   3.,   2.,   3.,   1.,   1.,   3.,\n",
       "          2.,   1.,   2.,   1.,   1.,   2.,   2.,   4.,   2.,   2.,   3.,\n",
       "          3.,   1.,   1.,   2.,   2.,   2.,   3.,   1.,   4.,   1.,   1.,\n",
       "          1.,   1.,   2.,   2.,   2.,   3.,   2.,   1.,   1.,   1.,   1.,\n",
       "          2.,   3.,   1.,   2.,   2.,   2.,   2.,   3.,   2.,   1.,   2.,\n",
       "          1.,   2.,   2.,   2.,   2.,   3.,   2.,   2.,   1.,   1.,   1.,\n",
       "          3.,   2.,   1.,   2.,   1.,   1.,   3.,   4.,   2.,   1.,   4.,\n",
       "          1.,   2.,   1.,   1.,   1.,   2.,   1.,   2.,   2.,   2.,   1.,\n",
       "          3.,   2.,   3.,   1.,   2.,   3.,   1.,   2.,   1.,   1.,   1.,\n",
       "          2.,   1.,   3.,   1.,   1.,   3.,   2.,   1.,   3.,   3.,   1.,\n",
       "          3.,   1.,   2.,   3.,   1.,   2.,   2.,   1.,   3.,   2.,   2.,\n",
       "          2.,   1.,   1.,   2.,   2.,   2.,   3.,   1.,   1.,   3.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   3.,   2.,   2.,   1.,   2.,   2.,\n",
       "          2.,   2.,   2.,   3.,   2.,   2.,   1.,   1.,   1.,   2.,   2.,\n",
       "          2.,   2.,   2.,   3.,   1.,   1.,   2.,   2.,   1.,   1.,   2.,\n",
       "          1.,   3.,   3.,   3.,   3.,   2.,   2.,   3.,   1.,   3.,   1.,\n",
       "          1.,   2.,   2.,   1.,   1.,   1.,   2.,   3.,   1.,   2.,   1.,\n",
       "          1.,   2.,   2.,   2.,   2.,   3.,   2.,   3.,   2.,   1.,   2.,\n",
       "          1.,   2.,   2.,   1.,   2.,   1.,   2.,   2.,   1.,   2.,   3.,\n",
       "          2.,   2.,   2.,   1.,   3.,   2.,   2.,   2.,   2.,   2.,   2.,\n",
       "          3.,   1.,   2.,   3.,   2.,   2.,   3.,   1.,   3.,   1.,   3.,\n",
       "          2.,   2.,   2.,   2.,   2.,   2.,   1.,   2.,   3.,   1.,   1.,\n",
       "          2.,   1.,   2.,   2.,   1.,   3.,   2.,   1.,   2.,   3.,   1.,\n",
       "          2.,   3.,   2.,   1.,   3.,   4.,   2.,   3.,   2.,   2.,   2.,\n",
       "          2.,   2.,   2.,   2.,   2.,   2.,   1.,   2.,   2.,   2.,   3.,\n",
       "          2.,   2.,   3.,   2.,   1.,   2.,   2.,   2.,   3.,   1.,   2.,\n",
       "          2.,   2.,   2.,   2.,   1.,   2.,   2.,   3.,   2.,   4.,   1.,\n",
       "          3.,   2.,   1.,   1.,   1.,   2.,   1.,   2.,   2.,   1.,   1.,\n",
       "          1.,   1.,   2.,   2.,   2.,   2.,   2.,   2.,   1.,   2.,   3.,\n",
       "          1.,   2.,   2.,   3.,   1.,   3.,   3.,   2.,   1.,   1.,   1.,\n",
       "          1.,   2.,   3.,   4.,   1.,   2.,   1.,   1.,   2.,   3.,   2.,\n",
       "          1.,   1.,   2.,   3.,   2.,   1.,   1.,   2.,   2.,   2.,   2.,\n",
       "          1.]),\n",
       " 'f6': array([  1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   4.,   1.,\n",
       "          1.,   1.,   4.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   4.,   1.,   1.,   1.,   1.,   4.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   4.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   4.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   4.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   4.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   4.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   4.,   1.,   1.,   1.,\n",
       "          4.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   4.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   4.,   1.,   1.,   1.,   1.,   4.,   1.,   1.,   1.,\n",
       "          1.,   1.,   4.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          4.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   4.,   1.,\n",
       "          1.,   1.,   4.,   1.,   1.,   1.,   4.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,  nan,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   4.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   4.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   4.,   1.,   4.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   4.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   4.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   4.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   4.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   4.,   1.,   1.,   1.,   1.,   1.,   4.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   4.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   4.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   4.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.]),\n",
       " 'f7': array([130, 109, 119, 119, 109, 119, 108, 132, 126, 117, 125, 131, 128,\n",
       "        108, 130, 130, 128, 129, 131, 118, 108, 131, 123, 115, 111, 129,\n",
       "        116, 129, 121, 131, 109, 132, 119, 131, 117, 131, 129, 126, 121,\n",
       "        131, 131, 129, 122, 111, 114, 113, 111, 108, 130, 126, 132, 119,\n",
       "        124, 113, 129, 120, 114, 122, 125, 124, 108, 115, 130, 123, 115,\n",
       "        122, 119, 116, 130, 126, 119, 117, 120, 126, 131, 122, 108, 126,\n",
       "        131, 110, 109, 120, 116, 110, 124, 131, 118, 125, 122, 116, 122,\n",
       "        121, 119, 126, 128, 122, 124, 124, 123, 126, 124, 123, 125, 118,\n",
       "        124, 124, 121, 131, 121, 129, 125, 116, 108, 114, 123, 113, 122,\n",
       "        114, 124, 124, 121, 108, 113, 121, 129, 114, 111, 130, 108, 116,\n",
       "        108, 108, 116, 117, 125, 109, 112, 132, 131, 128, 131, 120, 112,\n",
       "        130, 113, 122, 126, 113, 113, 131, 119, 131, 113, 127, 123, 127,\n",
       "        127, 130, 108, 130, 116, 130, 115, 115, 117, 108, 131, 120, 129,\n",
       "        122, 118, 114, 124, 124, 113, 122, 119, 131, 131, 117, 127, 115,\n",
       "        132, 131, 114, 122, 126, 111, 108, 116, 107, 129, 109, 118, 114,\n",
       "        126, 107, 124, 110, 126, 115, 112, 120, 123, 117, 126, 128, 130,\n",
       "        117, 118, 114, 121, 113, 117, 117, 115, 109, 108, 123, 125, 127,\n",
       "        119, 111, 125, 132, 123, 120, 123, 128, 123, 114, 108, 110, 122,\n",
       "        108, 115, 112, 109, 127, 128, 118, 107, 108, 115, 117, 111, 120,\n",
       "        124, 122, 119, 123, 122, 119, 108, 108, 115, 110, 127, 111, 127,\n",
       "        126, 128, 109, 110, 113, 121, 118, 120, 125, 114, 128, 112, 112,\n",
       "        115, 127, 110, 131, 125, 117, 116, 121, 122, 118, 129, 112, 130,\n",
       "        115, 109, 131, 110, 124, 131, 109, 124, 129, 123, 122, 127, 128,\n",
       "        118, 124, 114, 128, 114, 108, 107, 127, 108, 123, 119, 128, 122,\n",
       "        117, 123, 120, 130, 128, 114, 118, 126, 121, 122, 114, 126, 129,\n",
       "        118, 120, 109, 122, 132, 128, 122, 122, 110, 116, 123, 123, 126,\n",
       "        124, 124, 117, 112, 129, 121, 126, 127, 124, 112, 117, 125, 132,\n",
       "        120, 123, 112, 120, 125, 129, 121, 125, 120, 126, 115, 128, 113,\n",
       "        108, 115, 116, 113, 115, 111, 125, 126, 112, 126, 131, 111, 119,\n",
       "        126, 116, 129, 126, 119, 118, 120, 115, 118, 129, 127, 117, 124,\n",
       "        113, 128, 119, 129, 118, 126, 132, 122, 115, 120, 118, 129, 118,\n",
       "        120, 112, 108, 111, 108, 129, 109, 130, 117, 125, 116, 130, 127,\n",
       "        125, 126, 128, 129, 125, 113, 109, 126, 131, 129, 116, 121, 131,\n",
       "        126, 116, 122, 126, 116, 118, 131, 108, 124, 129, 116, 128, 125,\n",
       "        130, 123, 119, 131, 108, 123, 108, 119, 119, 124, 126, 130, 124,\n",
       "        114, 128, 132, 110, 116, 120, 113, 131, 110, 129, 129, 124, 120,\n",
       "        111, 126, 131, 125, 110, 113, 119, 131, 117, 120, 127, 123, 132,\n",
       "        128, 109, 131, 127, 132, 125, 122, 115, 124, 124, 109, 130, 118,\n",
       "        122, 130, 127, 108, 128, 114, 131, 108, 111, 108, 113, 123, 122,\n",
       "        116, 114, 108, 121, 115, 120, 131, 128, 108, 119, 118, 112, 129,\n",
       "        123, 108, 127, 125, 114, 129, 123, 121, 119, 119, 125, 109, 128,\n",
       "        129, 122, 129, 129, 112, 126, 108, 124, 129, 128, 112, 115, 123,\n",
       "        122, 131, 108, 131, 127, 127, 111, 130, 113, 118, 109, 126, 108,\n",
       "        119, 111, 124, 108, 128, 110, 127, 121, 124, 118, 114, 126, 128,\n",
       "        111, 108, 119, 125, 123, 120, 116, 108, 125, 108, 114, 107, 124,\n",
       "        123, 108, 115, 117, 111, 109, 109, 111, 108, 117, 131, 113, 131,\n",
       "        131, 121, 109, 115, 119, 118, 122, 126, 114, 128, 115, 116, 120,\n",
       "        115, 123, 127, 122, 118, 129, 130, 126, 131, 113, 124, 113, 124,\n",
       "        117, 123, 125, 130, 123, 109, 113, 119, 118, 118, 116, 116, 131,\n",
       "        111, 124, 131, 131, 124, 120, 119, 120, 130, 119, 112, 109, 129,\n",
       "        118, 122, 118, 121, 127, 131, 120, 109, 126, 125, 129, 131, 112,\n",
       "        118, 131, 126, 120, 116, 127, 126, 126, 127, 131, 111, 115, 109,\n",
       "        124, 122, 121, 121, 125, 130, 108, 125, 109, 122, 129, 127, 120,\n",
       "        122, 116, 113, 124, 117, 126, 131, 120, 122, 122, 115, 107, 115,\n",
       "        117, 131, 121, 123, 110, 112, 119, 117, 125, 131, 113, 117, 124,\n",
       "        115, 121, 130, 131, 132, 131, 118, 116, 110, 125, 109, 121, 130,\n",
       "        127, 108, 120, 116, 121, 118, 117, 123, 121, 129, 129, 114, 126,\n",
       "        120, 120, 112, 122, 126, 124, 130, 109, 110, 118, 121, 132, 110,\n",
       "        130, 112, 128, 118, 110, 123, 130, 128, 113, 113, 108, 120, 127,\n",
       "        128, 132, 132, 117, 128, 120, 123, 118, 129, 120, 121, 131, 118,\n",
       "        121, 131, 122, 131, 126, 108, 131, 128, 110, 127, 131, 114, 128,\n",
       "        108, 120, 131, 116, 120, 115, 115, 110, 110, 119, 116, 129, 124,\n",
       "        111, 132, 131, 123, 129, 128, 119, 118, 128, 129, 120, 131, 124,\n",
       "        131, 116, 120, 125, 110, 131, 125, 116, 127, 125, 116, 121, 121,\n",
       "        117, 127, 113, 119, 122, 123, 116, 121, 113, 130, 131, 122, 131,\n",
       "        115, 117, 116, 116, 120, 131, 129, 121, 112, 122, 112, 129, 116,\n",
       "        113, 114, 123, 125, 112, 119, 128, 114, 114, 129, 126, 108, 128,\n",
       "        130, 128, 110, 126, 121, 117, 119, 110, 123, 114, 129, 130, 127,\n",
       "        114, 130, 115, 132, 130, 131, 129, 107, 113, 125, 124, 132, 108,\n",
       "        122, 119, 127, 121, 121, 121]),\n",
       " 'f8': array([ 54.5       ,  57.5       ,  58.95      ,  54.83333333,\n",
       "         59.2       ,  53.14      ,  50.        ,  58.        ,\n",
       "         59.        ,  51.9       ,  62.5       ,  58.        ,\n",
       "         62.        ,  54.3       ,  62.        ,  55.        ,\n",
       "         53.55      ,  60.75      ,  59.        ,  57.25      ,\n",
       "         55.        ,  57.25      ,  60.5       ,  55.5       ,\n",
       "         51.8       ,  55.        ,  56.        ,  58.        ,\n",
       "         55.25      ,  58.        ,  51.        ,  62.        ,\n",
       "         54.7       ,  59.25      ,  57.        ,  61.        ,\n",
       "         56.        ,  62.        ,  58.        ,  57.        ,\n",
       "         63.        ,  50.5       ,  59.25      ,  48.35      ,\n",
       "         55.25      ,  59.5       ,  52.46      ,  51.625     ,\n",
       "         62.5       ,  62.        ,  57.5       ,  53.5       ,\n",
       "         55.        ,  52.5       ,  58.3       ,  57.5       ,\n",
       "         50.85      ,  59.        ,  55.1       ,  56.8       ,\n",
       "         58.        ,  60.        ,  60.5       ,  56.125     ,\n",
       "         57.5       ,  56.5       ,  62.        ,  56.75      ,\n",
       "         52.        ,  59.        ,  54.        ,  54.75      ,\n",
       "         57.25      ,  56.625     ,  55.75      ,  53.1       ,\n",
       "         55.8       ,  57.5       ,  60.775     ,  53.35      ,\n",
       "         56.        ,  50.        ,  59.5       ,  57.        ,\n",
       "         56.        ,  55.8       ,  50.5       ,  55.        ,\n",
       "         53.        ,  53.5       ,  58.        ,  55.        ,\n",
       "         58.        ,  57.5       ,  57.25      ,  57.5       ,\n",
       "         57.5       ,  56.75      ,  61.        ,  58.        ,\n",
       "         56.7       ,  57.3       ,  62.5       ,  50.        ,\n",
       "         60.1       ,  55.25      ,  59.        ,  63.1       ,\n",
       "         53.13      ,  62.        ,  56.5       ,  50.5       ,\n",
       "         48.5       ,  59.        ,  54.        ,  55.775     ,\n",
       "         55.5       ,  57.        ,  58.        ,  62.        ,\n",
       "         53.        ,  54.5       ,  51.        ,  54.        ,\n",
       "         58.5       ,  53.5       ,  53.1       ,  58.        ,\n",
       "         54.        ,  60.375     ,  51.5       ,  54.95      ,\n",
       "         57.125     ,  54.        ,  52.3       ,  55.        ,\n",
       "         55.        ,  57.        ,  62.225     ,  56.125     ,\n",
       "         58.5       ,  57.        ,  50.5       ,  58.        ,\n",
       "         52.1       ,  57.5       ,  60.9       ,  48.6       ,\n",
       "         53.5       ,  52.5       ,  55.8       ,  53.        ,\n",
       "         51.5       ,  60.5       ,  52.15      ,  61.        ,\n",
       "         60.5       ,  59.05      ,  51.5       ,  56.95      ,\n",
       "         50.5       ,  59.        ,  53.875     ,  53.5       ,\n",
       "         54.        ,  52.        ,  53.        ,  51.5       ,\n",
       "         61.        ,  57.25      ,  55.5       ,  56.25      ,\n",
       "         55.        ,  53.45      ,  57.83333333,  54.125     ,\n",
       "         55.47      ,  56.        ,  55.5       ,  56.625     ,\n",
       "         58.        ,  61.        ,  53.5       ,  58.5       ,\n",
       "         56.02      ,  56.        ,  57.        ,  55.        ,\n",
       "         49.5       ,  53.93333333,  50.5       ,  58.375     ,\n",
       "         51.        ,  50.        ,  57.33333333,  53.5       ,\n",
       "         56.        ,  57.02      ,  52.64333333,  54.5       ,\n",
       "         56.5       ,  50.        ,  57.        ,  58.775     ,\n",
       "         56.25      ,  54.75      ,  54.5       ,  60.5       ,\n",
       "         51.875     ,  53.85      ,  55.        ,  58.        ,\n",
       "         57.        ,  50.        ,  55.        ,  50.75      ,\n",
       "         50.5       ,  56.4       ,  64.        ,  56.375     ,\n",
       "         53.75      ,  53.275     ,  63.        ,  58.25      ,\n",
       "         54.25      ,  56.25      ,  60.        ,  54.        ,\n",
       "         54.        ,  52.95      ,  57.        ,  55.        ,\n",
       "         57.        ,  54.875     ,  54.25      ,  50.05      ,\n",
       "         48.775     ,  52.75      ,  58.        ,  65.5       ,\n",
       "         52.75      ,  55.5       ,  50.5       ,  53.        ,\n",
       "         54.375     ,  59.        ,  55.75      ,  59.43333333,\n",
       "         59.        ,  55.5       ,  57.76      ,  60.        ,\n",
       "         57.        ,  56.5       ,  51.        ,  53.5       ,\n",
       "         51.5       ,  61.25      ,  54.        ,  52.5       ,\n",
       "         59.1       ,  57.25      ,  58.        ,  57.25      ,\n",
       "         52.5       ,  52.25      ,  61.75      ,  55.45      ,\n",
       "         61.25      ,  54.        ,  60.5       ,  52.        ,\n",
       "         56.2       ,  57.        ,  57.5       ,  54.        ,\n",
       "         56.        ,  58.5       ,  53.25      ,  53.625     ,\n",
       "         55.08333333,  54.        ,  57.        ,  61.675     ,\n",
       "         56.        ,  59.875     ,  63.5       ,  55.95      ,\n",
       "         55.5       ,  52.4       ,  55.        ,  56.25      ,\n",
       "         64.25      ,  62.        ,  54.5       ,  52.5       ,\n",
       "         54.25      ,  59.        ,  58.875     ,  55.3       ,\n",
       "         58.25      ,  52.        ,  57.5       ,  52.5       ,\n",
       "         51.        ,  50.6       ,  55.5       ,  53.        ,\n",
       "         60.5       ,  54.75      ,  54.25      ,  52.75      ,\n",
       "         61.        ,  54.        ,  55.45      ,  63.25      ,\n",
       "         56.        ,  54.25      ,  54.5       ,  55.1       ,\n",
       "         54.375     ,  52.5       ,  50.75      ,  53.8       ,\n",
       "         60.5       ,  51.35      ,  57.        ,  53.36666667,\n",
       "         58.3       ,  57.5       ,  57.5       ,  58.        ,\n",
       "         56.5       ,  57.5       ,  53.675     ,  57.875     ,\n",
       "         61.5       ,  59.25      ,  54.15      ,  51.        ,\n",
       "         52.3       ,  54.91666667,  48.9       ,  52.        ,\n",
       "         56.        ,  56.5       ,  58.75      ,  56.        ,\n",
       "         55.        ,  55.5       ,  58.        ,  55.        ,\n",
       "         55.6       ,  54.        ,  56.25      ,  55.5       ,\n",
       "         61.        ,  56.        ,  53.        ,  53.9       ,\n",
       "         53.25      ,  53.25      ,  56.5       ,  53.5       ,\n",
       "         51.25      ,  55.5       ,  52.        ,  50.75      ,\n",
       "         55.625     ,  54.5       ,  54.        ,  56.15      ,\n",
       "         51.        ,  60.        ,  56.4       ,  56.        ,\n",
       "         53.25      ,  56.        ,  64.        ,  56.875     ,\n",
       "         56.3       ,  56.        ,  53.        ,  54.        ,\n",
       "         59.63333333,  52.16      ,  52.5       ,  56.5       ,\n",
       "         56.        ,  61.5       ,  54.65      ,  58.        ,\n",
       "         54.5       ,  55.        ,  57.        ,  57.4       ,\n",
       "         60.        ,  57.        ,  56.        ,  53.5       ,\n",
       "         55.25      ,  59.19      ,  51.5       ,  50.5       ,\n",
       "         55.25      ,  52.4       ,  51.45      ,  51.25      ,\n",
       "         56.25      ,  48.1       ,  52.98333333,  57.25      ,\n",
       "         55.5       ,  55.        ,  59.75      ,  55.375     ,\n",
       "         59.2       ,  57.625     ,  56.75      ,  56.5       ,\n",
       "         56.95      ,  57.        ,  55.5       ,  53.        ,\n",
       "         55.        ,  57.6       ,  53.75      ,  49.        ,\n",
       "         63.        ,  55.        ,  56.05      ,  56.9       ,\n",
       "         56.9       ,  57.175     ,  57.5       ,  56.        ,\n",
       "         58.        ,  56.5       ,  54.        ,  52.75      ,\n",
       "         62.        ,  57.        ,  62.        ,  53.        ,\n",
       "         53.75      ,  58.        ,  55.25      ,  55.75      ,\n",
       "         52.925     ,  53.        ,  53.        ,  54.25      ,\n",
       "         54.9       ,  48.6       ,  55.25      ,  52.875     ,\n",
       "         56.5       ,  54.5       ,  55.25      ,  54.8       ,\n",
       "         60.        ,  52.        ,  57.        ,  50.5       ,\n",
       "         58.625     ,  53.5       ,  53.        ,  60.        ,\n",
       "         57.5       ,  56.375     ,  54.85      ,  62.25      ,\n",
       "         53.        ,  53.5       ,  56.        ,  51.        ,\n",
       "         58.        ,  57.        ,  51.15      ,  60.5       ,\n",
       "         58.95      ,  56.        ,  52.25      ,  56.        ,\n",
       "         61.        ,  58.125     ,  56.        ,  57.        ,\n",
       "         54.8       ,  62.        ,  56.125     ,  55.        ,\n",
       "         59.5       ,  58.675     ,  48.225     ,  56.25      ,\n",
       "         58.8       ,  53.        ,  50.5       ,  55.75      ,\n",
       "         56.        ,  50.5       ,  52.5       ,  53.        ,\n",
       "         54.        ,  55.55      ,  55.6       ,  57.8       ,\n",
       "         51.625     ,  53.5       ,  57.5       ,  55.        ,\n",
       "         56.5       ,  55.36666667,  60.3       ,  53.625     ,\n",
       "         57.        ,  58.25      ,  52.8       ,  54.125     ,\n",
       "         60.        ,  48.5       ,  59.        ,  57.625     ,\n",
       "         63.25      ,  55.75      ,  59.        ,  53.55      ,\n",
       "         51.875     ,  53.75      ,  60.        ,  55.5       ,\n",
       "         53.        ,  59.6       ,  57.        ,  58.5       ,\n",
       "         57.        ,  52.5       ,  56.6       ,  53.875     ,\n",
       "         54.        ,  59.5       ,  54.5       ,  51.125     ,\n",
       "         51.75      ,  55.        ,  54.25      ,  53.5       ,\n",
       "         54.        ,  58.        ,  58.        ,  53.5       ,\n",
       "         52.875     ,  53.        ,  54.5       ,  59.        ,\n",
       "         51.        ,  55.        ,  51.        ,  56.66666667,\n",
       "         59.125     ,  55.        ,  53.        ,  55.        ,\n",
       "         52.95      ,  52.375     ,  54.5       ,  56.4       ,\n",
       "         62.        ,  53.5       ,  60.        ,  59.125     ,\n",
       "         49.5       ,  54.25      ,  56.        ,  60.5       ,\n",
       "         54.        ,  55.75      ,  57.5       ,  49.        ,\n",
       "         61.        ,  52.        ,  52.        ,  52.5       ,\n",
       "         59.        ,  60.        ,  53.15      ,  62.        ,\n",
       "         56.5135    ,  61.5       ,  54.5       ,  57.8       ,\n",
       "         51.125     ,  53.        ,  53.5       ,  59.        ,\n",
       "         50.        ,  58.        ,  57.77      ,  56.        ,\n",
       "         53.5       ,  55.9       ,  55.5       ,  60.95      ,\n",
       "         52.        ,  50.        ,  57.        ,  59.        ,\n",
       "         55.875     ,  55.        ,  58.        ,  57.5       ,\n",
       "         54.95      ,  55.25      ,  51.        ,  54.5       ,\n",
       "         61.        ,  55.25      ,  52.        ,  58.625     ,\n",
       "         56.25      ,  55.5       ,  56.5       ,  57.375     ,\n",
       "         55.3       ,  60.        ,  54.5       ,  57.25      ,\n",
       "         54.        ,  52.75      ,  54.        ,  53.        ,\n",
       "         53.        ,  58.        ,  52.        ,  53.25      ,\n",
       "         54.5       ,  58.5       ,  62.        ,  55.5       ,\n",
       "         57.        ,  58.5       ,  59.        ,  54.25      ,\n",
       "         55.875     ,  54.        ,  58.        ,  53.2       ,\n",
       "         52.85      ,  54.25      ,  52.        ,  57.        ,\n",
       "         56.5       ,  56.25      ,  58.        ,  56.        ,\n",
       "         54.375     ,  52.        ,  61.        ,  56.75      ,\n",
       "         60.25      ,  44.5       ,  56.        ,  57.125     ,\n",
       "         54.        ,  53.5       ,  55.5       ,  56.        ,\n",
       "         56.75      ,  57.125     ,  60.4       ,  58.        ,\n",
       "         56.        ,  51.5       ,  57.        ,  55.5       ,\n",
       "         60.5       ,  56.25      ,  57.        ,  50.5       ,\n",
       "         56.        ,  57.125     ,  53.5       ,  56.        ,\n",
       "         52.        ,  51.5       ,  55.5       ,  58.875     ,\n",
       "         58.        ,  58.875     ,  53.        ,  50.45      ,\n",
       "         64.        ,  52.        ,  57.25      ,  52.5       ,\n",
       "         54.5       ,  56.        ,  57.5       ,  54.745     ,\n",
       "         51.        ,  56.5       ,  59.        ,  53.25      ,\n",
       "         61.        ,  55.5       ,  51.        ,  54.5       ,\n",
       "         58.5       ,  55.        ,  53.5       ,  57.5       ,\n",
       "         41.5       ,  56.8       ,  56.5       ,  57.        ,\n",
       "         54.        ,  65.        ,  61.        ,  59.25      ,\n",
       "         57.        ,  52.        ,  56.65      ,  53.        ,\n",
       "         57.75      ,  55.75      ,  56.5       ,  57.25      ,\n",
       "         51.        ,  51.25      ,  55.85      ,  51.33333333,\n",
       "         53.16666667,  58.5       ,  55.        ,  59.        ,\n",
       "         56.5       ,  52.5       ,  58.        ,  52.4       ,\n",
       "         60.        ,  57.        ,  58.5       ,  53.27      ,\n",
       "         57.625     ,  60.        ,  52.        ,  58.        ,\n",
       "         53.75      ,  58.875     ,  59.        ,  54.5       ,\n",
       "         63.        ,  52.        ,  61.5       ,  50.5       ,\n",
       "         59.5       ,  56.        ,  54.        ,  53.25      ,\n",
       "         57.5       ,  62.875     ,  54.5       ,  57.7       ,\n",
       "         55.7       ,  58.        ,  57.5       ,  64.25      ,\n",
       "         58.5       ,  59.        ,  58.        ,  52.        ,\n",
       "         54.5       ,  60.        ,  54.        ,  59.        ,\n",
       "         58.5       ,  54.5       ,  59.        ,  50.        ,\n",
       "         59.25      ,  58.6       ,  52.3       ,  59.        ,\n",
       "         55.11      ,  54.        ,  56.        ,  56.25      ,\n",
       "         54.5       ,  59.        ,  58.25      ,  53.5       ,\n",
       "         59.66666667,  52.25      ,  55.25      ,  60.        ,\n",
       "         54.5       ,  58.41666667,  54.625     ,  54.725     ,\n",
       "         49.75      ,  50.        ,  57.1       ,  57.        ,\n",
       "         57.8       ,  61.        ,  54.        ,  59.625     ,\n",
       "         60.        ,  58.        ,  62.06666667,  56.        ,\n",
       "         55.        ,  55.7       ,  56.        ,  60.5       ,\n",
       "         59.        ,  60.25      ,  62.        ,  56.375     ,\n",
       "         58.75      ,  54.125     ,  53.33333333,  52.875     ,\n",
       "         62.        ,  55.5       ,  53.625     ,  59.        ,\n",
       "         61.        ,  52.76      ,  53.25      ,  41.        ,\n",
       "         58.        ,  60.98      ,  59.        ,  55.        ,\n",
       "         55.5       ,  56.25      ,  55.        ,  59.        ,\n",
       "         36.6       ,  59.        ,  59.375     ,  59.        ,\n",
       "         53.        ,  48.9       ,  58.        ,  54.5       ,\n",
       "         57.25      ,  59.25      ,  54.        ,  54.875     ,\n",
       "         55.        ,  54.6       ,  56.3       ,  54.        ,\n",
       "         56.        ,  52.        ,  54.5       ,  54.5       ,\n",
       "         58.        ,  58.5       ,  57.75      ,  60.5       ,\n",
       "         55.5       ,  54.        ,  56.5       ,  57.75      ,\n",
       "         54.375     ,  55.9       ,  60.        ,  58.75      ,\n",
       "         57.5       ,  53.375     ,  61.        ,  59.5       ,\n",
       "         52.16666667,  49.5       ,  50.        ,  51.5       ,\n",
       "         57.25      ,  54.5       ,  58.        ,  62.16666667,\n",
       "         52.9       ,  58.        ,  50.9       ,  52.5       ,\n",
       "         57.        ,  57.        ,  53.        ,  52.75      ,\n",
       "         54.        ,  54.25      ,  60.7       ,  55.75      ,\n",
       "         50.1       ,  56.        ,  52.3       ,  58.        ,\n",
       "         58.125     ,  61.        ,  54.7       ]),\n",
       " 'f9': array([  68.5       ,   72.        ,   96.6       ,   65.26666667,\n",
       "          94.8       ,   69.        ,   65.08333333,   84.        ,\n",
       "         141.95      ,   58.2       ,  189.        ,  134.        ,\n",
       "         109.        ,   63.56666667,   95.        ,   88.        ,\n",
       "          70.4       ,  115.        ,   80.5       ,   72.        ,\n",
       "          61.4       ,   81.        ,  125.        ,   64.5       ,\n",
       "          74.2       ,   49.5       ,   63.        ,   87.        ,\n",
       "          93.        ,  114.        ,   71.        ,  159.        ,\n",
       "          81.8       ,   76.        ,   79.        ,  118.        ,\n",
       "          92.        ,  100.        ,  136.4       ,  115.        ,\n",
       "         149.8       ,   51.        ,   89.        ,   46.36666667,\n",
       "         106.        ,  128.6       ,   79.8       ,   74.5       ,\n",
       "         109.        ,  105.        ,   98.        ,   69.        ,\n",
       "          70.        ,   58.        ,  103.        ,   78.33333333,\n",
       "          57.25      ,   79.2       ,   70.6       ,   76.        ,\n",
       "          73.        ,  110.5       ,  134.        ,   79.25      ,\n",
       "          87.        ,  103.        ,  126.        ,   90.        ,\n",
       "          60.        ,  145.        ,   72.25      ,   66.        ,\n",
       "          68.75      ,  104.        ,   71.2       ,   76.3       ,\n",
       "          68.6       ,   66.5       ,   89.        ,   67.55      ,\n",
       "          89.        ,   76.        ,   86.        ,  118.3333333 ,\n",
       "          63.        ,   65.5       ,   54.        ,   84.5       ,\n",
       "          63.        ,   57.        ,  104.3       ,   85.        ,\n",
       "          75.        ,   97.5       ,   92.        ,   66.        ,\n",
       "          90.75      ,   81.25      ,  115.        ,   82.        ,\n",
       "          73.9       ,  102.        ,  122.        ,   63.        ,\n",
       "          90.6       ,   63.6       ,   87.        ,  133.65      ,\n",
       "          80.        ,  106.        ,   70.2       ,   56.06666667,\n",
       "          68.        ,   93.        ,   78.        ,   69.8       ,\n",
       "          80.8       ,  107.        ,   98.        ,  129.65      ,\n",
       "          56.        ,   80.2       ,   77.5       ,   79.        ,\n",
       "         100.        ,   85.03333333,   60.3       ,   59.        ,\n",
       "          70.        ,  131.6666667 ,   58.        ,   64.2       ,\n",
       "          74.        ,   72.        ,   63.8       ,   65.4       ,\n",
       "          67.08333333,   80.        ,  118.8       ,   85.5       ,\n",
       "          73.        ,  128.        ,   68.        ,  103.        ,\n",
       "          52.5       ,   74.5       ,  140.2       ,   88.        ,\n",
       "          74.        ,   96.        ,   67.        ,   70.        ,\n",
       "          59.5       ,   88.3       ,   60.        ,  108.2       ,\n",
       "         114.        ,  114.6333333 ,   64.        ,   87.5       ,\n",
       "          77.        ,  123.        ,   76.        ,   74.3       ,\n",
       "          85.        ,   74.        ,   76.        ,   85.        ,\n",
       "          86.5       ,   76.        ,   92.3       ,   75.        ,\n",
       "          66.        ,  106.        ,   83.83333333,   58.2       ,\n",
       "          67.4       ,   86.8       ,   79.53333333,   67.        ,\n",
       "         122.5       ,  102.        ,   62.5       ,   92.        ,\n",
       "          74.2       ,   85.        ,   88.66666667,  103.2       ,\n",
       "          55.        ,   70.83333333,   81.66666667,   66.        ,\n",
       "          59.1       ,   53.        ,   88.8       ,   68.        ,\n",
       "          70.        ,   93.53333333,   76.25      ,   59.        ,\n",
       "          76.        ,   54.8       ,  121.        ,   85.5       ,\n",
       "          66.1       ,   66.5       ,   71.        ,  116.        ,\n",
       "          58.5       ,   72.25      ,   80.        ,  106.5       ,\n",
       "         132.        ,   58.5       ,   66.25      ,   70.5       ,\n",
       "          50.        ,   79.        ,  149.        ,   66.        ,\n",
       "          62.        ,   68.75      ,  180.        ,  122.25      ,\n",
       "          73.        ,   68.4       ,  108.8666667 ,   80.        ,\n",
       "          83.        ,   62.4       ,   94.5       ,   81.        ,\n",
       "         142.        ,  108.        ,   55.75      ,   55.        ,\n",
       "          58.75      ,   63.        ,   85.        ,   99.        ,\n",
       "          66.5       ,   99.        ,   55.        ,   66.5       ,\n",
       "          62.5       ,   78.        ,   91.16666667,   87.        ,\n",
       "         113.        ,   87.        ,   97.33333333,   85.        ,\n",
       "          95.        ,   72.        ,   62.        ,   57.06666667,\n",
       "         100.45      ,  132.75      ,   70.        ,   70.        ,\n",
       "         126.        ,   84.3       ,  119.        ,   79.        ,\n",
       "          68.7       ,   66.75      ,  132.5       ,   64.86666667,\n",
       "         149.225     ,   68.        ,   99.        ,   53.        ,\n",
       "          71.91      ,  101.        ,   92.        ,   83.        ,\n",
       "          72.        ,   89.5       ,   59.5       ,  105.5       ,\n",
       "          91.        ,   85.        ,   71.5       ,  112.7       ,\n",
       "         122.2       ,  128.        ,  117.        ,   97.9       ,\n",
       "          69.        ,   76.2       ,   72.5       ,   64.        ,\n",
       "          90.        ,  110.        ,   66.        ,   61.        ,\n",
       "          70.        ,  108.6       ,  115.75      ,   70.        ,\n",
       "         110.5       ,   59.6       ,   89.        ,   64.        ,\n",
       "          73.25      ,   51.25      ,   80.5       ,   61.        ,\n",
       "         102.        ,   99.        ,   93.75      ,   53.        ,\n",
       "         122.05      ,   69.        ,   93.        ,  117.5       ,\n",
       "          75.        ,   67.        ,   77.4       ,   79.9       ,\n",
       "          66.95      ,   67.        ,   61.        ,   68.9       ,\n",
       "         124.        ,   70.05      ,   80.        ,   69.9       ,\n",
       "         120.1666667 ,   83.8       ,  160.        ,   91.        ,\n",
       "          75.2       ,  127.        ,   75.6       ,   74.91666667,\n",
       "          96.        ,   81.        ,   74.8       ,   61.        ,\n",
       "          67.        ,   77.        ,   94.        ,   61.        ,\n",
       "          90.        ,   71.5       ,   92.5       ,   73.        ,\n",
       "          80.        ,   68.2       ,   78.        ,   58.        ,\n",
       "          72.9       ,   94.6       ,   77.        ,   76.        ,\n",
       "         101.        ,   78.        ,   55.        ,   56.8       ,\n",
       "          68.        ,   72.5       ,   78.        ,   70.        ,\n",
       "          58.        ,  128.9333333 ,   53.        ,   55.        ,\n",
       "          86.        ,   74.        ,   75.        ,   67.8       ,\n",
       "          66.        ,   85.        ,   71.        ,   70.5       ,\n",
       "          67.16666667,   81.        ,  144.6       ,   78.5       ,\n",
       "          70.1       ,   80.        ,   68.        ,   69.        ,\n",
       "         119.        ,   83.45      ,   71.        ,   89.        ,\n",
       "         124.4       ,  150.15      ,  141.3333333 ,   92.33333333,\n",
       "          64.        ,   66.05      ,   79.        ,   82.86666667,\n",
       "          75.        ,   75.        ,   79.        ,   64.8       ,\n",
       "         116.        ,   94.45      ,   65.5       ,   52.25      ,\n",
       "          84.5       ,   59.33333333,   71.        ,   62.        ,\n",
       "          77.75      ,   65.8       ,   56.75      ,   89.        ,\n",
       "          69.        ,   62.        ,   82.        ,   76.58333333,\n",
       "          93.03333333,   99.5       ,  130.8       ,  105.5       ,\n",
       "         110.        ,   74.        ,  124.        ,   60.        ,\n",
       "          75.        ,   94.7       ,   60.        ,   56.        ,\n",
       "         104.        ,   57.5       ,   68.05      ,   68.5       ,\n",
       "          86.        ,   97.33333333,   78.        ,   77.        ,\n",
       "          79.        ,   77.2       ,   60.25      ,   64.        ,\n",
       "         155.        ,   75.        ,  159.75      ,   63.91666667,\n",
       "          68.75      ,   91.8       ,   78.2       ,   74.        ,\n",
       "          58.2       ,   67.        ,   64.8       ,   77.25      ,\n",
       "          77.06666667,   44.        ,   64.        ,   78.8       ,\n",
       "          65.9       ,   76.        ,   77.25      ,   66.        ,\n",
       "          89.        ,   72.        ,   82.        ,   57.66666667,\n",
       "          64.75      ,   64.        ,   71.        ,  123.        ,\n",
       "          77.        ,   78.75      ,   73.2       ,  105.        ,\n",
       "          72.        ,   70.5       ,  125.        ,  149.        ,\n",
       "          81.        ,   75.        ,   57.05      ,   98.5       ,\n",
       "          76.5       ,   60.75      ,   62.        ,   68.        ,\n",
       "         216.4666667 ,   70.9       ,  107.        ,   85.        ,\n",
       "          68.4       ,  166.3333333 ,   87.        ,   78.        ,\n",
       "          87.45      ,  122.6       ,  122.        ,   78.2       ,\n",
       "          83.25      ,   73.        ,   66.75      ,   75.3       ,\n",
       "          77.        ,   52.5       ,   68.        ,   73.2       ,\n",
       "          77.9       ,   64.        ,   69.1       ,   78.16666667,\n",
       "          63.        ,   81.46666667,   76.2       ,   72.        ,\n",
       "          68.        ,   61.        ,   98.3       ,   56.        ,\n",
       "          89.        ,   86.5       ,   66.6       ,   64.25      ,\n",
       "         107.3333333 ,   47.        ,  110.        ,   79.2       ,\n",
       "         169.5       ,   71.25      ,   84.        ,   61.2       ,\n",
       "          65.33333333,   64.        ,   87.66666667,   90.5       ,\n",
       "          60.        ,   97.2       ,   96.1       ,  123.        ,\n",
       "         115.        ,   64.        ,   88.6       ,   60.        ,\n",
       "          60.        ,   77.5       ,   78.58333333,   63.25      ,\n",
       "          71.5       ,   80.75      ,   89.75      ,   55.        ,\n",
       "          69.95      ,   98.3       ,   80.        ,   68.16666667,\n",
       "          69.8       ,   73.        ,   74.        ,  145.        ,\n",
       "         102.        ,  108.        ,   54.        ,   84.41666667,\n",
       "         123.9166667 ,   94.        ,   60.        ,   59.        ,\n",
       "          61.53333333,   66.        ,   61.41666667,   78.1       ,\n",
       "         117.        ,   66.75      ,   99.5       ,  168.        ,\n",
       "          69.5       ,   75.        ,   65.        ,  100.2       ,\n",
       "          66.        ,   91.        ,  110.        ,   57.        ,\n",
       "         132.        ,   51.        ,   77.        ,   75.        ,\n",
       "         107.5       ,   83.        ,   69.2       ,  112.05      ,\n",
       "          82.9       ,  108.5       ,   88.        ,   67.        ,\n",
       "          61.5       ,   70.        ,   63.8       ,  104.        ,\n",
       "          60.        ,   72.2       ,   74.66666667,   82.        ,\n",
       "          75.        ,   71.        ,   88.5       ,   81.75      ,\n",
       "          57.        ,   62.5       ,  115.        ,   90.        ,\n",
       "          85.        ,   72.5       ,  107.8       ,   79.        ,\n",
       "         115.8       ,   73.5       ,   51.        ,   64.        ,\n",
       "         128.        ,  102.5       ,   62.5       ,   83.5       ,\n",
       "          97.        ,   76.        ,   76.1       ,  108.        ,\n",
       "          76.3       ,   89.        ,   70.5       ,   79.5       ,\n",
       "          62.        ,   83.5       ,   71.        ,   53.        ,\n",
       "          60.        ,   73.5       ,   75.        ,   75.        ,\n",
       "          81.86666667,  125.        ,  127.        ,   60.        ,\n",
       "          90.        ,   77.2       ,   85.5       ,   55.75      ,\n",
       "          73.8       ,   74.2       ,   74.        ,   72.25      ,\n",
       "          65.5       ,   58.5       ,   54.5       ,  111.3333333 ,\n",
       "          71.        ,   68.        ,   94.        ,   81.55      ,\n",
       "          64.55      ,   61.3       ,  101.        ,   70.75      ,\n",
       "         104.1666667 ,   74.1       ,  102.        ,   77.08333333,\n",
       "          61.        ,   67.        ,   70.        ,   67.        ,\n",
       "          76.        ,  111.9166667 ,   80.16666667,   94.        ,\n",
       "          63.6       ,   57.        ,   86.5       ,   90.        ,\n",
       "          90.        ,   97.        ,   64.        ,   55.5       ,\n",
       "         108.        ,   71.5       ,   70.        ,  105.        ,\n",
       "          62.        ,   54.2       ,   66.        ,  112.        ,\n",
       "          86.        ,   86.33333333,   54.        ,   56.9       ,\n",
       "         131.        ,   68.        ,   94.        ,   68.2       ,\n",
       "          66.66666667,   76.25      ,  105.        ,   60.5       ,\n",
       "          57.        ,  103.75      ,   99.        ,   73.75      ,\n",
       "          91.        ,   90.        ,   59.25      ,  119.        ,\n",
       "         112.        ,   67.        ,   69.        ,   73.75      ,\n",
       "          71.        ,   89.05      ,   68.        ,  128.        ,\n",
       "          80.4       ,  151.        ,  101.        ,   84.        ,\n",
       "          73.        ,   65.6       ,   84.76666667,   61.        ,\n",
       "          76.05      ,   74.5       ,   61.        ,   74.        ,\n",
       "          56.        ,   62.9       ,   75.93333333,   73.41666667,\n",
       "          66.        ,   92.        ,   72.        ,   89.        ,\n",
       "          71.26666667,   72.        ,   92.        ,   69.36666667,\n",
       "          86.        ,   93.        ,   91.        ,   71.13333333,\n",
       "          72.5       ,  124.1666667 ,   81.        ,   76.        ,\n",
       "          68.5       ,  100.        ,  115.        ,   59.        ,\n",
       "         189.        ,   81.66666667,  102.        ,   58.        ,\n",
       "          82.        ,   75.        ,   84.7       ,   89.        ,\n",
       "         101.5       ,  131.25      ,   70.        ,   76.25      ,\n",
       "          63.3       ,   70.        ,   74.9       ,  188.4       ,\n",
       "         107.4       ,  100.1333333 ,   96.        ,   61.        ,\n",
       "          73.53333333,  111.8       ,   67.        ,   78.25      ,\n",
       "         136.        ,  115.        ,   81.5       ,   56.        ,\n",
       "          86.        ,   92.        ,   71.26666667,   82.        ,\n",
       "          76.        ,   65.2       ,  118.        ,   70.        ,\n",
       "          82.2       ,  104.4       ,   79.5       ,   62.        ,\n",
       "          67.        ,   55.        ,   69.        ,   76.        ,\n",
       "          82.        ,   80.58333333,   84.5       ,   69.        ,\n",
       "          56.        ,   52.        ,   83.6       ,  104.        ,\n",
       "         105.4       ,  113.        ,   78.        ,   97.7       ,\n",
       "          99.        ,   76.        ,   66.55      ,   71.08333333,\n",
       "          65.5       ,   73.36666667,   76.        ,  163.        ,\n",
       "         106.        ,   89.        ,  100.        ,   78.        ,\n",
       "         127.        ,   75.5       ,   64.2       ,  106.3333333 ,\n",
       "         102.        ,   71.        ,   58.5       ,   89.9       ,\n",
       "          59.8       ,   70.1       ,   73.        ,   66.        ,\n",
       "          77.        ,  133.        ,   79.        ,  128.55      ,\n",
       "          73.5       ,   87.25      ,   85.        ,  115.        ,\n",
       "          55.        ,  111.        ,   91.4       ,  101.05      ,\n",
       "          62.        ,  103.        ,   68.        ,   77.        ,\n",
       "          88.        ,   91.        ,   61.        ,   57.06666667,\n",
       "          73.1       ,   94.7       ,   77.3       ,   75.        ,\n",
       "          62.        ,   62.8       ,   67.        ,   69.5       ,\n",
       "          81.26666667,   90.66666667,  115.        ,   93.        ,\n",
       "          81.        ,   65.        ,   80.3       ,  112.25      ,\n",
       "          53.        ,   82.        ,  142.        ,   75.        ,\n",
       "         124.        ,   60.56666667,  118.        ,  152.8333333 ,\n",
       "          63.2       ,  130.        ,   74.25      ,   61.        ,\n",
       "          90.        ,   61.        ,   89.        ,  129.25      ,\n",
       "          82.05      ,  145.3       ,   58.33333333,   56.        ,\n",
       "          78.        ,   76.        ,   74.        ,   57.9       ,\n",
       "          60.9       ,   81.4       ,  163.3       ,   78.5       ,\n",
       "          61.16666667,   66.        ,   61.8       ,  103.        ,\n",
       "          74.        ,   88.        ,   59.5       ]),\n",
       " 'fabs': <ufunc 'fabs'>,\n",
       " 'fact': 393849377343759797528386895216640000L,\n",
       " 'fastCopyAndTranspose': <function numpy.core.multiarray._fastCopyAndTranspose>,\n",
       " 'fft': <module 'numpy.fft' from '/anaconda2/lib/python2.7/site-packages/numpy/fft/__init__.pyc'>,\n",
       " 'fig': <matplotlib.figure.Figure at 0x10cf453d0>,\n",
       " 'fill_diagonal': <function numpy.lib.index_tricks.fill_diagonal>,\n",
       " 'final': array([[  0.00000000e+000,   3.00393120e-308,   6.94881468e-311,\n",
       "           3.33772113e-308],\n",
       "        [  2.33650410e-308,   1.89142313e-308,   1.89139427e-308,\n",
       "           3.00396684e-308],\n",
       "        [  1.89146387e-308,   7.50991287e-309,   1.37960351e-307,\n",
       "           1.89142313e-308],\n",
       "        [  2.11395258e-308,   2.78147983e-308,   2.78151718e-308,\n",
       "           1.20161050e-307],\n",
       "        [  1.89142313e-308,   2.04721462e-307,   2.31422349e-307,\n",
       "           1.89142313e-308],\n",
       "        [  1.02358083e-307,   2.13616190e-307,   1.78012428e-307,\n",
       "           1.89139257e-308],\n",
       "        [  2.22518420e-308,   4.89544090e-308,   1.00135538e-308,\n",
       "           2.67025839e-308],\n",
       "        [  1.29061006e-307,   5.11800261e-308,   2.55900300e-308,\n",
       "           2.55900470e-308],\n",
       "        [  1.11259736e-307,   5.34048283e-308,   5.11799921e-308,\n",
       "           2.22519779e-308],\n",
       "        [  4.22790177e-308,   2.11394919e-308,   1.33510679e-307,\n",
       "           2.04717931e-307],\n",
       "        [  1.95814105e-307,   8.90088960e-309,   1.95822797e-307,\n",
       "           1.42421024e-307],\n",
       "        [  1.95813698e-307,   1.95819945e-307,   9.79067130e-308,\n",
       "           1.89142313e-308],\n",
       "        [  2.89270806e-308,   4.67289277e-308,   1.78022477e-307,\n",
       "           1.33514363e-308],\n",
       "        [  1.39073822e-308,   3.56036263e-308,   4.22791534e-308,\n",
       "           4.22787460e-308],\n",
       "        [  1.27948622e-308,   9.45752306e-309,   1.37961166e-307,\n",
       "           5.56292231e-308],\n",
       "        [  1.24611334e-307,   1.39077047e-308,   4.00529592e-308,\n",
       "           3.78291755e-308],\n",
       "        [  1.51311677e-307,   4.22796967e-308,   1.78021119e-307,\n",
       "           1.33512308e-307],\n",
       "        [  1.29061074e-307,   4.89545448e-308,   1.24609229e-307,\n",
       "           2.55903865e-308],\n",
       "        [  3.33769228e-308,   8.90098297e-309,   8.01086345e-308,\n",
       "           8.90074361e-308],\n",
       "        [  2.33650410e-308,   1.33510679e-307,   2.89272164e-308,\n",
       "           1.33513089e-308],\n",
       "        [  2.55903526e-308,   3.33774660e-308,   5.56308189e-308,\n",
       "           1.27946076e-308],\n",
       "        [  9.79068488e-308,   7.56583510e-308,   2.13614153e-307,\n",
       "           3.56047807e-308],\n",
       "        [  3.22649290e-308,   2.55904205e-308,   2.13614560e-307,\n",
       "           1.06811354e-307],\n",
       "        [  1.11258650e-307,   4.00535703e-308,   1.02361207e-307,\n",
       "           3.33773811e-308],\n",
       "        [  5.34039795e-308,   8.45574921e-308,   8.01097210e-308,\n",
       "           2.78148323e-308],\n",
       "        [  2.33642432e-308,   1.20160711e-307,   2.22517707e-307,\n",
       "           2.04716709e-307],\n",
       "        [  5.78542630e-308,   9.34588740e-308,   5.11797205e-308,\n",
       "           3.44907159e-308],\n",
       "        [  1.11258446e-307,   5.11791773e-308,   3.11524600e-308,\n",
       "           4.22792893e-308],\n",
       "        [  1.00137576e-308,   7.50990863e-309,   2.67018200e-308,\n",
       "           1.24608889e-307],\n",
       "        [  1.33510679e-307,   5.78559267e-308,   7.50993409e-309,\n",
       "           1.33511137e-308],\n",
       "        [  4.45051440e-308,   2.31417324e-307,   5.78555193e-308,\n",
       "           1.86912723e-307],\n",
       "        [  4.89532207e-308,   1.60219306e-307,   1.51312356e-307,\n",
       "           2.31415287e-307],\n",
       "        [  3.22650648e-308,   1.42416542e-307,   1.05695762e-308,\n",
       "           2.31423571e-307],\n",
       "        [  2.13622708e-307,   1.69112268e-307,   3.33779413e-308,\n",
       "           7.50982799e-309],\n",
       "        [  8.45608873e-308,   3.33779583e-308,   1.06806737e-307,\n",
       "           1.33510883e-308],\n",
       "        [  2.22524362e-308,   1.16820452e-308,   2.00274303e-308,\n",
       "           2.00274303e-308],\n",
       "        [  2.44777477e-308,   1.69112947e-307,   1.42413690e-307,\n",
       "           3.11523412e-308],\n",
       "        [  1.27950999e-308,   3.22647423e-308,   5.56293250e-308,\n",
       "           1.05700600e-308],\n",
       "        [  1.60217133e-307,   8.90098806e-308,   3.00403135e-308,\n",
       "           1.33510679e-307],\n",
       "        [  1.89148084e-308,   3.56051881e-308,   3.11519677e-308,\n",
       "           1.00136642e-308],\n",
       "        [  1.78020440e-307,   1.60216047e-307,   1.27951848e-308,\n",
       "           1.69122182e-307],\n",
       "        [  1.27948368e-308,   2.31415015e-307,   7.51014204e-309,\n",
       "           7.51012931e-309],\n",
       "        [  1.86915439e-307,   2.22517979e-307,   1.42411653e-307,\n",
       "           1.89145878e-308],\n",
       "        [  8.45604799e-308,   1.33508981e-307,   5.11803656e-308,\n",
       "           5.11803656e-308],\n",
       "        [  1.51320369e-307,   1.24610248e-307,   1.11258277e-308,\n",
       "           2.00274302e-308],\n",
       "        [  1.95818179e-307,   4.00531629e-308,   1.39073143e-308,\n",
       "           1.20159217e-307],\n",
       "        [  1.27948283e-308,   2.33650241e-308,   2.22525041e-308,\n",
       "           3.33775339e-308],\n",
       "        [  3.11527996e-308,   2.00273454e-308,   9.79080032e-308,\n",
       "           3.56049165e-308],\n",
       "        [  3.33781280e-308,   2.04717660e-307,   1.33510679e-307,\n",
       "           2.18084067e-315],\n",
       "        [  2.27153626e-315,   2.18084067e-315,   2.27153628e-315,\n",
       "           2.18084067e-315],\n",
       "        [  2.27152241e-315,   2.18084067e-315,   2.27153633e-315,\n",
       "           2.18084067e-315],\n",
       "        [  2.27153640e-315,   2.18084067e-315,   2.27153643e-315,\n",
       "           2.18084067e-315],\n",
       "        [  2.27153645e-315,   2.18084067e-315,   2.27153647e-315,\n",
       "           2.18084067e-315],\n",
       "        [  2.27153650e-315,   2.18084067e-315,   2.27153652e-315,\n",
       "           2.18084067e-315],\n",
       "        [  2.27153654e-315,   2.18084067e-315,   2.27150856e-315,\n",
       "           2.18084067e-315],\n",
       "        [  2.27150896e-315,   2.18084067e-315,   2.27150922e-315,\n",
       "           2.18084067e-315],\n",
       "        [  2.27151010e-315,   2.18084067e-315,   2.27150827e-315,\n",
       "           2.18084067e-315],\n",
       "        [  2.27150829e-315,   2.18084067e-315,   2.27150832e-315,\n",
       "           2.18084067e-315],\n",
       "        [  2.27150834e-315,   1.02930033e+000,   1.01415004e+000,\n",
       "           8.27985037e-001],\n",
       "        [  7.99310218e-001,   9.84208642e-001,   8.65296557e-001,\n",
       "           8.64896564e-001]]),\n",
       " 'find_common_type': <function numpy.core.numerictypes.find_common_type>,\n",
       " 'finfo': numpy.core.getlimits.finfo,\n",
       " 'fix': <function numpy.lib.ufunclike.fix>,\n",
       " 'flatiter': numpy.flatiter,\n",
       " 'flatnonzero': <function numpy.core.numeric.flatnonzero>,\n",
       " 'flexible': numpy.flexible,\n",
       " 'flip': <function numpy.lib.function_base.flip>,\n",
       " 'fliplr': <function numpy.lib.twodim_base.fliplr>,\n",
       " 'flipud': <function numpy.lib.twodim_base.flipud>,\n",
       " 'float128': numpy.float128,\n",
       " 'float16': numpy.float16,\n",
       " 'float32': numpy.float32,\n",
       " 'float64': numpy.float64,\n",
       " 'float_': numpy.float64,\n",
       " 'float_power': <ufunc 'float_power'>,\n",
       " 'floating': numpy.floating,\n",
       " 'floor': <ufunc 'floor'>,\n",
       " 'floor_divide': <ufunc 'floor_divide'>,\n",
       " 'fmax': <ufunc 'fmax'>,\n",
       " 'fmin': <ufunc 'fmin'>,\n",
       " 'fmod': <ufunc 'fmod'>,\n",
       " 'format_parser': <class numpy.core.records.format_parser at 0x1086337a0>,\n",
       " 'frexp': <ufunc 'frexp'>,\n",
       " 'frombuffer': <function numpy.core.multiarray.frombuffer>,\n",
       " 'fromfile': <function numpy.core.multiarray.fromfile>,\n",
       " 'fromfunction': <function numpy.core.numeric.fromfunction>,\n",
       " 'fromiter': <function numpy.core.multiarray.fromiter>,\n",
       " 'frompyfunc': <function numpy.core.umath.frompyfunc>,\n",
       " 'fromregex': <function numpy.lib.npyio.fromregex>,\n",
       " 'fromstring': <function numpy.core.multiarray.fromstring>,\n",
       " 'full': <function numpy.core.numeric.full>,\n",
       " 'full_like': <function numpy.core.numeric.full_like>,\n",
       " 'fv': <function numpy.lib.financial.fv>,\n",
       " 'generic': numpy.generic,\n",
       " 'genfromtxt': <function numpy.lib.npyio.genfromtxt>,\n",
       " 'geomspace': <function numpy.core.function_base.geomspace>,\n",
       " 'get_array_wrap': <function numpy.lib.shape_base.get_array_wrap>,\n",
       " 'get_include': <function numpy.lib.utils.get_include>,\n",
       " 'get_ipython': <bound method ZMQInteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x10767ffd0>>,\n",
       " 'get_printoptions': <function numpy.core.arrayprint.get_printoptions>,\n",
       " 'getbuffer': <function numpy.core.multiarray.getbuffer>,\n",
       " 'getbufsize': <function numpy.core.numeric.getbufsize>,\n",
       " 'geterr': <function numpy.core.numeric.geterr>,\n",
       " 'geterrcall': <function numpy.core.numeric.geterrcall>,\n",
       " 'geterrobj': <function numpy.core.umath.geterrobj>,\n",
       " 'gradient': <function numpy.lib.function_base.gradient>,\n",
       " 'greater': <ufunc 'greater'>,\n",
       " 'greater_equal': <ufunc 'greater_equal'>,\n",
       " 'half': numpy.float16,\n",
       " 'hamming': <function numpy.lib.function_base.hamming>,\n",
       " 'hanning': <function numpy.lib.function_base.hanning>,\n",
       " 'heaviside': <ufunc 'heaviside'>,\n",
       " 'histogram': <function numpy.lib.function_base.histogram>,\n",
       " 'histogram2d': <function numpy.lib.twodim_base.histogram2d>,\n",
       " 'histogramdd': <function numpy.lib.function_base.histogramdd>,\n",
       " 'hsplit': <function numpy.lib.shape_base.hsplit>,\n",
       " 'hstack': <function numpy.core.shape_base.hstack>,\n",
       " 'hypot': <ufunc 'hypot'>,\n",
       " 'i': 4,\n",
       " 'i0': <function numpy.lib.function_base.i0>,\n",
       " 'identity': <function numpy.core.numeric.identity>,\n",
       " 'ii': array([1, 2, 3, 4]),\n",
       " 'iinfo': numpy.core.getlimits.iinfo,\n",
       " 'imag': <function numpy.lib.type_check.imag>,\n",
       " 'imputer': Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0),\n",
       " 'in1d': <function numpy.lib.arraysetops.in1d>,\n",
       " 'ind': array([ 53, 105, 205, 204, 172,   8,  66,  52,  81, 197, 220, 301,  18,\n",
       "        115, 296, 110,  46, 265, 294,  10,  76,  94, 109, 196,  44, 118,\n",
       "          5, 214, 240,  28, 286, 180, 102,  19, 215, 153, 267,  69, 217,\n",
       "          9, 144, 176, 242, 203,  85,  67,  40, 146, 211, 160, 131, 178,\n",
       "         78, 250,  25, 201,  21,  83, 228, 237, 288, 139,  16, 111,  51,\n",
       "        148,  17,  60, 167, 219,  23, 191, 233,   3,  38, 161, 245, 295,\n",
       "        188,  99, 114,  24,  50,  86,  15, 103, 299, 236,  64, 256, 287,\n",
       "        141,  14,  20,  49, 159, 282, 123, 279,  35,  74, 247, 170, 290,\n",
       "        200,  72,  42, 232, 249, 187,  54, 222, 289,  62, 154,  22, 195,\n",
       "          2, 269, 251, 185, 291,  71, 150, 278,  96, 100, 243,  80,   4,\n",
       "        129, 127, 164, 128, 163, 261, 210, 285, 143, 162,  77, 171,  39,\n",
       "        151, 258, 152, 268, 158, 157,  61, 229, 298, 297, 213, 124,  33,\n",
       "        275, 246,  12, 235, 264,  27, 271, 272, 283, 253,   6, 281, 175,\n",
       "        119,  95,  34, 140,  57,   7, 280, 206, 137,  26,  11, 277,  70,\n",
       "        192, 263, 101, 199, 257, 230, 108, 216,   1, 270,  87, 221, 132,\n",
       "        292, 149,  37, 202,  82, 226,  36, 212, 113, 166, 156,  79,  89,\n",
       "        117, 244, 186,   0, 223, 276, 126, 194, 189, 300, 207, 145, 142,\n",
       "        138,  31, 134, 208, 125, 241,  30,  32, 135, 273,  43, 231, 260,\n",
       "         84,  47, 122, 262, 106,  91, 254, 293, 165, 198,  90, 183, 224,\n",
       "        284, 130, 181, 182,  59, 266, 133, 259, 252,  48, 155,  68, 238,\n",
       "        116,  98, 173, 190, 112, 225, 179, 147, 234, 104, 121, 169, 193,\n",
       "        120, 255, 274, 174,  29,  65, 107,  13,  45, 227,  97, 218,  55,\n",
       "        168,  93, 239,  41,  88,  75, 209, 248,  56,  73, 177, 184, 136,\n",
       "         63,  58,  92]),\n",
       " 'index_exp': <numpy.lib.index_tricks.IndexExpression at 0x1086eb290>,\n",
       " 'indices': <function numpy.core.numeric.indices>,\n",
       " 'inexact': numpy.inexact,\n",
       " 'inf': inf,\n",
       " 'info': <function numpy.lib.utils.info>,\n",
       " 'infty': inf,\n",
       " 'inner': <function numpy.core.multiarray.inner>,\n",
       " 'insert': <function numpy.lib.function_base.insert>,\n",
       " 'int0': numpy.int64,\n",
       " 'int16': numpy.int16,\n",
       " 'int32': numpy.int32,\n",
       " 'int64': numpy.int64,\n",
       " 'int8': numpy.int8,\n",
       " 'int_': numpy.int64,\n",
       " 'int_asbuffer': <function numpy.core.multiarray.int_asbuffer>,\n",
       " 'intc': numpy.int32,\n",
       " 'integer': numpy.integer,\n",
       " 'interp': <function numpy.lib.function_base.interp>,\n",
       " 'intersect1d': <function numpy.lib.arraysetops.intersect1d>,\n",
       " 'intp': numpy.int64,\n",
       " 'invert': <ufunc 'invert'>,\n",
       " 'ipmt': <function numpy.lib.financial.ipmt>,\n",
       " 'irr': <function numpy.lib.financial.irr>,\n",
       " 'is_busday': <function numpy.core.multiarray.is_busday>,\n",
       " 'isclose': <function numpy.core.numeric.isclose>,\n",
       " 'iscomplex': <function numpy.lib.type_check.iscomplex>,\n",
       " 'iscomplexobj': <function numpy.lib.type_check.iscomplexobj>,\n",
       " 'isfinite': <ufunc 'isfinite'>,\n",
       " 'isfortran': <function numpy.core.numeric.isfortran>,\n",
       " 'isin': <function numpy.lib.arraysetops.isin>,\n",
       " 'isinf': <ufunc 'isinf'>,\n",
       " 'isnan': <ufunc 'isnan'>,\n",
       " 'isnat': <ufunc 'isnat'>,\n",
       " 'isneginf': <function numpy.lib.ufunclike.isneginf>,\n",
       " 'isposinf': <function numpy.lib.ufunclike.isposinf>,\n",
       " 'isreal': <function numpy.lib.type_check.isreal>,\n",
       " 'isrealobj': <function numpy.lib.type_check.isrealobj>,\n",
       " 'isscalar': <function numpy.core.numeric.isscalar>,\n",
       " 'issctype': <function numpy.core.numerictypes.issctype>,\n",
       " 'issubclass_': <function numpy.core.numerictypes.issubclass_>,\n",
       " 'issubdtype': <function numpy.core.numerictypes.issubdtype>,\n",
       " 'issubsctype': <function numpy.core.numerictypes.issubsctype>,\n",
       " 'iterable': <function numpy.lib.function_base.iterable>,\n",
       " 'ix_': <function numpy.lib.index_tricks.ix_>,\n",
       " 'kaiser': <function numpy.lib.function_base.kaiser>,\n",
       " 'key': 'lev1',\n",
       " 'kron': <function numpy.lib.shape_base.kron>,\n",
       " 'labels_true': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.]),\n",
       " 'lady_dudes':        src_subject_id  pds_ht2_y  pds_skin2_y  pds_bdyhair_y  PDS  pds_f4_2_y  \\\n",
       " 0    NDAR_INV00X2TBWJ          1            1              1  1.0         1.0   \n",
       " 1    NDAR_INV028D3ELL          3            3              1  1.8         1.0   \n",
       " 2    NDAR_INV02H7G2T6          3            1              2  1.8         2.0   \n",
       " 3    NDAR_INV03NW0RKL          2            1              1  1.4         2.0   \n",
       " 4    NDAR_INV05T64PXD          3            2              2  2.0         2.0   \n",
       " 5    NDAR_INV07RAHHYH          1            1              1  1.2         2.0   \n",
       " 6    NDAR_INV09T2EBX4          2            1              1  1.2         1.0   \n",
       " 7    NDAR_INV0A9K5L4R          2            1              1  1.2         1.0   \n",
       " 8    NDAR_INV0AEBMADL          4            1              4  2.8         4.0   \n",
       " 9    NDAR_INV0B7UGM1D          3            1              1  1.4         1.0   \n",
       " 10   NDAR_INV0C1ED337          4            1              1  1.8         2.0   \n",
       " 11   NDAR_INV0C765WK4          2            2              2  1.8         2.0   \n",
       " 12   NDAR_INV0CP9XGTP          3            3              1  2.2         3.0   \n",
       " 13   NDAR_INV0D0C239B          2            1              1  1.2         1.0   \n",
       " 14   NDAR_INV0D83M5VE          3            2              2  2.0         2.0   \n",
       " 15   NDAR_INV0DBRJXKG          2            2              1  1.6         2.0   \n",
       " 16   NDAR_INV0DVK13LU          1            1              1  1.0         1.0   \n",
       " 17   NDAR_INV0EV57VEX          2            3              3  2.2         2.0   \n",
       " 18   NDAR_INV0GUTM6AM          3            3              2  2.2         2.0   \n",
       " 19   NDAR_INV0GZM9UZJ          3            2              2  1.8         1.0   \n",
       " 20   NDAR_INV0J6LY05U          3            3              1  2.0         2.0   \n",
       " 21   NDAR_INV0JWEE23L          2            2              2  2.0         3.0   \n",
       " 22   NDAR_INV0KPZW3NB          3            1              1  1.6         2.0   \n",
       " 23   NDAR_INV0L3VJZEL          1            1              1  1.0         1.0   \n",
       " 24   NDAR_INV0MRY4Z3E          3            2              3  2.4         3.0   \n",
       " 25   NDAR_INV0P0GTDY0          3            1              1  1.6         2.0   \n",
       " 26   NDAR_INV0PHTY15N          3            2              2  1.8         1.0   \n",
       " 27   NDAR_INV0RHLKA9M          4            3              4  3.0         3.0   \n",
       " 28   NDAR_INV0UPVEC1J          1            1              1  1.0         1.0   \n",
       " 29   NDAR_INV0UYDV4HJ          3            2              1  2.0         3.0   \n",
       " ..                ...        ...          ...            ...  ...         ...   \n",
       " 873  NDAR_INVZ5M1W790          2            1              2  1.4         1.0   \n",
       " 874  NDAR_INVZ730VLUZ          3            3              3  3.2         3.0   \n",
       " 875  NDAR_INVZ85UEYE5          3            2              2  2.2         3.0   \n",
       " 876  NDAR_INVZ96PL9LM          3            2              1  1.8         2.0   \n",
       " 877  NDAR_INVZ9DEWNVF          3            1              1  1.4         1.0   \n",
       " 878  NDAR_INVZ9T3MCZC          3            1              2  1.6         1.0   \n",
       " 879  NDAR_INVZ9U6GT0L          3            2              1  1.6         1.0   \n",
       " 880  NDAR_INVZB0WCRDU          3            2              1  1.6         1.0   \n",
       " 881  NDAR_INVZBH4VPZJ          2            1              2  1.6         2.0   \n",
       " 882  NDAR_INVZCA261ZR          4            3              3  2.8         3.0   \n",
       " 883  NDAR_INVZCDF5310          4            1              4  3.4         4.0   \n",
       " 884  NDAR_INVZCZPNBKW          1            1              1  1.0         1.0   \n",
       " 885  NDAR_INVZD57Y0V7          3            2              1  1.8         2.0   \n",
       " 886  NDAR_INVZGWMJWB5          1            1              1  1.0         1.0   \n",
       " 887  NDAR_INVZJEG08WY          2            2              1  1.4         1.0   \n",
       " 888  NDAR_INVZK8052MG          2            2              1  1.6         2.0   \n",
       " 889  NDAR_INVZLD0PANU          3            2              3  2.4         3.0   \n",
       " 890  NDAR_INVZN9E45NT          3            2              2  2.0         2.0   \n",
       " 891  NDAR_INVZPCU8GG3          2            1              2  1.4         1.0   \n",
       " 892  NDAR_INVZRDZ2V00          3            2              1  1.6         1.0   \n",
       " 893  NDAR_INVZTTGYL51          3            1              2  1.8         2.0   \n",
       " 894  NDAR_INVZTWTFU2A          3            1              3  2.2         3.0   \n",
       " 895  NDAR_INVZUJYFZPW          1            1              2  1.4         2.0   \n",
       " 896  NDAR_INVZUXHPX3N          3            1              2  1.6         1.0   \n",
       " 897  NDAR_INVZVD13ZMG          3            1              2  1.6         1.0   \n",
       " 898  NDAR_INVZVGAMFG7          1            1              1  1.2         2.0   \n",
       " 899  NDAR_INVZWP490TG          2            1              2  1.6         2.0   \n",
       " 900  NDAR_INVZXKWKTC7          3            2              3  2.2         2.0   \n",
       " 901  NDAR_INVZXL36BR5          4            2              2  2.2         2.0   \n",
       " 902  NDAR_INVZZZ2ALR6          2            2              2  1.6         1.0   \n",
       " \n",
       "      pds_f5_y  pds_m4_y  pds_m5_y  interview_age gender  anthroheightcalc  \\\n",
       " 0         1.0       0.0       0.0            130      F         54.500000   \n",
       " 1         1.0       0.0       0.0            109      F         57.500000   \n",
       " 2         1.0       0.0       0.0            119      F         58.950000   \n",
       " 3         1.0       0.0       0.0            119      F         54.833333   \n",
       " 4         1.0       0.0       0.0            109      F         59.200000   \n",
       " 5         1.0       0.0       0.0            119      F         53.140000   \n",
       " 6         1.0       0.0       0.0            108      F         50.000000   \n",
       " 7         1.0       0.0       0.0            132      F         58.000000   \n",
       " 8         1.0       0.0       0.0            126      F         59.000000   \n",
       " 9         1.0       0.0       0.0            117      F         51.900000   \n",
       " 10        1.0       0.0       0.0            125      F         62.500000   \n",
       " 11        1.0       0.0       0.0            131      F         58.000000   \n",
       " 12        1.0       0.0       0.0            128      F         62.000000   \n",
       " 13        1.0       0.0       0.0            108      F         54.300000   \n",
       " 14        1.0       0.0       0.0            130      F         62.000000   \n",
       " 15        1.0       0.0       0.0            130      F         55.000000   \n",
       " 16        1.0       0.0       0.0            128      F         53.550000   \n",
       " 17        1.0       0.0       0.0            129      F         60.750000   \n",
       " 18        1.0       0.0       0.0            131      F         59.000000   \n",
       " 19        1.0       0.0       0.0            118      F         57.250000   \n",
       " 20        1.0       0.0       0.0            108      F         55.000000   \n",
       " 21        1.0       0.0       0.0            131      F         57.250000   \n",
       " 22        1.0       0.0       0.0            123      F         60.500000   \n",
       " 23        1.0       0.0       0.0            115      F         55.500000   \n",
       " 24        1.0       0.0       0.0            111      F         51.800000   \n",
       " 25        1.0       0.0       0.0            129      F         55.000000   \n",
       " 26        1.0       0.0       0.0            116      F         56.000000   \n",
       " 27        1.0       0.0       0.0            129      F         58.000000   \n",
       " 28        1.0       0.0       0.0            121      F         55.250000   \n",
       " 29        1.0       0.0       0.0            131      F         58.000000   \n",
       " ..        ...       ...       ...            ...    ...               ...   \n",
       " 873       1.0       0.0       0.0            110      F         53.375000   \n",
       " 874       4.0       0.0       0.0            126      F         61.000000   \n",
       " 875       1.0       0.0       0.0            121      F         59.500000   \n",
       " 876       1.0       0.0       0.0            117      F         52.166667   \n",
       " 877       1.0       0.0       0.0            119      F         49.500000   \n",
       " 878       1.0       0.0       0.0            110      F         50.000000   \n",
       " 879       1.0       0.0       0.0            123      F         51.500000   \n",
       " 880       1.0       0.0       0.0            114      F         57.250000   \n",
       " 881       1.0       0.0       0.0            129      F         54.500000   \n",
       " 882       1.0       0.0       0.0            130      F         58.000000   \n",
       " 883       4.0       0.0       0.0            127      F         62.166667   \n",
       " 884       1.0       0.0       0.0            114      F         52.900000   \n",
       " 885       1.0       0.0       0.0            130      F         58.000000   \n",
       " 886       1.0       0.0       0.0            115      F         50.900000   \n",
       " 887       1.0       0.0       0.0            132      F         52.500000   \n",
       " 888       1.0       0.0       0.0            130      F         57.000000   \n",
       " 889       1.0       0.0       0.0            131      F         57.000000   \n",
       " 890       1.0       0.0       0.0            129      F         53.000000   \n",
       " 891       1.0       0.0       0.0            107      F         52.750000   \n",
       " 892       1.0       0.0       0.0            113      F         54.000000   \n",
       " 893       1.0       0.0       0.0            125      F         54.250000   \n",
       " 894       1.0       0.0       0.0            124      F         60.700000   \n",
       " 895       1.0       0.0       0.0            132      F         55.750000   \n",
       " 896       1.0       0.0       0.0            108      F         50.100000   \n",
       " 897       1.0       0.0       0.0            122      F         56.000000   \n",
       " 898       1.0       0.0       0.0            119      F         52.300000   \n",
       " 899       1.0       0.0       0.0            127      F         58.000000   \n",
       " 900       1.0       0.0       0.0            121      F         58.125000   \n",
       " 901       1.0       0.0       0.0            121      F         61.000000   \n",
       " 902       1.0       0.0       0.0            121      F         54.700000   \n",
       " \n",
       "      anthroweightcalc  anthro_waist_cm  hormone_scr_dhea_mean  \\\n",
       " 0           68.500000            22.25                   1089   \n",
       " 1           72.000000            23.50                    667   \n",
       " 2           96.600000            30.00                   1528   \n",
       " 3           65.266667            21.80                    214   \n",
       " 4           94.800000            26.40                      1   \n",
       " 5           69.000000            23.75                   2127   \n",
       " 6           65.083333            26.00                   1018   \n",
       " 7           84.000000            28.00                   1067   \n",
       " 8          141.950000            35.00                     23   \n",
       " 9           58.200000            22.45                     44   \n",
       " 10         189.000000            42.00                      1   \n",
       " 11         134.000000            23.00                   2525   \n",
       " 12         109.000000            26.00                     49   \n",
       " 13          63.566667            20.50                    108   \n",
       " 14          95.000000            26.00                      1   \n",
       " 15          88.000000            27.50                   1969   \n",
       " 16          70.400000            25.50                    651   \n",
       " 17         115.000000            30.00                    715   \n",
       " 18          80.500000            20.50                      1   \n",
       " 19          72.000000            25.00                   2356   \n",
       " 20          61.400000            21.00                   1234   \n",
       " 21          81.000000            25.50                     73   \n",
       " 22         125.000000            35.00                   1849   \n",
       " 23          64.500000            23.00                   2491   \n",
       " 24          74.200000            24.30                   1588   \n",
       " 25          49.500000            25.00                   2201   \n",
       " 26          63.000000            22.00                      1   \n",
       " 27          87.000000            28.00                    316   \n",
       " 28          93.000000            29.00                      1   \n",
       " 29         114.000000            28.00                   2196   \n",
       " ..                ...              ...                    ...   \n",
       " 873         60.566667            21.50                      1   \n",
       " 874        118.000000            31.00                      1   \n",
       " 875        152.833333            35.00                      1   \n",
       " 876         63.200000            27.50                      1   \n",
       " 877        130.000000            31.50                    626   \n",
       " 878         74.250000            24.25                   1886   \n",
       " 879         61.000000            24.00                      1   \n",
       " 880         90.000000            29.00                   2484   \n",
       " 881         61.000000            23.50                   1027   \n",
       " 882         89.000000            25.50                    224   \n",
       " 883        129.250000            31.50                      1   \n",
       " 884         82.050000            29.00                    989   \n",
       " 885        145.300000            36.80                      1   \n",
       " 886         58.333333            22.50                      1   \n",
       " 887         56.000000            23.00                      1   \n",
       " 888         78.000000            27.00                   1302   \n",
       " 889         76.000000            25.00                   2503   \n",
       " 890         74.000000            61.00                      1   \n",
       " 891         57.900000            23.00                   2098   \n",
       " 892         60.900000            24.00                      1   \n",
       " 893         81.400000            26.80                      1   \n",
       " 894        163.300000            35.50                      1   \n",
       " 895         78.500000            29.00                      1   \n",
       " 896         61.166667            25.90                      1   \n",
       " 897         66.000000            23.50                   2137   \n",
       " 898         61.800000            22.00                   2261   \n",
       " 899        103.000000            29.00                    299   \n",
       " 900         74.000000            25.00                   1786   \n",
       " 901         88.000000            25.00                    279   \n",
       " 902         59.500000            19.00                    311   \n",
       " \n",
       "      hormone_scr_hse_mean  hormone_scr_ert_mean  sex  \n",
       " 0                  1.0450               16.6165    1  \n",
       " 1                  1.3000               39.3810    1  \n",
       " 2                  1.1200               36.1655    1  \n",
       " 3                  1.3485               39.3290    1  \n",
       " 4                     NaN                   NaN    1  \n",
       " 5                  1.0105               31.3025    1  \n",
       " 6                  1.2275               18.3435    1  \n",
       " 7                  0.5725               12.6605    1  \n",
       " 8                     NaN                   NaN    1  \n",
       " 9                     NaN                   NaN    1  \n",
       " 10                    NaN                   NaN    1  \n",
       " 11                 1.2165               28.4050    1  \n",
       " 12                    NaN                   NaN    1  \n",
       " 13                 0.0000                0.0000    1  \n",
       " 14                    NaN                   NaN    1  \n",
       " 15                 0.8255               20.9600    1  \n",
       " 16                 1.2950               14.9500    1  \n",
       " 17                 1.5605               59.6315    1  \n",
       " 18                    NaN                   NaN    1  \n",
       " 19                 1.3600               40.8200    1  \n",
       " 20                 0.8050               22.2535    1  \n",
       " 21                 1.0720               44.5270    1  \n",
       " 22                 1.8260               32.2820    1  \n",
       " 23                 1.3330               26.9420    1  \n",
       " 24                26.3880                   NaN    1  \n",
       " 25                 1.2100               50.0400    1  \n",
       " 26                    NaN                   NaN    1  \n",
       " 27                 1.0300               46.6330    1  \n",
       " 28                    NaN                   NaN    1  \n",
       " 29                 1.2025               42.7685    1  \n",
       " ..                    ...                   ...  ...  \n",
       " 873                   NaN                   NaN    1  \n",
       " 874                   NaN                   NaN    1  \n",
       " 875                   NaN                   NaN    1  \n",
       " 876                   NaN                   NaN    1  \n",
       " 877                1.0800               84.1000    1  \n",
       " 878                1.1810               30.8300    1  \n",
       " 879                   NaN                   NaN    1  \n",
       " 880                0.7630               35.8605    1  \n",
       " 881                0.5955               14.6855    1  \n",
       " 882                2.1900               88.9600    1  \n",
       " 883                   NaN                   NaN    1  \n",
       " 884                1.4290               22.6625    1  \n",
       " 885                   NaN                   NaN    1  \n",
       " 886                   NaN                   NaN    1  \n",
       " 887                   NaN                   NaN    1  \n",
       " 888                0.7470               26.9815    1  \n",
       " 889                1.8130               44.8795    1  \n",
       " 890                   NaN                   NaN    1  \n",
       " 891                0.5560               10.3710    1  \n",
       " 892                   NaN                   NaN    1  \n",
       " 893                   NaN                   NaN    1  \n",
       " 894                   NaN                   NaN    1  \n",
       " 895                   NaN                   NaN    1  \n",
       " 896                   NaN                   NaN    1  \n",
       " 897                1.8350               38.4530    1  \n",
       " 898                1.5500               48.2375    1  \n",
       " 899                1.4815               42.8325    1  \n",
       " 900                0.7825               26.5845    1  \n",
       " 901                0.5555               11.9505    1  \n",
       " 902                1.3090               51.1875    1  \n",
       " \n",
       " [903 rows x 18 columns],\n",
       " 'ldexp': <ufunc 'ldexp'>,\n",
       " 'left_shift': <ufunc 'left_shift'>,\n",
       " 'less': <ufunc 'less'>,\n",
       " 'less_equal': <ufunc 'less_equal'>,\n",
       " 'lev': 'lev3',\n",
       " 'levels': ['lev1', 'lev2', 'lev3'],\n",
       " 'lexsort': <function numpy.core.multiarray.lexsort>,\n",
       " 'linalg': <module 'numpy.linalg' from '/anaconda2/lib/python2.7/site-packages/numpy/linalg/__init__.pyc'>,\n",
       " 'linspace': <function numpy.core.function_base.linspace>,\n",
       " 'little_endian': True,\n",
       " 'load': <function numpy.lib.npyio.load>,\n",
       " 'load_digits': <function sklearn.datasets.base.load_digits>,\n",
       " 'load_iris': <function sklearn.datasets.base.load_iris>,\n",
       " 'loads': <function cPickle.loads>,\n",
       " 'loadtxt': <function numpy.lib.npyio.loadtxt>,\n",
       " 'log': <ufunc 'log'>,\n",
       " 'log10': <ufunc 'log10'>,\n",
       " 'log1p': <ufunc 'log1p'>,\n",
       " 'log2': <ufunc 'log2'>,\n",
       " 'logaddexp': <ufunc 'logaddexp'>,\n",
       " 'logaddexp2': <ufunc 'logaddexp2'>,\n",
       " 'logical_and': <ufunc 'logical_and'>,\n",
       " 'logical_not': <ufunc 'logical_not'>,\n",
       " 'logical_or': <ufunc 'logical_or'>,\n",
       " 'logical_xor': <ufunc 'logical_xor'>,\n",
       " 'logspace': <function numpy.core.function_base.logspace>,\n",
       " 'longcomplex': numpy.complex256,\n",
       " 'longdouble': numpy.float128,\n",
       " 'longfloat': numpy.float128,\n",
       " 'longlong': numpy.int64,\n",
       " 'lookfor': <function numpy.lib.utils.lookfor>,\n",
       " 'ma': <module 'numpy.ma' from '/anaconda2/lib/python2.7/site-packages/numpy/ma/__init__.pyc'>,\n",
       " 'mafromtxt': <function numpy.lib.npyio.mafromtxt>,\n",
       " 'mask_indices': <function numpy.lib.twodim_base.mask_indices>,\n",
       " 'mat': <function numpy.matrixlib.defmatrix.asmatrix>,\n",
       " 'math': <module 'math' from '/anaconda2/lib/python2.7/lib-dynload/math.so'>,\n",
       " 'matmul': <function numpy.core.multiarray.matmul>,\n",
       " 'matplotlib': <module 'matplotlib' from '/anaconda2/lib/python2.7/site-packages/matplotlib/__init__.pyc'>,\n",
       " 'matrix': numpy.matrixlib.defmatrix.matrix,\n",
       " 'maximum': <ufunc 'maximum'>,\n",
       " 'maximum_sctype': <function numpy.core.numerictypes.maximum_sctype>,\n",
       " 'may_share_memory': <function numpy.core.multiarray.may_share_memory>,\n",
       " 'mean': <function numpy.core.fromnumeric.mean>,\n",
       " 'median': <function numpy.lib.function_base.median>,\n",
       " 'memmap': numpy.core.memmap.memmap,\n",
       " 'meshgrid': <function numpy.lib.function_base.meshgrid>,\n",
       " 'metrics': <module 'sklearn.metrics' from '/anaconda2/lib/python2.7/site-packages/sklearn/metrics/__init__.pyc'>,\n",
       " 'mgrid': <numpy.lib.index_tricks.nd_grid at 0x1086dafd0>,\n",
       " 'min_scalar_type': <function numpy.core.multiarray.min_scalar_type>,\n",
       " 'minimum': <ufunc 'minimum'>,\n",
       " 'mintypecode': <function numpy.lib.type_check.mintypecode>,\n",
       " 'mirr': <function numpy.lib.financial.mirr>,\n",
       " 'mod': <ufunc 'remainder'>,\n",
       " 'modf': <ufunc 'modf'>,\n",
       " 'moveaxis': <function numpy.core.numeric.moveaxis>,\n",
       " 'msort': <function numpy.lib.function_base.msort>,\n",
       " 'multiply': <ufunc 'multiply'>,\n",
       " 'n': 10,\n",
       " 'n_features': 12,\n",
       " 'n_samples': 721,\n",
       " 'names': ['pds_ht2_y',\n",
       "  'pds_skin2_ypds_bdyhair_y',\n",
       "  'pds_f4_2_y',\n",
       "  'pds_f5_y',\n",
       "  'interview_age',\n",
       "  'anthroheightcalc',\n",
       "  'anthroweightcalc',\n",
       "  'anthro_waist_cm',\n",
       "  'hormone_scr_dhea_mean',\n",
       "  'hormone_scr_hse_mean',\n",
       "  'hormone_scr_ert_mean'],\n",
       " 'nan': nan,\n",
       " 'nan_to_num': <function numpy.lib.type_check.nan_to_num>,\n",
       " 'nanargmax': <function numpy.lib.nanfunctions.nanargmax>,\n",
       " 'nanargmin': <function numpy.lib.nanfunctions.nanargmin>,\n",
       " 'nancumprod': <function numpy.lib.nanfunctions.nancumprod>,\n",
       " 'nancumsum': <function numpy.lib.nanfunctions.nancumsum>,\n",
       " 'nanmax': <function numpy.lib.nanfunctions.nanmax>,\n",
       " 'nanmean': <function numpy.lib.nanfunctions.nanmean>,\n",
       " 'nanmedian': <function numpy.lib.nanfunctions.nanmedian>,\n",
       " 'nanmin': <function numpy.lib.nanfunctions.nanmin>,\n",
       " 'nanpercentile': <function numpy.lib.nanfunctions.nanpercentile>,\n",
       " 'nanprod': <function numpy.lib.nanfunctions.nanprod>,\n",
       " 'nanstd': <function numpy.lib.nanfunctions.nanstd>,\n",
       " 'nansum': <function numpy.lib.nanfunctions.nansum>,\n",
       " 'nanvar': <function numpy.lib.nanfunctions.nanvar>,\n",
       " 'nbytes': {numpy.bool_: 1,\n",
       "  numpy.object_: 8,\n",
       "  numpy.string_: 0,\n",
       "  numpy.unicode_: 0,\n",
       "  numpy.void: 0,\n",
       "  numpy.int8: 1,\n",
       "  numpy.int16: 2,\n",
       "  numpy.int32: 4,\n",
       "  numpy.int64: 8,\n",
       "  numpy.int64: 8,\n",
       "  numpy.uint8: 1,\n",
       "  numpy.uint16: 2,\n",
       "  numpy.uint32: 4,\n",
       "  numpy.uint64: 8,\n",
       "  numpy.uint64: 8,\n",
       "  numpy.float16: 2,\n",
       "  numpy.float32: 4,\n",
       "  numpy.float64: 8,\n",
       "  numpy.float128: 16,\n",
       "  numpy.datetime64: 8,\n",
       "  numpy.timedelta64: 8,\n",
       "  numpy.complex64: 8,\n",
       "  numpy.complex128: 16,\n",
       "  numpy.complex256: 32},\n",
       " 'ndarray': numpy.ndarray,\n",
       " 'ndenumerate': numpy.lib.index_tricks.ndenumerate,\n",
       " 'ndfromtxt': <function numpy.lib.npyio.ndfromtxt>,\n",
       " 'ndim': <function numpy.core.fromnumeric.ndim>,\n",
       " 'ndindex': numpy.lib.index_tricks.ndindex,\n",
       " 'nditer': numpy.nditer,\n",
       " 'negative': <ufunc 'negative'>,\n",
       " 'nested_iters': <function numpy.core.multiarray.nested_iters>,\n",
       " 'newaxis': None,\n",
       " 'newbuffer': <function numpy.core.multiarray.newbuffer>,\n",
       " 'nextafter': <ufunc 'nextafter'>,\n",
       " 'nonzero': <function numpy.core.fromnumeric.nonzero>,\n",
       " 'not_equal': <ufunc 'not_equal'>,\n",
       " 'np': <module 'numpy' from '/anaconda2/lib/python2.7/site-packages/numpy/__init__.pyc'>,\n",
       " 'nper': <function numpy.lib.financial.nper>,\n",
       " 'npv': <function numpy.lib.financial.npv>,\n",
       " 'number': numpy.number,\n",
       " 'obj2sctype': <function numpy.core.numerictypes.obj2sctype>,\n",
       " 'object0': numpy.object_,\n",
       " 'object_': numpy.object_,\n",
       " 'ogrid': <numpy.lib.index_tricks.nd_grid at 0x1086eb090>,\n",
       " 'ones': <function numpy.core.numeric.ones>,\n",
       " 'ones_like': <function numpy.core.numeric.ones_like>,\n",
       " 'outer': <function numpy.core.numeric.outer>,\n",
       " 'packbits': <function numpy.core.multiarray.packbits>,\n",
       " 'pad': <function numpy.lib.arraypad.pad>,\n",
       " 'partition': <function numpy.core.fromnumeric.partition>,\n",
       " 'pd': <module 'pandas' from '/anaconda2/lib/python2.7/site-packages/pandas/__init__.pyc'>,\n",
       " 'percentile': <function numpy.lib.function_base.percentile>,\n",
       " 'pi': 3.141592653589793,\n",
       " 'piecewise': <function numpy.lib.function_base.piecewise>,\n",
       " 'pkgload': <function numpy.pkgload>,\n",
       " 'place': <function numpy.lib.function_base.place>,\n",
       " 'plt': <module 'matplotlib.pyplot' from '/anaconda2/lib/python2.7/site-packages/matplotlib/pyplot.pyc'>,\n",
       " 'pmt': <function numpy.lib.financial.pmt>,\n",
       " 'poly': <function numpy.lib.polynomial.poly>,\n",
       " 'poly1d': numpy.lib.polynomial.poly1d,\n",
       " 'polyadd': <function numpy.lib.polynomial.polyadd>,\n",
       " 'polyder': <function numpy.lib.polynomial.polyder>,\n",
       " 'polydiv': <function numpy.lib.polynomial.polydiv>,\n",
       " 'polyfit': <function numpy.lib.polynomial.polyfit>,\n",
       " 'polyint': <function numpy.lib.polynomial.polyint>,\n",
       " 'polymul': <function numpy.lib.polynomial.polymul>,\n",
       " 'polysub': <function numpy.lib.polynomial.polysub>,\n",
       " 'polyval': <function numpy.lib.polynomial.polyval>,\n",
       " 'positive': <ufunc 'positive'>,\n",
       " 'power': <ufunc 'power'>,\n",
       " 'ppmt': <function numpy.lib.financial.ppmt>,\n",
       " 'prod': <function numpy.core.fromnumeric.prod>,\n",
       " 'product': <function numpy.core.fromnumeric.product>,\n",
       " 'promote_types': <function numpy.core.multiarray.promote_types>,\n",
       " 'ptp': <function numpy.core.fromnumeric.ptp>,\n",
       " 'put': <function numpy.core.fromnumeric.put>,\n",
       " 'putmask': <function numpy.core.multiarray.putmask>,\n",
       " 'pv': <function numpy.lib.financial.pv>,\n",
       " 'quit': <IPython.core.autocall.ZMQExitAutocall at 0x10773bb90>,\n",
       " 'r_': <numpy.lib.index_tricks.RClass at 0x1086eb110>,\n",
       " 'rad2deg': <ufunc 'rad2deg'>,\n",
       " 'radians': <ufunc 'radians'>,\n",
       " 'rand_dict': {'lev1': array([[ -4.94235846e-01,  -9.16001298e-01,   3.25320092e-01,\n",
       "           -1.09062346e+00,  -1.91891602e-01,  -1.75158436e+00,\n",
       "           -1.14479753e+00,  -4.02277474e-01,  -8.48628698e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            1.00000000e+00],\n",
       "         [  6.50110229e-01,  -9.16001298e-01,  -8.45054583e-01,\n",
       "           -1.09062346e+00,  -1.91891602e-01,  -1.89003680e+00,\n",
       "           -1.56405822e+00,  -1.35584960e+00,  -1.16359520e+00,\n",
       "            1.27727805e+00,  -1.57519992e-01,   1.40434932e+00,\n",
       "            1.00000000e+00],\n",
       "         [  6.50110229e-01,  -9.16001298e-01,  -8.45054583e-01,\n",
       "           -1.09062346e+00,  -1.91891602e-01,  -1.75158436e+00,\n",
       "           -8.45325608e-01,  -5.69938507e-01,  -9.53617532e-01,\n",
       "            6.22840123e-01,  -2.45222140e-01,  -5.95931040e-01,\n",
       "            1.00000000e+00],\n",
       "         [ -4.94235846e-01,  -9.16001298e-01,  -8.45054583e-01,\n",
       "           -1.09062346e+00,  -1.91891602e-01,  -1.61313192e+00,\n",
       "           -3.96117725e-01,   1.84536141e-01,   5.68720553e-01,\n",
       "            7.44491236e-01,  -1.79445529e-01,  -7.14664752e-01,\n",
       "            1.00000000e+00],\n",
       "         [ -1.63858192e+00,   3.80470758e-01,  -8.45054583e-01,\n",
       "            2.49624989e-01,  -1.91891602e-01,   1.43282177e+00,\n",
       "            5.30901591e-02,  -2.76531700e-01,  -8.48628698e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            1.00000000e+00],\n",
       "         [ -1.63858192e+00,  -9.16001298e-01,  -8.45054583e-01,\n",
       "           -1.09062346e+00,  -1.91891602e-01,  -7.82417280e-01,\n",
       "           -9.66458021e-02,  -8.00472427e-01,  -7.43639865e-01,\n",
       "            1.92270479e+00,  -2.21679145e-01,  -5.38988548e-01,\n",
       "            1.00000000e+00],\n",
       "         [ -4.94235846e-01,   3.80470758e-01,  -8.45054583e-01,\n",
       "           -1.09062346e+00,  -1.91891602e-01,  -7.82417280e-01,\n",
       "            2.02826120e-01,  -3.18446958e-01,  -1.13706864e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            1.00000000e+00],\n",
       "         [  6.50110229e-01,  -9.16001298e-01,  -8.45054583e-01,\n",
       "           -1.09062346e+00,  -1.91891602e-01,  -7.82417280e-01,\n",
       "           -5.83287676e-01,  -3.18446958e-01,  -6.38651031e-01,\n",
       "            1.34486200e+00,  -2.35966688e-01,  -2.48425555e-01,\n",
       "            1.00000000e+00],\n",
       "         [ -1.63858192e+00,  -9.16001298e-01,  -8.45054583e-01,\n",
       "            2.49624989e-01,  -1.91891602e-01,  -7.82417280e-01,\n",
       "           -8.45325608e-01,  -7.16641911e-01,  -7.43639865e-01,\n",
       "            9.12324715e-01,  -1.31460953e-01,  -1.04526547e-01,\n",
       "            1.00000000e+00],\n",
       "         [ -4.94235846e-01,  -9.16001298e-01,  -8.45054583e-01,\n",
       "           -1.09062346e+00,  -1.91891602e-01,  -1.75158436e+00,\n",
       "           -4.70985705e-01,  -3.60362216e-01,  -1.13706864e-01,\n",
       "            8.10948788e-01,  -2.74156660e-01,  -1.11686869e+00,\n",
       "            1.00000000e+00],\n",
       "         [ -1.63858192e+00,  -9.16001298e-01,   3.25320092e-01,\n",
       "            2.49624989e-01,  -1.91891602e-01,   1.43282177e+00,\n",
       "           -9.66458021e-02,  -9.89091089e-01,  -7.43639865e-01,\n",
       "           -7.20954108e-01,  -2.72539202e-01,  -5.08333370e-01,\n",
       "            1.00000000e+00],\n",
       "         [ -1.63858192e+00,  -9.16001298e-01,  -8.45054583e-01,\n",
       "            2.49624989e-01,  -1.91891602e-01,  -2.28607518e-01,\n",
       "           -1.05495595e+00,  -9.13643624e-01,  -9.53617532e-01,\n",
       "            1.66363297e+00,  -1.82680444e-01,   1.16772341e+00,\n",
       "            1.00000000e+00],\n",
       "         [ -4.94235846e-01,  -9.16001298e-01,  -8.45054583e-01,\n",
       "           -1.09062346e+00,  -1.91891602e-01,  -9.20869721e-01,\n",
       "           -1.48919024e+00,  -1.10435805e+00,  -8.48628698e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            1.00000000e+00],\n",
       "         [ -1.63858192e+00,   3.80470758e-01,  -8.45054583e-01,\n",
       "            2.49624989e-01,  -1.91891602e-01,   4.63654685e-01,\n",
       "           -1.44426945e+00,  -9.47175831e-01,  -5.33662198e-01,\n",
       "            1.11958217e+00,  -3.15851123e-01,  -3.77337587e-01,\n",
       "            1.00000000e+00],\n",
       "         [ -1.63858192e+00,  -9.16001298e-01,  -8.45054583e-01,\n",
       "           -1.09062346e+00,  -1.91891602e-01,  -9.20869721e-01,\n",
       "           -8.75272800e-01,  -6.48596458e-02,   5.16226137e-01,\n",
       "            2.30853206e-01,  -2.04426264e-01,  -8.81965882e-01,\n",
       "            1.00000000e+00],\n",
       "         [  6.50110229e-01,  -9.16001298e-01,  -8.45054583e-01,\n",
       "           -1.09062346e+00,  -1.91891602e-01,   1.29436933e+00,\n",
       "            2.22426160e+00,   1.42103626e+00,  -8.71803063e-03,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            1.00000000e+00],\n",
       "         [ -4.94235846e-01,  -9.16001298e-01,  -8.45054583e-01,\n",
       "           -1.09062346e+00,  -1.91891602e-01,  -2.28607518e-01,\n",
       "           -6.80422538e-03,  -6.95684282e-01,  -6.38651031e-01,\n",
       "            2.07198823e-01,  -2.87725332e-01,  -1.02762806e+00,\n",
       "            1.00000000e+00],\n",
       "         [ -1.63858192e+00,  -9.16001298e-01,  -8.45054583e-01,\n",
       "            2.49624989e-01,  -1.91891602e-01,  -3.67059959e-01,\n",
       "           -5.45853686e-01,  -6.95684282e-01,  -4.28673365e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            1.00000000e+00],\n",
       "         [ -4.94235846e-01,  -9.16001298e-01,   3.25320092e-01,\n",
       "           -1.09062346e+00,  -1.91891602e-01,  -1.47467948e+00,\n",
       "           -7.33023637e-01,  -9.65339109e-01,  -1.05860637e+00,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            1.00000000e+00],\n",
       "         [ -1.63858192e+00,  -9.16001298e-01,  -8.45054583e-01,\n",
       "            2.49624989e-01,  -1.91891602e-01,  -1.61313192e+00,\n",
       "           -1.44426945e+00,  -5.28023249e-01,  -3.23684531e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            1.00000000e+00]]),\n",
       "  'lev2': array([[  6.50110229e-01,   3.80470758e-01,   3.25320092e-01,\n",
       "           -1.09062346e+00,  -1.91891602e-01,   8.79012006e-01,\n",
       "           -6.95589647e-01,  -6.46783147e-01,  -7.43639865e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            2.00000000e+00],\n",
       "         [ -4.94235846e-01,   1.67694281e+00,   3.25320092e-01,\n",
       "            2.49624989e-01,  -1.91891602e-01,   1.86749804e-01,\n",
       "           -2.83815754e-01,   1.02284130e+00,   1.98606981e+00,\n",
       "           -6.72518943e-01,  -1.74952591e-01,   6.39091914e-01,\n",
       "            2.00000000e+00],\n",
       "         [  6.50110229e-01,   3.80470758e-01,   3.25320092e-01,\n",
       "            1.58987344e+00,  -1.91891602e-01,  -1.05932216e+00,\n",
       "            5.62192427e-01,  -3.07968143e-01,  -8.48628698e-01,\n",
       "           -2.37130106e-02,  -2.73707366e-01,  -8.94067665e-01,\n",
       "            2.00000000e+00],\n",
       "         [  6.50110229e-01,  -9.16001298e-01,  -8.45054583e-01,\n",
       "            2.49624989e-01,  -1.91891602e-01,   4.63654685e-01,\n",
       "           -2.46381763e-01,   4.36027690e-01,   3.06248470e-01,\n",
       "            1.75825051e+00,  -2.71550756e-01,   1.34057230e-02,\n",
       "            2.00000000e+00],\n",
       "         [  6.50110229e-01,   3.80470758e-01,   3.25320092e-01,\n",
       "            2.49624989e-01,  -1.91891602e-01,  -6.43964840e-01,\n",
       "            4.04969668e-01,   5.75745217e-01,   7.26203804e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            2.00000000e+00],\n",
       "         [  6.50110229e-01,   3.80470758e-01,  -8.45054583e-01,\n",
       "            2.49624989e-01,  -1.91891602e-01,  -5.05512399e-01,\n",
       "           -1.09488554e+00,  -8.54962263e-01,   2.01259636e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            2.00000000e+00],\n",
       "         [ -4.94235846e-01,  -9.16001298e-01,   3.25320092e-01,\n",
       "            1.58987344e+00,  -1.91891602e-01,  -7.82417280e-01,\n",
       "            2.31429669e-02,  -5.28023249e-01,  -7.43639865e-01,\n",
       "            1.45524912e+00,  -2.07301744e-01,  -4.71833330e-02,\n",
       "            2.00000000e+00],\n",
       "         [ -1.63858192e+00,   1.67694281e+00,   3.25320092e-01,\n",
       "            1.58987344e+00,  -1.91891602e-01,   1.43282177e+00,\n",
       "            3.52562082e-01,   2.68366657e-01,   7.26203804e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            2.00000000e+00],\n",
       "         [ -4.94235846e-01,   1.67694281e+00,  -8.45054583e-01,\n",
       "            2.49624989e-01,  -1.91891602e-01,  -1.05932216e+00,\n",
       "           -1.42910234e-02,  -5.78321559e-01,  -1.13706864e-01,\n",
       "            1.28065725e+00,  -1.51769032e-01,   4.65779965e-01,\n",
       "            2.00000000e+00],\n",
       "         [  6.50110229e-01,  -9.16001298e-01,   1.49569477e+00,\n",
       "            2.49624989e-01,  -1.91891602e-01,   4.82973630e-02,\n",
       "           -3.96117725e-01,  -9.29711140e-01,  -4.28673365e-01,\n",
       "           -6.52243758e-01,  -3.80010276e-01,   1.22346374e+00,\n",
       "            2.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   3.25320092e-01,\n",
       "            1.58987344e+00,  -1.91891602e-01,   1.15591689e+00,\n",
       "           -5.45853686e-01,  -9.78612275e-01,  -1.00611195e+00,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            2.00000000e+00],\n",
       "         [  6.50110229e-01,   3.80470758e-01,  -8.45054583e-01,\n",
       "            2.49624989e-01,  -1.91891602e-01,   1.29436933e+00,\n",
       "            1.27958140e-01,  -2.26233390e-01,  -2.18695698e-01,\n",
       "            1.70530974e+00,  -2.46749739e-01,   5.81187690e-01,\n",
       "            2.00000000e+00],\n",
       "         [  6.50110229e-01,   3.80470758e-01,  -8.45054583e-01,\n",
       "           -1.09062346e+00,  -1.91891602e-01,  -1.05932216e+00,\n",
       "           -5.45853686e-01,  -9.51367357e-01,  -5.33662198e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            2.00000000e+00],\n",
       "         [ -1.63858192e+00,  -9.16001298e-01,   2.66606944e+00,\n",
       "            2.49624989e-01,  -1.91891602e-01,  -2.28607518e-01,\n",
       "           -2.46381763e-01,   1.88419986e+00,   1.35613680e+00,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            2.00000000e+00],\n",
       "         [ -4.94235846e-01,   3.80470758e-01,   3.25320092e-01,\n",
       "           -1.09062346e+00,  -1.91891602e-01,  -9.01550776e-02,\n",
       "           -1.11619398e-01,  -7.85103499e-01,  -8.48628698e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            2.00000000e+00],\n",
       "         [  6.50110229e-01,   3.80470758e-01,   1.49569477e+00,\n",
       "            2.49624989e-01,  -1.91891602e-01,  -1.33622704e+00,\n",
       "           -8.82759598e-01,  -5.78321559e-01,  -5.33662198e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            2.00000000e+00],\n",
       "         [ -4.94235846e-01,   3.80470758e-01,   3.25320092e-01,\n",
       "            2.49624989e-01,  -1.91891602e-01,   1.86749804e-01,\n",
       "            2.02826120e-01,   8.13265014e-01,   8.31192637e-01,\n",
       "           -4.19079126e-01,  -2.50973100e-01,   2.35245585e+00,\n",
       "            2.00000000e+00],\n",
       "         [ -1.63858192e+00,   1.67694281e+00,   3.25320092e-01,\n",
       "            2.49624989e-01,  -1.91891602e-01,  -1.33622704e+00,\n",
       "            2.14939362e+00,   4.04073990e+00,   2.82598047e+00,\n",
       "            1.54423466e+00,  -2.65440360e-01,   3.93449775e-01,\n",
       "            2.00000000e+00],\n",
       "         [  6.50110229e-01,   3.80470758e-01,  -8.45054583e-01,\n",
       "            2.49624989e-01,  -1.91891602e-01,   1.15591689e+00,\n",
       "            8.01769965e-01,   6.87519239e-01,   6.21214970e-01,\n",
       "            9.93425456e-01,  -2.00113043e-01,  -2.32556992e-01,\n",
       "            2.00000000e+00],\n",
       "         [  6.50110229e-01,  -9.16001298e-01,  -8.45054583e-01,\n",
       "            2.49624989e-01,  -1.91891602e-01,   7.40559566e-01,\n",
       "           -7.70457628e-01,  -6.53769024e-01,  -6.38651031e-01,\n",
       "            8.89796731e-01,  -1.05581630e-01,  -1.06601716e+00,\n",
       "            2.00000000e+00]]),\n",
       "  'lev3': array([[  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,   4.63654685e-01,\n",
       "            9.05241494e-02,   1.42620882e-01,  -3.23684531e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,   5.21705294e+00,   8.79012006e-01,\n",
       "            6.52034004e-01,   4.36027690e-01,   5.68720553e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,   5.21705294e+00,   7.40559566e-01,\n",
       "            1.55044977e+00,   1.44199389e+00,   9.36181471e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   3.25320092e-01,\n",
       "            1.58987344e+00,   5.21705294e+00,  -1.05932216e+00,\n",
       "            1.10124189e+00,   1.88629562e+00,   6.21214970e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [ -1.63858192e+00,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,   5.21705294e+00,   1.57127421e+00,\n",
       "            1.13867588e+00,   5.91114145e-01,   4.11237303e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,  -9.16001298e-01,   1.49569477e+00,\n",
       "            1.58987344e+00,   5.21705294e+00,   1.43282177e+00,\n",
       "           -1.44426945e+00,   2.74136689e+00,   2.51101397e+00,\n",
       "            1.52846507e+00,  -2.03347959e-01,   6.11716983e-02,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,  -9.16001298e-01,   2.66606944e+00,\n",
       "            2.93012189e+00,  -1.91891602e-01,  -1.61313192e+00,\n",
       "           -9.66458021e-02,   1.69348544e+00,   1.19865355e+00,\n",
       "           -5.54247028e-01,  -7.93428730e-02,   1.22999550e+00,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,  -9.16001298e-01,   2.66606944e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,  -1.47467948e+00,\n",
       "            5.02298043e-01,   1.81923121e+00,   1.77609214e+00,\n",
       "            1.65800098e+00,  -2.59958976e-01,   1.38591614e+00,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,  -9.16001298e-01,   3.25320092e-01,\n",
       "            2.49624989e-01,   5.21705294e+00,   4.63654685e-01,\n",
       "            1.84992169e+00,   1.10667182e+00,   1.14615914e+00,\n",
       "            1.78190489e+00,  -1.47815246e-01,   1.88080125e-01,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,   1.67694281e+00,   2.66606944e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,   1.15591689e+00,\n",
       "            6.52034004e-01,   1.42620882e-01,   3.06248470e-01,\n",
       "           -5.27213448e-01,  -2.76133552e-01,   1.03913196e+00,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   2.97341487e+00,   3.25320092e-01,\n",
       "            1.58987344e+00,  -1.91891602e-01,   1.86749804e-01,\n",
       "           -6.66986099e-02,  -6.07662240e-01,  -3.86677831e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   3.80470758e-01,   1.49569477e+00,\n",
       "            1.58987344e+00,   5.21705294e+00,   1.43282177e+00,\n",
       "            1.84992169e+00,   7.71349755e-01,   7.26203804e-01,\n",
       "           -2.20832869e-01,  -2.55196462e-01,   1.71522888e+00,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,   7.40559566e-01,\n",
       "            1.52050258e+00,   2.37251262e+00,   1.56611447e+00,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,   5.21705294e+00,   6.02107125e-01,\n",
       "            3.37588485e-01,   1.10667182e+00,   6.21214970e-01,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,   1.67694281e+00,   3.25320092e-01,\n",
       "            1.58987344e+00,  -1.91891602e-01,   1.86749804e-01,\n",
       "            3.52562082e-01,   1.16255883e+00,   9.36181471e-01,\n",
       "            1.58027943e+00,  -1.86274795e-01,   9.96008681e-02,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,  -9.01550776e-02,\n",
       "            1.25097785e+00,   1.65157018e+00,   1.77609214e+00,\n",
       "            1.09592778e+00,  -2.32462196e-01,  -1.33378478e-01,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            1.58987344e+00,  -1.91891602e-01,  -5.05512399e-01,\n",
       "            1.55044977e+00,   1.61175068e+00,   5.16226137e-01,\n",
       "            5.96405293e-02,   1.16906268e+01,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,   1.67694281e+00,   2.66606944e+00,\n",
       "            2.93012189e+00,  -1.91891602e-01,   8.79012006e-01,\n",
       "            1.55044977e+00,   1.03122436e+00,   1.61860889e+00,\n",
       "           -3.12071203e-01,  -2.44323552e-01,   1.48886144e+00,\n",
       "            3.00000000e+00],\n",
       "         [  6.50110229e-01,   1.67694281e+00,   1.49569477e+00,\n",
       "            2.93012189e+00,  -1.91891602e-01,   6.02107125e-01,\n",
       "            1.55044977e+00,   2.02880750e+00,   1.46112564e+00,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00],\n",
       "         [  1.79445630e+00,   3.80470758e-01,   2.66606944e+00,\n",
       "            2.49624989e-01,   5.21705294e+00,   1.57127421e+00,\n",
       "            1.84992169e+00,   3.16051947e+00,   2.61600281e+00,\n",
       "           -8.82029192e-01,   1.83564402e-15,  -9.68080597e-15,\n",
       "            3.00000000e+00]])},\n",
       " 'random': <module 'numpy.random' from '/anaconda2/lib/python2.7/site-packages/numpy/random/__init__.pyc'>,\n",
       " 'random_selct': <function __main__.random_selct>,\n",
       " 'rank': <function numpy.core.fromnumeric.rank>,\n",
       " 'rate': <function numpy.lib.financial.rate>,\n",
       " 'ravel': <function numpy.core.fromnumeric.ravel>,\n",
       " 'ravel_multi_index': <function numpy.core.multiarray.ravel_multi_index>,\n",
       " 'real': <function numpy.lib.type_check.real>,\n",
       " 'real_if_close': <function numpy.lib.type_check.real_if_close>,\n",
       " 'rec': <module 'numpy.core.records' from '/anaconda2/lib/python2.7/site-packages/numpy/core/records.pyc'>,\n",
       " 'recarray': numpy.recarray,\n",
       " 'recfromcsv': <function numpy.lib.npyio.recfromcsv>,\n",
       " 'recfromtxt': <function numpy.lib.npyio.recfromtxt>,\n",
       " 'reciprocal': <ufunc 'reciprocal'>,\n",
       " 'record': numpy.record,\n",
       " 'remainder': <ufunc 'remainder'>,\n",
       " 'repeat': <function numpy.core.fromnumeric.repeat>,\n",
       " 'require': <function numpy.core.numeric.require>,\n",
       " 'reshape': <function numpy.core.fromnumeric.reshape>,\n",
       " 'resize': <function numpy.core.fromnumeric.resize>,\n",
       " 'result_type': <function numpy.core.multiarray.result_type>,\n",
       " 'right_shift': <ufunc 'right_shift'>,\n",
       " 'rint': <ufunc 'rint'>,\n",
       " 'roll': <function numpy.core.numeric.roll>,\n",
       " 'rollaxis': <function numpy.core.numeric.rollaxis>,\n",
       " 'roots': <function numpy.lib.polynomial.roots>,\n",
       " 'rot90': <function numpy.lib.function_base.rot90>,\n",
       " 'round_': <function numpy.core.fromnumeric.round_>,\n",
       " 'row_stack': <function numpy.core.shape_base.vstack>,\n",
       " 's_': <numpy.lib.index_tricks.IndexExpression at 0x1086eb310>,\n",
       " 'safe_eval': <function numpy.lib.utils.safe_eval>,\n",
       " 'save': <function numpy.lib.npyio.save>,\n",
       " 'savetxt': <function numpy.lib.npyio.savetxt>,\n",
       " 'savez': <function numpy.lib.npyio.savez>,\n",
       " 'savez_compressed': <function numpy.lib.npyio.savez_compressed>,\n",
       " 'scale': <function sklearn.preprocessing.data.scale>,\n",
       " 'sctype2char': <function numpy.core.numerictypes.sctype2char>,\n",
       " 'sctypeDict': {0: numpy.bool_,\n",
       "  1: numpy.int8,\n",
       "  2: numpy.uint8,\n",
       "  3: numpy.int16,\n",
       "  4: numpy.uint16,\n",
       "  5: numpy.int32,\n",
       "  6: numpy.uint32,\n",
       "  7: numpy.int64,\n",
       "  8: numpy.uint64,\n",
       "  9: numpy.int64,\n",
       "  10: numpy.uint64,\n",
       "  11: numpy.float32,\n",
       "  12: numpy.float64,\n",
       "  13: numpy.float128,\n",
       "  14: numpy.complex64,\n",
       "  15: numpy.complex128,\n",
       "  16: numpy.complex256,\n",
       "  17: numpy.object_,\n",
       "  18: numpy.string_,\n",
       "  19: numpy.unicode_,\n",
       "  20: numpy.void,\n",
       "  21: numpy.datetime64,\n",
       "  22: numpy.timedelta64,\n",
       "  23: numpy.float16,\n",
       "  '?': numpy.bool_,\n",
       "  'B': numpy.uint8,\n",
       "  'Bool': numpy.bool_,\n",
       "  'Complex128': numpy.complex256,\n",
       "  'Complex32': numpy.complex64,\n",
       "  'Complex64': numpy.complex128,\n",
       "  'D': numpy.complex128,\n",
       "  'Datetime64': numpy.datetime64,\n",
       "  'F': numpy.complex64,\n",
       "  'Float128': numpy.float128,\n",
       "  'Float16': numpy.float16,\n",
       "  'Float32': numpy.float32,\n",
       "  'Float64': numpy.float64,\n",
       "  'G': numpy.complex256,\n",
       "  'H': numpy.uint16,\n",
       "  'I': numpy.uint32,\n",
       "  'Int16': numpy.int16,\n",
       "  'Int32': numpy.int32,\n",
       "  'Int64': numpy.int64,\n",
       "  'Int8': numpy.int8,\n",
       "  'L': numpy.uint64,\n",
       "  'M': numpy.datetime64,\n",
       "  'M8': numpy.datetime64,\n",
       "  'O': numpy.object_,\n",
       "  'Object0': numpy.object_,\n",
       "  'P': numpy.uint64,\n",
       "  'Q': numpy.uint64,\n",
       "  'S': numpy.string_,\n",
       "  'String0': numpy.string_,\n",
       "  'Timedelta64': numpy.timedelta64,\n",
       "  'U': numpy.unicode_,\n",
       "  'UInt16': numpy.uint16,\n",
       "  'UInt32': numpy.uint32,\n",
       "  'UInt64': numpy.uint64,\n",
       "  'UInt8': numpy.uint8,\n",
       "  'Unicode0': numpy.unicode_,\n",
       "  'V': numpy.void,\n",
       "  'Void0': numpy.void,\n",
       "  'a': numpy.string_,\n",
       "  'b': numpy.int8,\n",
       "  'b1': numpy.bool_,\n",
       "  'bool': numpy.bool_,\n",
       "  'bool8': numpy.bool_,\n",
       "  'bool_': numpy.bool_,\n",
       "  'byte': numpy.int8,\n",
       "  'bytes_': numpy.string_,\n",
       "  'c16': numpy.complex128,\n",
       "  'c32': numpy.complex256,\n",
       "  'c8': numpy.complex64,\n",
       "  'cdouble': numpy.complex128,\n",
       "  'cfloat': numpy.complex128,\n",
       "  'clongdouble': numpy.complex256,\n",
       "  'clongfloat': numpy.complex256,\n",
       "  'complex': numpy.complex128,\n",
       "  'complex128': numpy.complex128,\n",
       "  'complex256': numpy.complex256,\n",
       "  'complex64': numpy.complex64,\n",
       "  'complex_': numpy.complex128,\n",
       "  'csingle': numpy.complex64,\n",
       "  'd': numpy.float64,\n",
       "  'datetime64': numpy.datetime64,\n",
       "  'double': numpy.float64,\n",
       "  'e': numpy.float16,\n",
       "  'f': numpy.float32,\n",
       "  'f16': numpy.float128,\n",
       "  'f2': numpy.float16,\n",
       "  'f4': numpy.float32,\n",
       "  'f8': numpy.float64,\n",
       "  'float': numpy.float64,\n",
       "  'float128': numpy.float128,\n",
       "  'float16': numpy.float16,\n",
       "  'float32': numpy.float32,\n",
       "  'float64': numpy.float64,\n",
       "  'float_': numpy.float64,\n",
       "  'g': numpy.float128,\n",
       "  'h': numpy.int16,\n",
       "  'half': numpy.float16,\n",
       "  'i': numpy.int32,\n",
       "  'i1': numpy.int8,\n",
       "  'i2': numpy.int16,\n",
       "  'i4': numpy.int32,\n",
       "  'i8': numpy.int64,\n",
       "  'int': numpy.int64,\n",
       "  'int0': numpy.int64,\n",
       "  'int16': numpy.int16,\n",
       "  'int32': numpy.int32,\n",
       "  'int64': numpy.int64,\n",
       "  'int8': numpy.int8,\n",
       "  'int_': numpy.int64,\n",
       "  'intc': numpy.int32,\n",
       "  'intp': numpy.int64,\n",
       "  'l': numpy.int64,\n",
       "  'longcomplex': numpy.complex256,\n",
       "  'longdouble': numpy.float128,\n",
       "  'longfloat': numpy.float128,\n",
       "  'longlong': numpy.int64,\n",
       "  'm': numpy.timedelta64,\n",
       "  'm8': numpy.timedelta64,\n",
       "  'object': numpy.object_,\n",
       "  'object0': numpy.object_,\n",
       "  'object_': numpy.object_,\n",
       "  'p': numpy.int64,\n",
       "  'q': numpy.int64,\n",
       "  'short': numpy.int16,\n",
       "  'single': numpy.float32,\n",
       "  'singlecomplex': numpy.complex64,\n",
       "  'str': numpy.string_,\n",
       "  'str_': numpy.string_,\n",
       "  'string': numpy.string_,\n",
       "  'string0': numpy.string_,\n",
       "  'string_': numpy.string_,\n",
       "  'timedelta64': numpy.timedelta64,\n",
       "  'u1': numpy.uint8,\n",
       "  'u2': numpy.uint16,\n",
       "  'u4': numpy.uint32,\n",
       "  'u8': numpy.uint64,\n",
       "  'ubyte': numpy.uint8,\n",
       "  'uint': numpy.uint64,\n",
       "  'uint0': numpy.uint64,\n",
       "  'uint16': numpy.uint16,\n",
       "  'uint32': numpy.uint32,\n",
       "  'uint64': numpy.uint64,\n",
       "  'uint8': numpy.uint8,\n",
       "  'uintc': numpy.uint32,\n",
       "  'uintp': numpy.uint64,\n",
       "  'ulonglong': numpy.uint64,\n",
       "  'unicode': numpy.unicode_,\n",
       "  'unicode0': numpy.unicode_,\n",
       "  'unicode_': numpy.unicode_,\n",
       "  'ushort': numpy.uint16,\n",
       "  'void': numpy.void,\n",
       "  'void0': numpy.void},\n",
       " 'sctypeNA': {'?': 'Bool',\n",
       "  'B': 'UInt8',\n",
       "  'Bool': numpy.bool_,\n",
       "  'Complex128': numpy.complex256,\n",
       "  'Complex32': numpy.complex64,\n",
       "  'Complex64': numpy.complex128,\n",
       "  'D': 'Complex64',\n",
       "  'Datetime64': numpy.datetime64,\n",
       "  'F': 'Complex32',\n",
       "  'Float128': numpy.float128,\n",
       "  'Float16': numpy.float16,\n",
       "  'Float32': numpy.float32,\n",
       "  'Float64': numpy.float64,\n",
       "  'G': 'Complex128',\n",
       "  'H': 'UInt16',\n",
       "  'I': 'UInt32',\n",
       "  'Int16': numpy.int16,\n",
       "  'Int32': numpy.int32,\n",
       "  'Int64': numpy.int64,\n",
       "  'Int8': numpy.int8,\n",
       "  'L': 'UInt64',\n",
       "  'M': 'Datetime64',\n",
       "  'M8': 'Datetime64',\n",
       "  'O': 'Object0',\n",
       "  'Object0': numpy.object_,\n",
       "  'Q': 'UInt64',\n",
       "  'S': 'String0',\n",
       "  'String0': numpy.string_,\n",
       "  'Timedelta64': numpy.timedelta64,\n",
       "  'U': 'Unicode0',\n",
       "  'UInt16': numpy.uint16,\n",
       "  'UInt32': numpy.uint32,\n",
       "  'UInt64': numpy.uint64,\n",
       "  'UInt8': numpy.uint8,\n",
       "  'Unicode0': numpy.unicode_,\n",
       "  'V': 'Void0',\n",
       "  'Void0': numpy.void,\n",
       "  'b': 'Int8',\n",
       "  'b1': 'Bool',\n",
       "  'c16': 'Complex64',\n",
       "  'c32': 'Complex128',\n",
       "  'c8': 'Complex32',\n",
       "  'd': 'Float64',\n",
       "  'e': 'Float16',\n",
       "  'f': 'Float32',\n",
       "  'f16': 'Float128',\n",
       "  'f2': 'Float16',\n",
       "  'f4': 'Float32',\n",
       "  'f8': 'Float64',\n",
       "  'g': 'Float128',\n",
       "  'h': 'Int16',\n",
       "  'i': 'Int32',\n",
       "  'i1': numpy.int8,\n",
       "  'i2': numpy.int16,\n",
       "  'i4': numpy.int32,\n",
       "  'i8': numpy.int64,\n",
       "  'l': 'Int64',\n",
       "  'm': 'Timedelta64',\n",
       "  'm8': 'Timedelta64',\n",
       "  'q': 'Int64',\n",
       "  'u1': numpy.uint8,\n",
       "  'u2': numpy.uint16,\n",
       "  'u4': numpy.uint32,\n",
       "  'u8': numpy.uint64,\n",
       "  numpy.bool_: 'Bool',\n",
       "  numpy.object_: 'Object0',\n",
       "  numpy.string_: 'String0',\n",
       "  numpy.unicode_: 'Unicode0',\n",
       "  numpy.void: 'Void0',\n",
       "  numpy.int8: 'Int8',\n",
       "  numpy.int16: 'Int16',\n",
       "  numpy.int32: 'Int32',\n",
       "  numpy.int64: 'Int64',\n",
       "  numpy.int64: 'Int64',\n",
       "  numpy.uint8: 'UInt8',\n",
       "  numpy.uint16: 'UInt16',\n",
       "  numpy.uint32: 'UInt32',\n",
       "  numpy.uint64: 'UInt64',\n",
       "  numpy.uint64: 'UInt64',\n",
       "  numpy.float16: 'Float16',\n",
       "  numpy.float32: 'Float32',\n",
       "  numpy.float64: 'Float64',\n",
       "  numpy.float128: 'Float128',\n",
       "  numpy.datetime64: 'Datetime64',\n",
       "  numpy.timedelta64: 'Timedelta64',\n",
       "  numpy.complex64: 'Complex32',\n",
       "  numpy.complex128: 'Complex64',\n",
       "  numpy.complex256: 'Complex128'},\n",
       " 'sctypes': {'complex': [numpy.complex64, numpy.complex128, numpy.complex256],\n",
       "  'float': [numpy.float16, numpy.float32, numpy.float64, numpy.float128],\n",
       "  'int': [numpy.int8, numpy.int16, numpy.int32, numpy.int64],\n",
       "  'others': [bool, object, str, unicode, numpy.void],\n",
       "  'uint': [numpy.uint8, numpy.uint16, numpy.uint32, numpy.uint64]},\n",
       " 'searchsorted': <function numpy.core.fromnumeric.searchsorted>,\n",
       " 'select': <function numpy.lib.function_base.select>,\n",
       " 'set_numeric_ops': <function numpy.core.multiarray.set_numeric_ops>,\n",
       " 'set_printoptions': <function numpy.core.arrayprint.set_printoptions>,\n",
       " 'set_string_function': <function numpy.core.numeric.set_string_function>,\n",
       " 'setbufsize': <function numpy.core.numeric.setbufsize>,\n",
       " 'setdiff1d': <function numpy.lib.arraysetops.setdiff1d>,\n",
       " 'seterr': <function numpy.core.numeric.seterr>,\n",
       " 'seterrcall': <function numpy.core.numeric.seterrcall>,\n",
       " 'seterrobj': <function numpy.core.umath.seterrobj>,\n",
       " 'setxor1d': <function numpy.lib.arraysetops.setxor1d>,\n",
       " 'shape': <function numpy.core.fromnumeric.shape>,\n",
       " 'shares_memory': <function numpy.core.multiarray.shares_memory>,\n",
       " 'short': numpy.int16,\n",
       " 'show_config': <function numpy.__config__.show>,\n",
       " 'sign': <ufunc 'sign'>,\n",
       " 'signbit': <ufunc 'signbit'>,\n",
       " 'signedinteger': numpy.signedinteger,\n",
       " 'sin': <ufunc 'sin'>,\n",
       " 'sinc': <function numpy.lib.function_base.sinc>,\n",
       " 'single': numpy.float32,\n",
       " 'singlecomplex': numpy.complex64,\n",
       " 'sinh': <ufunc 'sinh'>,\n",
       " 'size': <function numpy.core.fromnumeric.size>,\n",
       " 'sm': <module 'sklearn.metrics' from '/anaconda2/lib/python2.7/site-packages/sklearn/metrics/__init__.pyc'>,\n",
       " 'sns': <module 'seaborn' from '/anaconda2/lib/python2.7/site-packages/seaborn/__init__.pyc'>,\n",
       " 'sometrue': <function numpy.core.fromnumeric.sometrue>,\n",
       " 'sort': <function numpy.core.fromnumeric.sort>,\n",
       " 'sort_complex': <function numpy.lib.function_base.sort_complex>,\n",
       " 'source': <function numpy.lib.utils.source>,\n",
       " 'spacing': <ufunc 'spacing'>,\n",
       " 'split': <function numpy.lib.shape_base.split>,\n",
       " 'sqrt': <ufunc 'sqrt'>,\n",
       " 'square': <ufunc 'square'>,\n",
       " 'squeeze': <function numpy.core.fromnumeric.squeeze>,\n",
       " 'stack': <function numpy.core.shape_base.stack>,\n",
       " 'std': <function numpy.core.fromnumeric.std>,\n",
       " 'str_': numpy.string_,\n",
       " 'string0': numpy.string_,\n",
       " 'string_': numpy.string_,\n",
       " 'subtract': <ufunc 'subtract'>,\n",
       " 'sum': <function numpy.core.fromnumeric.sum>,\n",
       " 'swapaxes': <function numpy.core.fromnumeric.swapaxes>,\n",
       " 'take': <function numpy.core.fromnumeric.take>,\n",
       " 'tan': <ufunc 'tan'>,\n",
       " 'tanh': <ufunc 'tanh'>,\n",
       " 'target_dict': {'lev1': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.]),\n",
       "  'lev2': array([ 2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "          2.,  2.,  2.,  2.,  2.,  2.,  2.]),\n",
       "  'lev3': array([ 3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
       "          3.,  3.,  3.,  3.,  3.,  3.,  3.])},\n",
       " 'target_var':        0\n",
       " 0    1.0\n",
       " 1    1.8\n",
       " 2    1.8\n",
       " 3    1.4\n",
       " 4    2.0\n",
       " 5    1.2\n",
       " 6    1.2\n",
       " 7    1.2\n",
       " 8    2.8\n",
       " 9    1.4\n",
       " 10   1.8\n",
       " 11   1.8\n",
       " 12   2.2\n",
       " 13   1.2\n",
       " 14   2.0\n",
       " 15   1.6\n",
       " 16   1.0\n",
       " 17   2.2\n",
       " 18   2.2\n",
       " 19   1.8\n",
       " 20   2.0\n",
       " 21   2.0\n",
       " 22   1.6\n",
       " 23   1.0\n",
       " 24   2.4\n",
       " 25   1.6\n",
       " 26   1.8\n",
       " 27   3.0\n",
       " 28   1.0\n",
       " 29   2.0\n",
       " ..   ...\n",
       " 873  1.4\n",
       " 874  3.2\n",
       " 875  2.2\n",
       " 876  1.8\n",
       " 877  1.4\n",
       " 878  1.6\n",
       " 879  1.6\n",
       " 880  1.6\n",
       " 881  1.6\n",
       " 882  2.8\n",
       " 883  3.4\n",
       " 884  1.0\n",
       " 885  1.8\n",
       " 886  1.0\n",
       " 887  1.4\n",
       " 888  1.6\n",
       " 889  2.4\n",
       " 890  2.0\n",
       " 891  1.4\n",
       " 892  1.6\n",
       " 893  1.8\n",
       " 894  2.2\n",
       " 895  1.4\n",
       " 896  1.6\n",
       " 897  1.6\n",
       " 898  1.2\n",
       " 899  1.6\n",
       " 900  2.2\n",
       " 901  2.2\n",
       " 902  1.6\n",
       " \n",
       " [903 rows x 1 columns],\n",
       " 'tensordot': <function numpy.core.numeric.tensordot>,\n",
       " 'test': array([[-0.49423585,  0.38047076, -0.84505458, ...,  1.11057097,\n",
       "         -0.46124259, -2.69823504],\n",
       "        [ 1.7944563 , -0.9160013 ,  1.49569477, ..., -0.52946625,\n",
       "         -0.12157649,  2.70509056],\n",
       "        [-0.49423585,  1.67694281,  0.32532009, ...,  0.20494602,\n",
       "          0.04124758,  3.64514259],\n",
       "        ..., \n",
       "        [ 1.7944563 ,  1.67694281,  0.32532009, ..., -0.51594946,\n",
       "         -0.20622344,  1.59966087],\n",
       "        [-1.63858192, -0.9160013 , -0.84505458, ...,  0.21057802,\n",
       "         -0.13056236,  0.23985331],\n",
       "        [-0.49423585,  2.97341487, -0.84505458, ..., -0.52833985,\n",
       "         -0.1786368 ,  1.61308503]]),\n",
       " 'test_idx': array([306, 797, 118, 808, 804, 188, 612, 822, 551, 277, 599, 505, 446,\n",
       "        846, 825, 444, 483, 880,   0, 868, 789, 167,   4, 768, 153, 399,\n",
       "        578, 712, 805, 473, 303,  22, 180, 591,  88, 900, 201, 878,  38,\n",
       "        405, 562, 319, 213, 438, 834, 472, 468, 519, 773, 409, 187, 705,\n",
       "        643, 285, 327, 722, 474, 739, 877, 210, 393, 831, 568, 504, 156,\n",
       "        332, 646, 315, 465,  61, 497,  13, 884, 279,  39,  15, 560, 102,\n",
       "        582,  75, 276,  52, 550, 437, 147, 273, 111, 749, 775,  68, 579,\n",
       "        159, 103,   8, 779, 351, 353, 723, 651, 549,  55, 344, 875, 194,\n",
       "        585, 673,  19, 170, 462,  32, 380, 630, 318,  35, 624, 458, 464,\n",
       "        492, 639, 656, 534, 644,  96, 205, 895, 154, 373, 244, 291, 765,\n",
       "        416, 586, 330,  99, 626, 598, 481, 759, 440,  80, 162, 165, 890,\n",
       "        681, 214, 202, 136, 129, 760, 605, 381,  43, 513, 169, 278, 573,\n",
       "        192, 108, 707, 728, 559, 433, 298,  29, 661, 479, 155, 532, 224,\n",
       "        516, 240, 610, 666, 725, 311, 310,  10, 885,  49, 717, 604, 515]),\n",
       " 'tile': <function numpy.lib.shape_base.tile>,\n",
       " 'time': <function time.time>,\n",
       " 'timedelta64': numpy.timedelta64,\n",
       " 'title': 'hormone_scr_ert_mean',\n",
       " 'titles': ['pds_ht2_y',\n",
       "  'pds_skin2_ypds_bdyhair_y',\n",
       "  'pds_f4_2_y',\n",
       "  'pds_f5_y',\n",
       "  'interview_age',\n",
       "  'anthroheightcalc',\n",
       "  'anthroweightcalc',\n",
       "  'anthro_waist_cm',\n",
       "  'hormone_scr_dhea_mean',\n",
       "  'hormone_scr_hse_mean',\n",
       "  'hormone_scr_ert_mean'],\n",
       " 'trace': <function numpy.core.fromnumeric.trace>,\n",
       " 'tracemalloc_domain': 389047,\n",
       " 'training': array([[ -4.94235846e-01,  -9.16001298e-01,   3.25320092e-01, ...,\n",
       "           1.24235968e+00,  -2.96351773e-01,   4.46344983e-01],\n",
       "        [ -4.94235846e-01,  -9.16001298e-01,  -8.45054583e-01, ...,\n",
       "           9.90046259e-01,  -1.97507139e-01,  -2.99357228e-01],\n",
       "        [  6.50110229e-01,   3.80470758e-01,   3.25320092e-01, ...,\n",
       "           4.69649834e-01,  -1.85286348e-01,  -9.00078484e-01],\n",
       "        ..., \n",
       "        [  6.50110229e-01,  -9.16001298e-01,  -8.45054583e-01, ...,\n",
       "          -6.03808592e-01,  -8.11400482e-02,   7.99180061e-01],\n",
       "        [ -4.94235846e-01,  -9.16001298e-01,  -8.45054583e-01, ...,\n",
       "           1.31557562e+00,   4.96254216e+00,  -9.68080597e-15],\n",
       "        [  6.50110229e-01,  -9.16001298e-01,  -8.45054583e-01, ...,\n",
       "           1.59604902e+00,  -2.43784400e-01,   1.31218343e+00]]),\n",
       " 'training_idx': array([486, 617, 756, 215, 447, 138, 600, 506, 236, 158,  37, 776,  53,\n",
       "         57, 752, 288, 696,  47, 854, 830, 171, 175, 682, 143, 901, 862,\n",
       "        263, 342, 388, 527, 289, 239, 230, 680, 246, 385, 753,  84, 818,\n",
       "        663, 662, 652, 863, 548,  11, 829, 716, 461, 659,   9, 590, 401,\n",
       "        275, 282, 631, 233, 219, 450, 512, 691, 593,  21, 686, 688, 206,\n",
       "         69, 873, 212, 431,  92, 726, 494, 763, 625, 833, 203, 326, 245,\n",
       "        782, 810, 404, 480, 113, 299, 819, 642, 398, 572, 386, 837, 150,\n",
       "        888, 507, 859, 115, 304,  66, 234, 374, 614, 734, 106, 660,  72,\n",
       "        257, 595, 445, 161, 432, 518, 757, 664, 453, 807, 581, 302, 891,\n",
       "        130, 564, 766, 178, 730, 788, 628, 887, 533, 376, 232, 514, 208,\n",
       "        425, 693,  45, 469, 357,  58, 221, 368,  89, 365, 414,   1, 335,\n",
       "        470, 856, 719, 452, 574, 146, 500, 606, 790,  12, 270, 268, 584,\n",
       "        570, 774, 333, 300,  50, 632, 576, 397, 139, 121, 145, 811, 687,\n",
       "        375, 185, 336,  76, 751, 114,  70, 207, 857, 594, 841,  63, 211,\n",
       "        323, 650, 528, 529, 634, 783, 390, 713, 747, 899, 418, 729, 583,\n",
       "        434, 611, 243, 443, 354, 193, 855, 173, 565, 772, 467, 157, 451,\n",
       "        894, 654, 640, 638, 893, 272, 177, 867, 141, 109, 427,  83, 366,\n",
       "        793, 785, 850, 721,  40,  20, 649, 798, 119, 151, 412, 839, 261,\n",
       "         24, 228, 502, 623, 223, 128, 852, 471, 346, 526, 308, 267, 225,\n",
       "        801, 561, 341, 814, 258, 363, 771, 509, 152, 609, 520, 727, 735,\n",
       "        629, 415, 671, 307, 406, 543, 821, 616, 685, 264, 530, 164, 708,\n",
       "        575, 120, 836, 669, 392, 615, 350,  74, 325,  95, 281, 107, 608,\n",
       "        758, 876, 795, 334,  97, 322, 709, 832, 870,  71, 588, 812, 419,\n",
       "        116, 523, 249, 400,  28, 537, 695, 552, 372, 364, 359, 137, 340,\n",
       "        567, 331, 689,  59, 844, 254, 383, 305, 665, 484, 684, 290, 799,\n",
       "        176, 667, 478,  73, 287, 379, 294, 253, 847,  90, 692, 621, 613,\n",
       "        112, 517, 456, 542, 395, 460, 813,  91, 250, 618, 770, 736, 489,\n",
       "        535, 866, 349, 499, 601, 488, 848, 218, 476, 745, 540, 321, 655,\n",
       "        622, 522, 426, 352, 892, 370, 312,  94, 874, 485,  48, 743, 174,\n",
       "        457, 429, 668, 748,  41, 328, 338, 439, 371, 204, 838, 902, 229,\n",
       "        125, 168, 653, 195, 858, 242, 510, 711, 845,  54, 295, 566, 865,\n",
       "        172, 490, 800, 183, 637, 525, 345, 391, 619,  23, 378, 101, 105,\n",
       "        424,   2, 408,  85,  81, 329, 313, 851, 435, 780, 186, 284, 792,\n",
       "        367, 292, 823, 362, 592, 754, 815, 816, 827, 227, 896, 596, 436,\n",
       "        627, 449, 199, 466, 142, 163, 237, 126, 531, 132, 184, 402, 842,\n",
       "        820, 767, 889,  27, 731, 641, 861, 724, 694, 898, 360, 238, 496,\n",
       "        794, 441, 715, 355, 387,  16, 817, 241, 131, 597, 602, 704, 247,\n",
       "        317, 117, 556, 589, 710, 197,  18, 190, 110, 840, 134, 580, 459,\n",
       "        407, 698, 430, 706, 377, 675, 796, 179, 678,  44, 343, 803, 784,\n",
       "        648, 501, 271, 672, 791, 569, 320, 217, 421, 697, 196, 645, 554,\n",
       "        741, 737,  87, 293, 853, 864, 256, 511, 701, 309, 881,  46, 786,\n",
       "        269, 423,  51, 750, 607, 882, 463, 872, 482,  17, 647, 442,  42,\n",
       "         65, 265, 259, 487, 620, 231, 658, 235, 762, 657, 148,  36, 563,\n",
       "        454, 216, 301, 337, 547, 635, 778,  78, 503, 826,  31,  64, 475,\n",
       "        761, 733, 676, 348,  79, 149, 677, 356, 100, 403, 714, 886, 541,\n",
       "        683, 127, 871, 546, 690, 347, 189, 702, 422, 809, 806, 508, 410,\n",
       "        802, 491, 740, 545,  26, 314,  14, 732,  93, 361, 869, 394, 700,\n",
       "        324, 764, 389, 413, 558, 781, 220, 428, 420,   3, 879, 166, 557,\n",
       "        123, 396, 571, 703, 670, 455, 182, 539, 251, 536, 382, 555, 538,\n",
       "         56,  60, 411,  82, 843, 493, 191, 860, 448, 200, 226, 835, 755,\n",
       "        787,  98, 255,   5, 495, 286, 283, 262, 897, 824, 828, 274, 699,\n",
       "        498, 742, 636, 720, 521, 135, 339, 674, 260,  33, 417, 849, 679,\n",
       "        384, 718, 144, 248,  77, 369, 883,  86, 198, 358, 777, 738, 544,\n",
       "        633, 280, 587,  30, 577,  62, 122, 297, 524,   7, 746, 160, 222,\n",
       "        266, 477, 744, 553, 316, 296, 133, 104, 140,   6, 124,  34, 603,\n",
       "         67, 252, 769, 209, 181,  25]),\n",
       " 'trans': array([[-1.63858192, -0.9160013 , -0.84505458, ..., -0.27343779,\n",
       "         -1.36651804,  1.        ],\n",
       "        [ 0.65011023,  1.67694281, -0.84505458, ..., -0.22760982,\n",
       "          0.45792583,  2.        ],\n",
       "        [ 0.65011023, -0.9160013 ,  0.32532009, ..., -0.25995898,\n",
       "          0.20022198,  2.        ],\n",
       "        ..., \n",
       "        [ 0.65011023,  0.38047076,  1.49569477, ..., -0.32061364,\n",
       "         -0.56764012,  2.        ],\n",
       "        [ 1.7944563 ,  0.38047076,  0.32532009, ..., -0.36140951,\n",
       "         -1.74047113,  2.        ],\n",
       "        [-0.49423585,  0.38047076,  0.32532009, ..., -0.22599237,\n",
       "          1.40414896,  2.        ]]),\n",
       " 'transformed_values': array([[  1.00000000e+00,   1.00000000e+00,   1.00000000e+00, ...,\n",
       "           1.08900000e+03,   1.04500000e+00,   1.66165000e+01],\n",
       "        [  3.00000000e+00,   3.00000000e+00,   1.00000000e+00, ...,\n",
       "           6.67000000e+02,   1.30000000e+00,   3.93810000e+01],\n",
       "        [  3.00000000e+00,   1.00000000e+00,   2.00000000e+00, ...,\n",
       "           1.52800000e+03,   1.12000000e+00,   3.61655000e+01],\n",
       "        ..., \n",
       "        [  3.00000000e+00,   2.00000000e+00,   3.00000000e+00, ...,\n",
       "           1.78600000e+03,   7.82500000e-01,   2.65845000e+01],\n",
       "        [  4.00000000e+00,   2.00000000e+00,   2.00000000e+00, ...,\n",
       "           2.79000000e+02,   5.55500000e-01,   1.19505000e+01],\n",
       "        [  2.00000000e+00,   2.00000000e+00,   2.00000000e+00, ...,\n",
       "           3.11000000e+02,   1.30900000e+00,   5.11875000e+01]]),\n",
       " 'transformed_values_scale': array([[-1.63858192, -0.9160013 , -0.84505458, ...,  0.34349312,\n",
       "         -0.27343779, -1.36651804],\n",
       "        [ 0.65011023,  1.67694281, -0.84505458, ..., -0.13184733,\n",
       "         -0.22760982,  0.45792583],\n",
       "        [ 0.65011023, -0.9160013 ,  0.32532009, ...,  0.83798237,\n",
       "         -0.25995898,  0.20022198],\n",
       "        ..., \n",
       "        [ 0.65011023,  0.38047076,  1.49569477, ...,  1.12859336,\n",
       "         -0.32061364, -0.56764012],\n",
       "        [ 1.7944563 ,  0.38047076,  0.32532009, ..., -0.56889022,\n",
       "         -0.36140951, -1.74047113],\n",
       "        [-0.49423585,  0.38047076,  0.32532009, ..., -0.53284544,\n",
       "         -0.22599237,  1.40414896]]),\n",
       " 'transpose': <function numpy.core.fromnumeric.transpose>,\n",
       " 'trapz': <function numpy.lib.function_base.trapz>,\n",
       " 'tri': <function numpy.lib.twodim_base.tri>,\n",
       " 'tril': <function numpy.lib.twodim_base.tril>,\n",
       " 'tril_indices': <function numpy.lib.twodim_base.tril_indices>,\n",
       " 'tril_indices_from': <function numpy.lib.twodim_base.tril_indices_from>,\n",
       " 'trim_zeros': <function numpy.lib.function_base.trim_zeros>,\n",
       " 'triu': <function numpy.lib.twodim_base.triu>,\n",
       " 'triu_indices': <function numpy.lib.twodim_base.triu_indices>,\n",
       " 'triu_indices_from': <function numpy.lib.twodim_base.triu_indices_from>,\n",
       " 'true_divide': <ufunc 'true_divide'>,\n",
       " 'trunc': <ufunc 'trunc'>,\n",
       " 'typeDict': {0: numpy.bool_,\n",
       "  1: numpy.int8,\n",
       "  2: numpy.uint8,\n",
       "  3: numpy.int16,\n",
       "  4: numpy.uint16,\n",
       "  5: numpy.int32,\n",
       "  6: numpy.uint32,\n",
       "  7: numpy.int64,\n",
       "  8: numpy.uint64,\n",
       "  9: numpy.int64,\n",
       "  10: numpy.uint64,\n",
       "  11: numpy.float32,\n",
       "  12: numpy.float64,\n",
       "  13: numpy.float128,\n",
       "  14: numpy.complex64,\n",
       "  15: numpy.complex128,\n",
       "  16: numpy.complex256,\n",
       "  17: numpy.object_,\n",
       "  18: numpy.string_,\n",
       "  19: numpy.unicode_,\n",
       "  20: numpy.void,\n",
       "  21: numpy.datetime64,\n",
       "  22: numpy.timedelta64,\n",
       "  23: numpy.float16,\n",
       "  '?': numpy.bool_,\n",
       "  'B': numpy.uint8,\n",
       "  'Bool': numpy.bool_,\n",
       "  'Complex128': numpy.complex256,\n",
       "  'Complex32': numpy.complex64,\n",
       "  'Complex64': numpy.complex128,\n",
       "  'D': numpy.complex128,\n",
       "  'Datetime64': numpy.datetime64,\n",
       "  'F': numpy.complex64,\n",
       "  'Float128': numpy.float128,\n",
       "  'Float16': numpy.float16,\n",
       "  'Float32': numpy.float32,\n",
       "  'Float64': numpy.float64,\n",
       "  'G': numpy.complex256,\n",
       "  'H': numpy.uint16,\n",
       "  'I': numpy.uint32,\n",
       "  'Int16': numpy.int16,\n",
       "  'Int32': numpy.int32,\n",
       "  'Int64': numpy.int64,\n",
       "  'Int8': numpy.int8,\n",
       "  'L': numpy.uint64,\n",
       "  'M': numpy.datetime64,\n",
       "  'M8': numpy.datetime64,\n",
       "  'O': numpy.object_,\n",
       "  'Object0': numpy.object_,\n",
       "  'P': numpy.uint64,\n",
       "  'Q': numpy.uint64,\n",
       "  'S': numpy.string_,\n",
       "  'String0': numpy.string_,\n",
       "  'Timedelta64': numpy.timedelta64,\n",
       "  'U': numpy.unicode_,\n",
       "  'UInt16': numpy.uint16,\n",
       "  'UInt32': numpy.uint32,\n",
       "  'UInt64': numpy.uint64,\n",
       "  'UInt8': numpy.uint8,\n",
       "  'Unicode0': numpy.unicode_,\n",
       "  'V': numpy.void,\n",
       "  'Void0': numpy.void,\n",
       "  'a': numpy.string_,\n",
       "  'b': numpy.int8,\n",
       "  'b1': numpy.bool_,\n",
       "  'bool': numpy.bool_,\n",
       "  'bool8': numpy.bool_,\n",
       "  'bool_': numpy.bool_,\n",
       "  'byte': numpy.int8,\n",
       "  'bytes_': numpy.string_,\n",
       "  'c16': numpy.complex128,\n",
       "  'c32': numpy.complex256,\n",
       "  'c8': numpy.complex64,\n",
       "  'cdouble': numpy.complex128,\n",
       "  'cfloat': numpy.complex128,\n",
       "  'clongdouble': numpy.complex256,\n",
       "  'clongfloat': numpy.complex256,\n",
       "  'complex': numpy.complex128,\n",
       "  'complex128': numpy.complex128,\n",
       "  'complex256': numpy.complex256,\n",
       "  'complex64': numpy.complex64,\n",
       "  'complex_': numpy.complex128,\n",
       "  'csingle': numpy.complex64,\n",
       "  'd': numpy.float64,\n",
       "  'datetime64': numpy.datetime64,\n",
       "  'double': numpy.float64,\n",
       "  'e': numpy.float16,\n",
       "  'f': numpy.float32,\n",
       "  'f16': numpy.float128,\n",
       "  'f2': numpy.float16,\n",
       "  'f4': numpy.float32,\n",
       "  'f8': numpy.float64,\n",
       "  'float': numpy.float64,\n",
       "  'float128': numpy.float128,\n",
       "  'float16': numpy.float16,\n",
       "  'float32': numpy.float32,\n",
       "  'float64': numpy.float64,\n",
       "  'float_': numpy.float64,\n",
       "  'g': numpy.float128,\n",
       "  'h': numpy.int16,\n",
       "  'half': numpy.float16,\n",
       "  'i': numpy.int32,\n",
       "  'i1': numpy.int8,\n",
       "  'i2': numpy.int16,\n",
       "  'i4': numpy.int32,\n",
       "  'i8': numpy.int64,\n",
       "  'int': numpy.int64,\n",
       "  'int0': numpy.int64,\n",
       "  'int16': numpy.int16,\n",
       "  'int32': numpy.int32,\n",
       "  'int64': numpy.int64,\n",
       "  'int8': numpy.int8,\n",
       "  'int_': numpy.int64,\n",
       "  'intc': numpy.int32,\n",
       "  'intp': numpy.int64,\n",
       "  'l': numpy.int64,\n",
       "  'longcomplex': numpy.complex256,\n",
       "  'longdouble': numpy.float128,\n",
       "  'longfloat': numpy.float128,\n",
       "  'longlong': numpy.int64,\n",
       "  'm': numpy.timedelta64,\n",
       "  'm8': numpy.timedelta64,\n",
       "  'object': numpy.object_,\n",
       "  'object0': numpy.object_,\n",
       "  'object_': numpy.object_,\n",
       "  'p': numpy.int64,\n",
       "  'q': numpy.int64,\n",
       "  'short': numpy.int16,\n",
       "  'single': numpy.float32,\n",
       "  'singlecomplex': numpy.complex64,\n",
       "  'str': numpy.string_,\n",
       "  'str_': numpy.string_,\n",
       "  'string': numpy.string_,\n",
       "  'string0': numpy.string_,\n",
       "  'string_': numpy.string_,\n",
       "  'timedelta64': numpy.timedelta64,\n",
       "  'u1': numpy.uint8,\n",
       "  'u2': numpy.uint16,\n",
       "  'u4': numpy.uint32,\n",
       "  'u8': numpy.uint64,\n",
       "  'ubyte': numpy.uint8,\n",
       "  'uint': numpy.uint64,\n",
       "  'uint0': numpy.uint64,\n",
       "  'uint16': numpy.uint16,\n",
       "  'uint32': numpy.uint32,\n",
       "  'uint64': numpy.uint64,\n",
       "  'uint8': numpy.uint8,\n",
       "  'uintc': numpy.uint32,\n",
       "  'uintp': numpy.uint64,\n",
       "  'ulonglong': numpy.uint64,\n",
       "  'unicode': numpy.unicode_,\n",
       "  'unicode0': numpy.unicode_,\n",
       "  'unicode_': numpy.unicode_,\n",
       "  'ushort': numpy.uint16,\n",
       "  'void': numpy.void,\n",
       "  'void0': numpy.void},\n",
       " 'typeNA': {'?': 'Bool',\n",
       "  'B': 'UInt8',\n",
       "  'Bool': numpy.bool_,\n",
       "  'Complex128': numpy.complex256,\n",
       "  'Complex32': numpy.complex64,\n",
       "  'Complex64': numpy.complex128,\n",
       "  'D': 'Complex64',\n",
       "  'Datetime64': numpy.datetime64,\n",
       "  'F': 'Complex32',\n",
       "  'Float128': numpy.float128,\n",
       "  'Float16': numpy.float16,\n",
       "  'Float32': numpy.float32,\n",
       "  'Float64': numpy.float64,\n",
       "  'G': 'Complex128',\n",
       "  'H': 'UInt16',\n",
       "  'I': 'UInt32',\n",
       "  'Int16': numpy.int16,\n",
       "  'Int32': numpy.int32,\n",
       "  'Int64': numpy.int64,\n",
       "  'Int8': numpy.int8,\n",
       "  'L': 'UInt64',\n",
       "  'M': 'Datetime64',\n",
       "  'M8': 'Datetime64',\n",
       "  'O': 'Object0',\n",
       "  'Object0': numpy.object_,\n",
       "  'Q': 'UInt64',\n",
       "  'S': 'String0',\n",
       "  'String0': numpy.string_,\n",
       "  'Timedelta64': numpy.timedelta64,\n",
       "  'U': 'Unicode0',\n",
       "  'UInt16': numpy.uint16,\n",
       "  'UInt32': numpy.uint32,\n",
       "  'UInt64': numpy.uint64,\n",
       "  'UInt8': numpy.uint8,\n",
       "  'Unicode0': numpy.unicode_,\n",
       "  'V': 'Void0',\n",
       "  'Void0': numpy.void,\n",
       "  'b': 'Int8',\n",
       "  'b1': 'Bool',\n",
       "  'c16': 'Complex64',\n",
       "  'c32': 'Complex128',\n",
       "  'c8': 'Complex32',\n",
       "  'd': 'Float64',\n",
       "  'e': 'Float16',\n",
       "  'f': 'Float32',\n",
       "  'f16': 'Float128',\n",
       "  'f2': 'Float16',\n",
       "  'f4': 'Float32',\n",
       "  'f8': 'Float64',\n",
       "  'g': 'Float128',\n",
       "  'h': 'Int16',\n",
       "  'i': 'Int32',\n",
       "  'i1': numpy.int8,\n",
       "  'i2': numpy.int16,\n",
       "  'i4': numpy.int32,\n",
       "  'i8': numpy.int64,\n",
       "  'l': 'Int64',\n",
       "  'm': 'Timedelta64',\n",
       "  'm8': 'Timedelta64',\n",
       "  'q': 'Int64',\n",
       "  'u1': numpy.uint8,\n",
       "  'u2': numpy.uint16,\n",
       "  'u4': numpy.uint32,\n",
       "  'u8': numpy.uint64,\n",
       "  numpy.bool_: 'Bool',\n",
       "  numpy.object_: 'Object0',\n",
       "  numpy.string_: 'String0',\n",
       "  numpy.unicode_: 'Unicode0',\n",
       "  numpy.void: 'Void0',\n",
       "  numpy.int8: 'Int8',\n",
       "  numpy.int16: 'Int16',\n",
       "  numpy.int32: 'Int32',\n",
       "  numpy.int64: 'Int64',\n",
       "  numpy.int64: 'Int64',\n",
       "  numpy.uint8: 'UInt8',\n",
       "  numpy.uint16: 'UInt16',\n",
       "  numpy.uint32: 'UInt32',\n",
       "  numpy.uint64: 'UInt64',\n",
       "  numpy.uint64: 'UInt64',\n",
       "  numpy.float16: 'Float16',\n",
       "  numpy.float32: 'Float32',\n",
       "  numpy.float64: 'Float64',\n",
       "  numpy.float128: 'Float128',\n",
       "  numpy.datetime64: 'Datetime64',\n",
       "  numpy.timedelta64: 'Timedelta64',\n",
       "  numpy.complex64: 'Complex32',\n",
       "  numpy.complex128: 'Complex64',\n",
       "  numpy.complex256: 'Complex128'},\n",
       " 'typecodes': {'All': '?bhilqpBHILQPefdgFDGSUVOMm',\n",
       "  'AllFloat': 'efdgFDG',\n",
       "  'AllInteger': 'bBhHiIlLqQpP',\n",
       "  'Character': 'c',\n",
       "  'Complex': 'FDG',\n",
       "  'Datetime': 'Mm',\n",
       "  'Float': 'efdg',\n",
       "  'Integer': 'bhilqp',\n",
       "  'UnsignedInteger': 'BHILQP'},\n",
       " 'typename': <function numpy.lib.type_check.typename>,\n",
       " 'ubyte': numpy.uint8,\n",
       " 'ufunc': numpy.ufunc,\n",
       " 'uint': numpy.uint64,\n",
       " 'uint0': numpy.uint64,\n",
       " 'uint16': numpy.uint16,\n",
       " 'uint32': numpy.uint32,\n",
       " 'uint64': numpy.uint64,\n",
       " 'uint8': numpy.uint8,\n",
       " 'uintc': numpy.uint32,\n",
       " 'uintp': numpy.uint64,\n",
       " 'ulonglong': numpy.uint64,\n",
       " 'unicode0': numpy.unicode_,\n",
       " 'unicode_': numpy.unicode_,\n",
       " 'union1d': <function numpy.lib.arraysetops.union1d>,\n",
       " 'unique': <function numpy.lib.arraysetops.unique>,\n",
       " 'unpackbits': <function numpy.core.multiarray.unpackbits>,\n",
       " 'unravel_index': <function numpy.core.multiarray.unravel_index>,\n",
       " 'unsignedinteger': numpy.unsignedinteger,\n",
       " 'unwrap': <function numpy.lib.function_base.unwrap>,\n",
       " 'ushort': numpy.uint16,\n",
       " 'value': array([[ -1.63858192e+00,  -9.16001298e-01,  -8.45054583e-01, ...,\n",
       "          -2.73437790e-01,  -1.36651804e+00,   1.00000000e+00],\n",
       "        [ -4.94235846e-01,  -9.16001298e-01,  -8.45054583e-01, ...,\n",
       "          -2.18893524e-01,   4.53758326e-01,   1.00000000e+00],\n",
       "        [ -1.63858192e+00,  -9.16001298e-01,  -8.45054583e-01, ...,\n",
       "          -2.79638044e-01,  -1.89519528e-01,   1.00000000e+00],\n",
       "        ..., \n",
       "        [ -4.94235846e-01,  -9.16001298e-01,   3.25320092e-01, ...,\n",
       "          -3.61319655e-01,  -1.86705898e+00,   1.00000000e+00],\n",
       "        [ -1.63858192e+00,  -9.16001298e-01,   3.25320092e-01, ...,\n",
       "           1.83564402e-15,  -9.68080597e-15,   1.00000000e+00],\n",
       "        [ -1.63858192e+00,  -9.16001298e-01,  -8.45054583e-01, ...,\n",
       "          -1.82680444e-01,   1.16772341e+00,   1.00000000e+00]]),\n",
       " 'vander': <function numpy.lib.twodim_base.vander>,\n",
       " 'var': <function numpy.core.fromnumeric.var>,\n",
       " 'var_names': ['src_subject_id',\n",
       "  'pds_ht2_y',\n",
       "  'pds_skin2_y',\n",
       "  'pds_bdyhair_y',\n",
       "  'PDS',\n",
       "  'pds_f4_2_y',\n",
       "  'pds_f5_y',\n",
       "  'pds_m4_y',\n",
       "  'pds_m5_y',\n",
       "  'interview_age',\n",
       "  'gender',\n",
       "  'anthroheightcalc',\n",
       "  'anthroweightcalc',\n",
       "  'anthro_waist_cm',\n",
       "  'hormone_scr_dhea_mean',\n",
       "  'hormone_scr_hse_mean',\n",
       "  'hormone_scr_ert_mean',\n",
       "  'sex'],\n",
       " 'vdot': <function numpy.core.multiarray.vdot>,\n",
       " 'vectorize': numpy.lib.function_base.vectorize,\n",
       " 'void': numpy.void,\n",
       " 'void0': numpy.void,\n",
       " 'vsplit': <function numpy.lib.shape_base.vsplit>,\n",
       " 'vstack': <function numpy.core.shape_base.vstack>,\n",
       " 'where': <function numpy.core.multiarray.where>,\n",
       " 'who': <function numpy.lib.utils.who>,\n",
       " 'x': 9,\n",
       " 'y': array([ 0.65011023,  0.38047076,  0.32532009,  0.24962499, -0.1918916 ,\n",
       "         0.74055957,  1.84992169,  0.68751924,  1.14615914, -0.7367237 ,\n",
       "        -0.32106293, -0.13369906]),\n",
       " 'zeros': <function numpy.core.multiarray.zeros>,\n",
       " 'zeros_like': <function numpy.core.numeric.zeros_like>}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ykmeans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-6d010bcf6b67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mykmeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ykmeans' is not defined"
     ]
    }
   ],
   "source": [
    "ykmeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
